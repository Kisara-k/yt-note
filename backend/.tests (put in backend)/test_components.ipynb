{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4dc43b",
   "metadata": {},
   "source": [
    "# Backend Component Testing\n",
    "\n",
    "This notebook tests the EXACT functionality of each backend component:\n",
    "\n",
    "1. **backend/youtube** - Takes video ID(s), returns metadata via YouTube Data API v3\n",
    "2. **backend/subtitles** - Takes video ID, returns list of chunks\n",
    "3. **backend/openai** - Takes chunk text, returns title + 3 fields from OpenAI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce1f502",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import all necessary modules and configure environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6774c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All modules imported successfully!\n",
      "üì¶ OpenAI Model: gpt-4o-mini\n",
      "üå°Ô∏è  Temperature: 0.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import backend modules\n",
    "from youtube.metadata import extract_video_id, fetch_video_metadata, fetch_batch_metadata\n",
    "from subtitles.extractor import extract_and_chunk_subtitles\n",
    "from openai_api.enrichment import enrich_chunk\n",
    "from prompts import PROMPTS\n",
    "from config import OPENAI_MODEL, OPENAI_TEMPERATURE\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(f\"üì¶ OpenAI Model: {OPENAI_MODEL}\")\n",
    "print(f\"üå°Ô∏è  Temperature: {OPENAI_TEMPERATURE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c5ebc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Test YouTube Metadata Retrieval\n",
    "\n",
    "**Specification:** Takes in a YouTube video ID (or multiple IDs) and uses the Data API v3 to get metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62864bb",
   "metadata": {},
   "source": [
    "### Test 2.1: Single Video ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4518ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìπ Testing with video ID: dQw4w9WgXcQ\n",
      "============================================================\n",
      "‚úÖ SUCCESS - Metadata retrieved!\n",
      "\n",
      "üìä Metadata Structure:\n",
      "  ‚Ä¢ video_id: dQw4w9WgXcQ\n",
      "  ‚Ä¢ title: Rick Astley - Never Gonna Give You Up (Official Video) (4K Remaster)\n",
      "  ‚Ä¢ channel_title: Rick Astley\n",
      "  ‚Ä¢ channel_id: UCuAXFkgsw1L7xaCfnd5JJOw\n",
      "  ‚Ä¢ published_at: 2009-10-25T06:57:33Z\n",
      "  ‚Ä¢ duration: PT3M34S\n",
      "  ‚Ä¢ view_count: 1,701,939,817\n",
      "  ‚Ä¢ like_count: 18,582,124\n",
      "  ‚Ä¢ thumbnail_url: https://i.ytimg.com/vi/dQw4w9WgXcQ/hqdefault.jpg...\n",
      "‚úÖ SUCCESS - Metadata retrieved!\n",
      "\n",
      "üìä Metadata Structure:\n",
      "  ‚Ä¢ video_id: dQw4w9WgXcQ\n",
      "  ‚Ä¢ title: Rick Astley - Never Gonna Give You Up (Official Video) (4K Remaster)\n",
      "  ‚Ä¢ channel_title: Rick Astley\n",
      "  ‚Ä¢ channel_id: UCuAXFkgsw1L7xaCfnd5JJOw\n",
      "  ‚Ä¢ published_at: 2009-10-25T06:57:33Z\n",
      "  ‚Ä¢ duration: PT3M34S\n",
      "  ‚Ä¢ view_count: 1,701,939,817\n",
      "  ‚Ä¢ like_count: 18,582,124\n",
      "  ‚Ä¢ thumbnail_url: https://i.ytimg.com/vi/dQw4w9WgXcQ/hqdefault.jpg...\n"
     ]
    }
   ],
   "source": [
    "# Test with single video ID\n",
    "video_id = \"dQw4w9WgXcQ\"\n",
    "\n",
    "print(f\"üìπ Testing with video ID: {video_id}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "metadata = fetch_video_metadata(video_id)\n",
    "\n",
    "if metadata:\n",
    "    print(\"‚úÖ SUCCESS - Metadata retrieved!\")\n",
    "    print(f\"\\nüìä Metadata Structure:\")\n",
    "    print(f\"  ‚Ä¢ video_id: {metadata['video_id']}\")\n",
    "    print(f\"  ‚Ä¢ title: {metadata['title']}\")\n",
    "    print(f\"  ‚Ä¢ channel_title: {metadata['channel_title']}\")\n",
    "    print(f\"  ‚Ä¢ channel_id: {metadata['channel_id']}\")\n",
    "    print(f\"  ‚Ä¢ published_at: {metadata['published_at']}\")\n",
    "    print(f\"  ‚Ä¢ duration: {metadata['duration']}\")\n",
    "    print(f\"  ‚Ä¢ view_count: {metadata['view_count']:,}\")\n",
    "    print(f\"  ‚Ä¢ like_count: {metadata['like_count']:,}\")\n",
    "    print(f\"  ‚Ä¢ thumbnail_url: {metadata['thumbnail_url'][:50]}...\")\n",
    "else:\n",
    "    print(\"‚ùå FAILED - Could not retrieve metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc74386",
   "metadata": {},
   "source": [
    "### Test 2.2: Multiple Video IDs (Batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cd276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìπ Testing with 2 video IDs\n",
      "============================================================\n",
      "‚úÖ SUCCESS - Retrieved 2 videos!\n",
      "\n",
      "üìä Batch Results:\n",
      "\n",
      "  Video 1:\n",
      "    ‚Ä¢ ID: dQw4w9WgXcQ\n",
      "    ‚Ä¢ Title: Rick Astley - Never Gonna Give You Up (Official Vi...\n",
      "    ‚Ä¢ Channel: Rick Astley\n",
      "    ‚Ä¢ Views: 1,701,939,817\n",
      "\n",
      "  Video 2:\n",
      "    ‚Ä¢ ID: 9bZkp7q19f0\n",
      "    ‚Ä¢ Title: PSY - GANGNAM STYLE(Í∞ïÎÇ®Ïä§ÌÉÄÏùº) M/V...\n",
      "    ‚Ä¢ Channel: officialpsy\n",
      "    ‚Ä¢ Views: 5,727,528,210\n",
      "‚úÖ SUCCESS - Retrieved 2 videos!\n",
      "\n",
      "üìä Batch Results:\n",
      "\n",
      "  Video 1:\n",
      "    ‚Ä¢ ID: dQw4w9WgXcQ\n",
      "    ‚Ä¢ Title: Rick Astley - Never Gonna Give You Up (Official Vi...\n",
      "    ‚Ä¢ Channel: Rick Astley\n",
      "    ‚Ä¢ Views: 1,701,939,817\n",
      "\n",
      "  Video 2:\n",
      "    ‚Ä¢ ID: 9bZkp7q19f0\n",
      "    ‚Ä¢ Title: PSY - GANGNAM STYLE(Í∞ïÎÇ®Ïä§ÌÉÄÏùº) M/V...\n",
      "    ‚Ä¢ Channel: officialpsy\n",
      "    ‚Ä¢ Views: 5,727,528,210\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple video IDs\n",
    "video_ids = [\"dQw4w9WgXcQ\", \"9bZkp7q19f0\"]\n",
    "\n",
    "print(f\"üìπ Testing with {len(video_ids)} video IDs\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "metadata_list = fetch_batch_metadata(video_ids)\n",
    "\n",
    "if metadata_list:\n",
    "    print(f\"‚úÖ SUCCESS - Retrieved {len(metadata_list)} videos!\")\n",
    "    print(f\"\\nüìä Batch Results:\")\n",
    "    for i, meta in enumerate(metadata_list, 1):\n",
    "        print(f\"\\n  Video {i}:\")\n",
    "        print(f\"    ‚Ä¢ ID: {meta['video_id']}\")\n",
    "        print(f\"    ‚Ä¢ Title: {meta['title'][:50]}...\")\n",
    "        print(f\"    ‚Ä¢ Channel: {meta['channel_title']}\")\n",
    "        print(f\"    ‚Ä¢ Views: {meta['view_count']:,}\")\n",
    "else:\n",
    "    print(\"‚ùå FAILED - Could not retrieve batch metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9930acd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Test Subtitle Chunk Extraction\n",
    "\n",
    "**Specification:** Takes in a YouTube video ID and returns the LIST OF CHUNKS for that video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a0c234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìπ Extracting subtitles for: m3ojamMNbKM\n",
      "============================================================\n",
      "‚úÖ SUCCESS - Extracted 12 chunks!\n",
      "\n",
      "üìä Chunk Structure:\n",
      "\n",
      "  Chunk 0:\n",
      "    ‚Ä¢ text: it's you that goes backwards it's you're not telling me that you fail you're not you've never said t...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 1:\n",
      "    ‚Ä¢ text: time and I don't know if this is gonna be kind of oddly stubborn but pick something sure let's say i...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 2:\n",
      "    ‚Ä¢ text: the Battle of kawatche yeah because I hadn't I didn't know anything about it I was this is insane it...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 3:\n",
      "    ‚Ä¢ text: easier for me to cook takes less time things that great yeah so it feels that's not the issue okay s...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 4:\n",
      "    ‚Ä¢ text: so let's talk let's dig into one of these and try to understand what that rubber band is so pick som...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 5:\n",
      "    ‚Ä¢ text: ego around this job because I do think that you feel you're too good for it the other thing is that ...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 6:\n",
      "    ‚Ä¢ text: me what I want to share maybe why I'm accepting that because I want to share it so this is important...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 7:\n",
      "    ‚Ä¢ text: is something much larger much more grand and much more devastating then you have an excuse for the l...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 8:\n",
      "    ‚Ä¢ text: along with my ass of lecturers or teachers disagreed with them a lot okay I said that's arrogance ri...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 9:\n",
      "    ‚Ä¢ text: job and you show up there and then the next day you just do it and the next day you just do it and t...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 10:\n",
      "    ‚Ä¢ text: look over here and you say I'm gonna work because this is what I've decided for myself yeah and that...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 11:\n",
      "    ‚Ä¢ text: of day because I have nothing to give back to you well I guess I have to give me something back huh ...\n",
      "    ‚Ä¢ word_count: 882\n",
      "    ‚Ä¢ sentence_count: 23\n",
      "\n",
      "üíæ Saved first chunk for OpenAI testing\n",
      "‚úÖ SUCCESS - Extracted 12 chunks!\n",
      "\n",
      "üìä Chunk Structure:\n",
      "\n",
      "  Chunk 0:\n",
      "    ‚Ä¢ text: it's you that goes backwards it's you're not telling me that you fail you're not you've never said t...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 1:\n",
      "    ‚Ä¢ text: time and I don't know if this is gonna be kind of oddly stubborn but pick something sure let's say i...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 2:\n",
      "    ‚Ä¢ text: the Battle of kawatche yeah because I hadn't I didn't know anything about it I was this is insane it...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 3:\n",
      "    ‚Ä¢ text: easier for me to cook takes less time things that great yeah so it feels that's not the issue okay s...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 4:\n",
      "    ‚Ä¢ text: so let's talk let's dig into one of these and try to understand what that rubber band is so pick som...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 5:\n",
      "    ‚Ä¢ text: ego around this job because I do think that you feel you're too good for it the other thing is that ...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 6:\n",
      "    ‚Ä¢ text: me what I want to share maybe why I'm accepting that because I want to share it so this is important...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 7:\n",
      "    ‚Ä¢ text: is something much larger much more grand and much more devastating then you have an excuse for the l...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 8:\n",
      "    ‚Ä¢ text: along with my ass of lecturers or teachers disagreed with them a lot okay I said that's arrogance ri...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 9:\n",
      "    ‚Ä¢ text: job and you show up there and then the next day you just do it and the next day you just do it and t...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 10:\n",
      "    ‚Ä¢ text: look over here and you say I'm gonna work because this is what I've decided for myself yeah and that...\n",
      "    ‚Ä¢ word_count: 1000\n",
      "    ‚Ä¢ sentence_count: 25\n",
      "\n",
      "  Chunk 11:\n",
      "    ‚Ä¢ text: of day because I have nothing to give back to you well I guess I have to give me something back huh ...\n",
      "    ‚Ä¢ word_count: 882\n",
      "    ‚Ä¢ sentence_count: 23\n",
      "\n",
      "üíæ Saved first chunk for OpenAI testing\n"
     ]
    }
   ],
   "source": [
    "# Test subtitle extraction and chunking\n",
    "video_id = \"m3ojamMNbKM\"\n",
    "\n",
    "print(f\"üìπ Extracting subtitles for: {video_id}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "chunks = extract_and_chunk_subtitles(video_id)\n",
    "\n",
    "if chunks:\n",
    "    print(f\"‚úÖ SUCCESS - Extracted {len(chunks)} chunks!\")\n",
    "    print(f\"\\nüìä Chunk Structure:\")\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"\\n  Chunk {i}:\")\n",
    "        print(f\"    ‚Ä¢ text: {chunk['text'][:100]}...\")\n",
    "        print(f\"    ‚Ä¢ word_count: {chunk['word_count']}\")\n",
    "        print(f\"    ‚Ä¢ sentence_count: {chunk['sentence_count']}\")\n",
    "    \n",
    "    # Save first chunk for OpenAI test\n",
    "    test_chunk_text = chunks[0]['text']\n",
    "    print(f\"\\nüíæ Saved first chunk for OpenAI testing\")\n",
    "else:\n",
    "    print(\"‚ùå FAILED - Could not extract subtitles\")\n",
    "    test_chunk_text = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d525ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Test OpenAI Processing\n",
    "\n",
    "**Specification:** Takes in a subtitle chunk (only the text) and returns the title and 3 fields from OpenAI based on the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3422b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Processing chunk with OpenAI\n",
      "============================================================\n",
      "üìù Input text preview: it's you that goes backwards it's you're not telling me that you fail you're not you've never said that to me right you say that when I am making prog...\n",
      "\n",
      "‚è≥ Calling OpenAI API...\n",
      "\n",
      "‚úÖ SUCCESS - OpenAI enrichment complete!\n",
      "\n",
      "üìä Output Structure:\n",
      "  ‚Ä¢ title: Overcoming Feelings of Powerlessness and Addiction\n",
      "  ‚Ä¢ field_1: In this video segment, the conversation revolves around feelings of powerlessness and hopelessness r...\n",
      "  ‚Ä¢ field_2: - The conversation revolves around feelings of powerlessness and hopelessness in daily life, particu...\n",
      "  ‚Ä¢ field_3: addiction, feelings of powerlessness, mental health, personal growth, self-improvement...\n",
      "\n",
      "‚úÖ SUCCESS - OpenAI enrichment complete!\n",
      "\n",
      "üìä Output Structure:\n",
      "  ‚Ä¢ title: Overcoming Feelings of Powerlessness and Addiction\n",
      "  ‚Ä¢ field_1: In this video segment, the conversation revolves around feelings of powerlessness and hopelessness r...\n",
      "  ‚Ä¢ field_2: - The conversation revolves around feelings of powerlessness and hopelessness in daily life, particu...\n",
      "  ‚Ä¢ field_3: addiction, feelings of powerlessness, mental health, personal growth, self-improvement...\n"
     ]
    }
   ],
   "source": [
    "# Prepare prompts\n",
    "prompt_dict = {\n",
    "    'title': PROMPTS['short_title']['template'],\n",
    "    'field_1': PROMPTS['ai_field_1']['template'],\n",
    "    'field_2': PROMPTS['ai_field_2']['template'],\n",
    "    'field_3': PROMPTS['ai_field_3']['template']\n",
    "}\n",
    "\n",
    "# Test with chunk text from previous step\n",
    "if test_chunk_text:\n",
    "    print(f\"ü§ñ Processing chunk with OpenAI\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìù Input text preview: {test_chunk_text[:150]}...\")\n",
    "    print(f\"\\n‚è≥ Calling OpenAI API...\")\n",
    "    \n",
    "    result = enrich_chunk(\n",
    "        text=test_chunk_text,\n",
    "        prompts=prompt_dict,\n",
    "        model=OPENAI_MODEL,\n",
    "        temperature=OPENAI_TEMPERATURE\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        print(f\"\\n‚úÖ SUCCESS - OpenAI enrichment complete!\")\n",
    "        print(f\"\\nüìä Output Structure:\")\n",
    "        print(f\"  ‚Ä¢ title: {result.get('title', 'N/A')}\")\n",
    "        print(f\"  ‚Ä¢ field_1: {result.get('field_1', 'N/A')[:100]}...\")\n",
    "        print(f\"  ‚Ä¢ field_2: {result.get('field_2', 'N/A')[:100]}...\")\n",
    "        print(f\"  ‚Ä¢ field_3: {result.get('field_3', 'N/A')[:100]}...\")\n",
    "    else:\n",
    "        print(\"‚ùå FAILED - OpenAI enrichment failed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping OpenAI test - no chunk text available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77403f6d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Integration Test: End-to-End Pipeline\n",
    "\n",
    "Test all components together in sequence: **YouTube ‚Üí Subtitles ‚Üí OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c066f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-end integration test\n",
    "test_video_id = \"dQw4w9WgXcQ\"\n",
    "\n",
    "print(\"üöÄ STARTING END-TO-END INTEGRATION TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Get metadata\n",
    "print(f\"\\n[1/3] üìπ Fetching video metadata...\")\n",
    "metadata = fetch_video_metadata(test_video_id)\n",
    "if metadata:\n",
    "    print(f\"      ‚úÖ Got metadata: {metadata['title'][:50]}...\")\n",
    "else:\n",
    "    print(f\"      ‚ùå Failed to get metadata\")\n",
    "\n",
    "# Step 2: Extract and chunk subtitles\n",
    "print(f\"\\n[2/3] üìù Extracting subtitle chunks...\")\n",
    "chunks = extract_and_chunk_subtitles(test_video_id)\n",
    "if chunks:\n",
    "    print(f\"      ‚úÖ Got {len(chunks)} chunks\")\n",
    "else:\n",
    "    print(f\"      ‚ùå Failed to extract chunks\")\n",
    "\n",
    "# Step 3: Enrich first chunk with OpenAI\n",
    "if chunks and len(chunks) > 0:\n",
    "    print(f\"\\n[3/3] ü§ñ Processing first chunk with OpenAI...\")\n",
    "    \n",
    "    enriched = enrich_chunk(\n",
    "        text=chunks[0]['text'],\n",
    "        prompts=prompt_dict,\n",
    "        model=OPENAI_MODEL,\n",
    "        temperature=OPENAI_TEMPERATURE\n",
    "    )\n",
    "    \n",
    "    if enriched:\n",
    "        print(f\"      ‚úÖ OpenAI enrichment complete!\")\n",
    "    else:\n",
    "        print(f\"      ‚ùå OpenAI enrichment failed\")\n",
    "else:\n",
    "    print(f\"\\n[3/3] ‚ö†Ô∏è  Skipping OpenAI - no chunks available\")\n",
    "    enriched = None\n",
    "\n",
    "# Final results\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"üìä INTEGRATION TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if metadata:\n",
    "    print(f\"\\n‚úÖ Video Metadata:\")\n",
    "    print(f\"   ‚Ä¢ Title: {metadata['title']}\")\n",
    "    print(f\"   ‚Ä¢ Channel: {metadata['channel_title']}\")\n",
    "    print(f\"   ‚Ä¢ Views: {metadata['view_count']:,}\")\n",
    "\n",
    "if chunks:\n",
    "    print(f\"\\n‚úÖ Subtitle Chunks:\")\n",
    "    print(f\"   ‚Ä¢ Total chunks: {len(chunks)}\")\n",
    "    print(f\"   ‚Ä¢ First chunk words: {chunks[0]['word_count']}\")\n",
    "    print(f\"   ‚Ä¢ First chunk sentences: {chunks[0]['sentence_count']}\")\n",
    "\n",
    "if enriched:\n",
    "    print(f\"\\n‚úÖ OpenAI Enrichment:\")\n",
    "    print(f\"   ‚Ä¢ Title: {enriched.get('title', 'N/A')}\")\n",
    "    print(f\"   ‚Ä¢ Field 1: {enriched.get('field_1', 'N/A')[:80]}...\")\n",
    "    print(f\"   ‚Ä¢ Field 2: {enriched.get('field_2', 'N/A')[:80]}...\")\n",
    "    print(f\"   ‚Ä¢ Field 3: {enriched.get('field_3', 'N/A')[:80]}...\")\n",
    "\n",
    "if metadata and chunks and enriched:\n",
    "    print(f\"\\nüéâ ALL COMPONENTS WORKING CORRECTLY!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Some components failed - check logs above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ff97f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook tested the EXACT functionality of each backend component:\n",
    "\n",
    "### ‚úÖ Component Specifications Verified:\n",
    "\n",
    "1. **backend/youtube/metadata.py**\n",
    "   - ‚úì Takes in video ID(s)\n",
    "   - ‚úì Uses YouTube Data API v3\n",
    "   - ‚úì Returns metadata dictionary\n",
    "\n",
    "2. **backend/subtitles/extractor.py**\n",
    "   - ‚úì Takes in video ID\n",
    "   - ‚úì Returns LIST OF CHUNKS\n",
    "   - ‚úì Each chunk has: text, word_count, sentence_count\n",
    "\n",
    "3. **backend/openai_api/enrichment.py**\n",
    "   - ‚úì Takes in chunk text (only)\n",
    "   - ‚úì Takes in prompts (required)\n",
    "   - ‚úì Returns title + 3 fields\n",
    "\n",
    "All components work independently and integrate correctly! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
