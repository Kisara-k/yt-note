[
  {
    "index": 5,
    "level": 1,
    "start_page": 6,
    "end_page": 11,
    "title": "Introduction: The Two-Thousand-Year-Old Assumption",
    "content": "Introduction: The Two-Thousand-Year-Old Assumption. On December 14, 2012, the deadliest school shooting in U.S. history took place at Sandy Hook Elementary School in Newtown, Connecticut. Twenty- six people inside the school, including twenty children, were massacred by a lone gunman. Several weeks after this horror, I watched the governor of Connecticut, Dannel Malloy, give his annual “State of the State” speech on television. He spoke in a strong and animated voice for the first three minutes, thanking individuals for their service. And then he began to address the Newtown tragedy: We have all walked a very long and very dark road together. What befell Newtown is not something we thought possible in any of Connecticut's beautiful towns or cities. And yet, in the midst of one of the worst days in our history, we also saw the best of our state. Teachers and a therapist that sacrificed their lives protecting students. As the governor spoke the last two words, “protecting students,” his voice caught in his throat ever so slightly. If you weren't paying close attention, you might have missed it. But that tiny waver devastated me. My stomach instantly knotted into a ball. My eyes flooded. The TV camera panned to the crowd where other people had started to sob too. As for Governor Malloy, he stopped speaking and was gazing downward. Emotions like Governor Malloy's and mine seem primal-hardwired into us, reflexively deployed, shared with all our fellow humans. When triggered, they seem to unleash themselves in each of us in basically the same way. My sadness was like Governor Malloy's sadness was like the crowd's sadness. Humanity has understood sadness and other emotions in this way for over two thousand years. But at the same time, if humanity has learned anything from centuries of scientific discovery, it's that things aren't always what they appear to be. The time-honored story of emotion goes something like this: We all have emotions built-in from birth. They are distinct, recognizable phenomena inside us. When something happens in the world, whether it's a gunshot or a flirtatious glance, our emotions come on quickly and automatically, as if someone has flipped a switch. We broadcast emotions on our faces by way of smiles, frowns, scowls, and other characteristic expressions that anyone can easily recognize. Our voices reveal our emotions through laughter, shouts, and cries. Our body posture betrays our feelings with every gesture and slouch. Modern science has an account that fits this story, which I call the classical view of emotion. According to this view, the waver in Governor Malloy's voice launched a chain reaction that began in my brain. A particular set of neurons-call it the “sadness circuit”-leaped into action and caused my face and body to respond in a certain, specific way. My brow furrowed, I frowned, my shoulders stooped, and I cried. This proposed circuit also triggered physical changes inside my body, causing my heart rate and breathing to speed up, my sweat glands to activate, and my blood vessels to constrict.* This collection of movements on the inside and outside of my body are said to be like a “fingerprint” that uniquely identifies sadness, much like your own fingerprints uniquely identify you. The classical view of emotion holds that we have many such emotion circuits in our brains, and each is said to cause a distinct set of changes, that is, a fingerprint. Perhaps an annoying coworker triggers your “anger neurons,” so your blood pressure rises; you scowl, yell, and feel the heat of fury. Or an alarming news story triggers your “fear neurons,” so your heart races; you freeze and feel a flash of dread. Because we experience anger, happiness, surprise, and other emotions as clear and identifiable states of being, it seems reasonable to assume that each emotion has a defining underlying pattern in the brain and body. Our emotions, according to the classical view, are artifacts of evolution, having long ago been advantageous for survival, and are now a fixed component of our biological nature. As such, they are universal: people of every age, in every culture, in every part of the world should experience sadness more or less as you do-and more or less as did our hominin ancestors who roamed the African savanna a million years ago. I say “more or less” because no one believes that faces, bodies, and brain activity look exactly the same each time someone is sad. Your heart rate and breathing and blood flow won't always change by the same amount. Your brow might furrow slightly less by chance or by custom. Emotions are thus thought to be a kind of brute reflex, very often at odds with our rationality. The primitive part of your brain wants you to tell your boss he's an idiot, but your deliberative side knows that doing so would get you fired, so you restrain yourself. This kind of internal battle between emotion and reason is one of the great narratives of Western civilization. It helps define you as human. Without rationality, you are merely an emotional beast. This view of emotions has been around for millennia in various forms. Plato believed a version of it. So did Hippocrates, Aristotle, the Buddha, René Descartes, Sigmund Freud, and Charles Darwin. Today, prominent thinkers such as Steven Pinker, Paul Ekman, and the Dalai Lama also offer up descriptions of emotions rooted in the classical view. The classical view is found in virtually every introductory college textbook on psychology, and in most magazine and newspaper articles that discuss emotion. Preschools throughout America hang posters displaying the smiles, frowns, and pouts that are supposed to be the universal language of the face for recognizing emotions. Facebook even commissioned a set of emoticons inspired by Darwin's writings. The classical view is also entrenched in our culture. Television shows like Lie to Me and Daredevil are predicated on the assumption that your innermost feelings are exposed by your heart rate or facial movements. Sesame Street teaches children that emotions are distinct things inside us seeking expression in the face and body, as does the Pixar movie Inside Out. Companies like Affectiva and Realeyes offer to help businesses detect their customers' feelings through “emotion analytics.” In the NBA draft, the Milwaukee Bucks evaluate a player's “psychological, character and personality issues” and assess “team chemistry” from facial expressions. And for several decades, the U.S. Federal Bureau of Investigation (FBI) based some of its advanced agent training on the classical view. More significantly, the classical view of emotion is embedded in our social institutions. The American legal system assumes that emotions are part of an inherent animal nature and cause us to perform foolish and even violent acts unless we control them with our rational thoughts. In medicine, researchers study the health effects of anger, supposing that there is a single pattern of changes in the body that goes by that name. People suffering from a variety of mental illnesses, including children and adults diagnosed with autism spectrum disorder, are taught how to recognize facial configurations for specific emotions, ostensibly to help them communicate and relate to others. And yet . . despite the distinguished intellectual pedigree of the classical view of emotion, and despite its immense influence in our culture and society, there is abundant scientific evidence that this view cannot possibly be true. Even after a century of effort, scientific research has not revealed a consistent, physical fingerprint for even a single emotion. When scientists attach electrodes to a person's face and measure how facial muscles actually move during the experience of an emotion, they find tremendous variety, not uniformity. They find the same variety-the same absence of fingerprints- when they study the body and the brain. You can experience anger with or without a spike in blood pressure. You can experience fear with or without an amygdala, the brain region historically tagged as the home of fear. To be sure, hundreds of experiments offer some evidence for the classical view. But hundreds more cast that evidence into doubt. The only reasonable scientific conclusion, in my opinion, is that emotions are not what we typically think they are. So what are they, really? When scientists set aside the classical view and just look at the data, a radically different explanation for emotion comes to light. In short, we find that your emotions are not built-in but made from more basic parts. They are not universal but vary from culture to culture. They are not triggered; you create them. They emerge as a combination of the physical properties of your body, a flexible brain that wires itself to whatever environment it develops in, and your culture and upbringing, which provide that environment. Emotions are real, but not in the objective sense that molecules or neurons are real. They are real in the same sense that money is real-that is, hardly an illusion, but a product of human agreement. This view, which I call the theory of constructed emotion, offers a very different interpretation of the events during Governor Malloy's speech. When Malloy's voice caught in his throat, it did not trigger a brain circuit for sadness inside me, causing a distinctive set of bodily changes. Rather, I felt sadness in that moment because, having been raised in a certain culture, I learned long ago that “sadness” is something that may occur when certain bodily feelings coincide with terrible loss. Using bits and pieces of past experience, such as my knowledge of shootings and my previous sadness about them, my brain rapidly predicted what my body should do to cope with such tragedy. Its predictions caused my thumping heart, my flushed face, and the knots in my stomach. They directed me to cry, an action that would calm my nervous system. And they made the resulting sensations meaningful as an instance of sadness. In this manner, my brain constructed my experience of emotion. My particular movements and sensations were not a fingerprint for sadness. With different predictions, my skin would cool rather than flush and my stomach would remain unknotted, yet my brain could still transform the resulting sensations into sadness. Not only that, but my original thumping heart, flushed face, knotted stomach, and tears could become meaningful as a different emotion, such as anger or fear, instead of sadness. Or in a very different situation, like a wedding celebration, those same sensations could become joy or gratitude. If this explanation doesn't make complete sense or even sounds counterintuitive so far, believe me, I am right there with you. After Governor Malloy's speech, as I came back to myself, wiping my tears, I was reminded that no matter what I know about emotions as a scientist, I experience them much as the classical view conceives them. My sadness felt like an instantly recognizable wave of bodily changes and feelings that overwhelmed me as a reaction to tragedy and loss. If I were not a scientist using experiments to reveal that emotions are in fact made and not triggered, I too would trust my immediate experience. The classical view of emotion remains compelling, despite the evidence against it, precisely because it's intuitive. The classical view also provides reassuring answers to deep, fundamental questions like: Where do you come from, evolutionarily speaking? Are you responsible for your actions when you get emotional? Do your experiences accurately reveal the world outside you? The theory of constructed emotion answers such questions differently. It's a different theory of human nature that helps you see yourself and others in a new and more scientifically justified light. The theory of constructed emotion might not fit the way you typically experience emotion and, in fact, may well violate your deepest beliefs about how the mind works, where humans come from, and why we act and feel as we do. But the theory consistently predicts and explains the scientific evidence on emotion, including plenty of evidence that the classical view struggles to make sense of. Why should you care which theory of emotion is correct? Because belief in the classical view affects your life in ways you might not realize. Think about the last time you went through airport security, where taciturn agents of the Transportation Security Administration (TSA) X-rayed your shoes and evaluated your likelihood as a terrorist threat. Not long ago, a training program called SPOT (Screening Passengers by Observation Techniques) taught those TSA agents to detect deception and assess risk based on facial and bodily movements, on the theory that such movements reveal your innermost feelings. It didn't work, and the program cost taxpayers $900 million. We need to understand emotion scientifically so government agents won't detain us-or overlook those who actually do pose a threat-based on an incorrect view of emotion. Now imagine that you're in a doctor's office, complaining of chest pressure and shortness of breath, which may be heart attack symptoms. If you're a woman, you're more likely to be diagnosed with anxiety and sent home, whereas if you're a man, you're more likely to be diagnosed with heart disease and receive lifesaving preventive treatment. As a result, women over age sixty-five die more frequently of heart attacks than men do. The perceptions of doctors, nurses, and the female patients themselves are shaped by classical view beliefs that they can detect emotions like anxiety, and that women are inherently more emotional than men . . with fatal consequences. Belief in the classical view can even start wars. The Gulf War in Iraq was launched, in part, because Saddam Hussein's half-brother thought he could read the emotions of the American negotiators and informed Saddam that the United States wasn't serious about attacking. The subsequent war claimed the lives of 175,000 Iraqis and hundreds of coalition forces. We are, I believe, in the midst of a revolution in our understanding of emotion, the mind, and the brain-a revolution that may compel us to radically rethink such central tenets of our society as our treatments for mental and physical illness, our understanding of personal relationships, our approaches to raising children, and ultimately our view of ourselves. Other scientific disciplines have seen revolutions of this kind, each one a momentous shift away from centuries of common sense. Physics moved from Isaac Newton's intuitive ideas about time and space to Albert Einstein's more relative ideas, and eventually to quantum mechanics. In biology, scientists carved up the natural world into fixed species, each having an ideal form, until Charles Darwin introduced the concept of natural selection. Scientific revolutions tend to emerge not from a sudden discovery but by asking better questions. How are emotions made, if they aren't simply triggered reactions? Why do they vary so much, and why have we believed for so long that they have distinctive fingerprints? These questions in and of themselves can be delightfully interesting to ponder. But taking pleasure in the unknown is more than just a scientific indulgence. It's part of the spirit of adventure that makes us human. In the pages that follow, I invite you to share that adventure with me. Chapters 1-3 introduce the new science of emotion: how psychology, neuroscience, and related disciplines are moving away from the search for emotion fingerprints and instead asking how emotions are constructed. Chapters 4-7 explain how, exactly, emotions are made. And chapters 8-12 explore the practical, real-world implications of this new theory of emotions on our approaches to health, emotional intelligence, child-rearing, personal relationships, systems of law, and even human nature itself. To close the book, chapter 13 reveals how the science of emotion illuminates the age-old mystery of how a human brain creates a human mind."
  },
  {
    "index": 6,
    "level": 1,
    "start_page": 12,
    "end_page": 34,
    "title": "The Search for Emotion’s “Fingerprints”",
    "content": "The Search for Emotion's “Fingerprints.” Once upon a time, in the 1980s, I thought I would be a clinical psychologist. I headed into a Ph.D. program at the University of Waterloo, expecting to learn the tools of the trade as a psychotherapist and one day treat patients in a stylish yet tasteful office. I was going to be a consumer of science, not a producer. I certainly had no intention of joining a revolution to unseat basic beliefs about the mind that have existed since the days of Plato. But life sometimes tosses little surprises in your direction. It was in graduate school that I felt my first tug of doubt about the classical view of emotion. At the time, I was researching the roots of low self-esteem and how it leads to anxiety or depression. Numerous experiments showed that people feel depressed when they fail to live up to their own ideals, but when they fall short of a standard set by others, they feel anxious. My first experiment in grad school was simply to replicate this well-known phenomenon before building on it to test my own hypotheses. In the course of this experiment, I asked a large number of volunteers if they felt anxious or depressed using well-established checklists of symptoms. I'd done more complicated experiments as an undergraduate student, so this one should have been a piece of cake. Instead, it crashed and burned. My volunteers did not report anxious or depressed feelings in the expected pattern. So I tried to replicate a second published experiment, and it failed too. I tried again, over and over, each experiment taking months. After three years, all I'd achieved was the same failure eight times in a row. In science, experiments often don't replicate, but eight consecutive failures is an impressive record. My internal critic taunted me: not everyone is cut out to be a scientist. When I looked closely at all the evidence I had collected, however, I noticed something consistently odd across all eight experiments. Many of my subjects appeared to be unwilling, or unable, to distinguish between feeling anxious and feeling depressed. Instead, they had indicated feeling both or neither; rarely did a subject report feeling just one. This made no sense. Everybody knows that anxiety and depression, when measured as emotions, are decidedly different. When you're anxious, you feel worked up, jittery, like you're worried something bad will happen. In depression you feel miserable and sluggish; everything seems horrible and life is a struggle. These emotions should leave your body in completely opposite physical states, and so they should feel different and be trivial for any healthy person to tell apart. Nevertheless, the data declared that my test subjects weren't doing so. The question was . . why? As it turned out, my experiments weren't failing after all. My first “botched” experiment actually revealed a genuine discovery-that people often did not distinguish between feeling anxious and feeling depressed. My next seven experiments hadn't failed either; they'd replicated the first one. I also began noticing the same effect lurking in other scientists' data. After completing my Ph.D. and becoming a university professor, I continued pursuing this mystery. I directed a lab that asked hundreds of test subjects to keep track of their emotional experiences for weeks or months as they went about their lives. My students and I inquired about a wide variety of emotional experiences, not just anxious and depressed feelings, to see if the discovery generalized. These new experiments revealed something that had never been documented before: everyone we tested used the same emotion words like “angry,” “sad,” and “afraid” to communicate their feelings but not necessarily to mean the same thing. Some test subjects made fine distinctions with their word use: for example, they experienced sadness and fear as qualitatively different. Other subjects, however, lumped together words like “sad” and “afraid” and “anxious” and “depressed” to mean “I feel crappy” (or, more scientifically, “I feel unpleasant”). The effect was the same for pleasant emotions like happiness, calmness, and pride. After testing over seven hundred American subjects, we discovered that people vary tremendously in how they differentiate their emotional experiences. A skilled interior designer can look at five shades of blue and distinguish azure, cobalt, ultramarine, royal blue, and cyan. My husband, on the other hand, would call them all blue. My students and I had discovered a similar phenomenon for emotions, which I described as emotional granularity. Here's where the classical view of emotion entered the picture. Emotional granularity, in terms of this view, must be about accurately reading your internal emotional states. Someone who distinguished among different feelings using words like “joy,” “sadness,” “fear,” “disgust,” “excitement,” and “awe” must be detecting physical cues or reactions for each emotion and interpreting them correctly. A person exhibiting lower emotional granularity, who uses words like “anxious” and “depressed” interchangeably, must be failing to detect these cues. I began wondering if I could teach people to improve their emotional granularity by coaching them to recognize their emotional states accurately. The key word here is “accurately.” How can a scientist tell if someone who says “I'm happy” or “I'm anxious” is accurate? Clearly, I needed some way to measure an emotion objectively and then compare it to what the person reports. If a person reports feeling anxious, and the objective criteria indicate that he is in a state of anxiety, then he is accurately detecting his own emotion. On the other hand, if the objective criteria indicate that he is depressed or angry or enthusiastic, then he's inaccurate. With an objective test in hand, the rest would be simple. I could ask a person how he feels and compare his answer to his “real” emotional state. I could correct any of his apparent mistakes by teaching him to better recognize the cues that distinguish one emotion from another and improve his emotional granularity. Like most students of psychology, I had read that each emotion is supposed to have a distinct pattern of physical changes, roughly like a fingerprint. Each time you grasp a doorknob, the fingerprints that you leave behind may vary depending on the firmness of your grip, how slippery the surface is, or how warm and pliable your skin is at that moment. Nevertheless, your fingerprints look similar enough each time to identify you uniquely. The “fingerprint” of an emotion is likewise assumed to be similar enough from one instance to the next, and in one person to the next, regardless of age, sex, personality, or culture. In a laboratory, scientists should be able to tell whether someone is sad or happy or anxious just by looking at physical measurements of a person's face, body, and brain. I felt confident that these emotion fingerprints could provide the objective criteria I needed to measure emotion. If the scientific literature was correct, then assessing people's emotional accuracy would be a breeze. But things did not turn out quite as I expected. According to the classical view of emotion, our faces hold the key to assessing emotions objectively and accurately. A primary inspiration for this idea is Charles Darwin's book The Expression of the Emotions in Man and Animals, where he claimed that emotions and their expressions were an ancient part of universal human nature. All people, everywhere in the world, are said to exhibit and recognize facial expressions of emotion without any training whatsoever. So, I thought that my lab should be able to measure facial movements, assess our test subjects' true emotional state, compare it to their verbal reports of emotion, and calculate their accuracy. If subjects made a pouting expression in the lab, for instance, but did not report feeling sad, we could train them to recognize the sadness they must be feeling. Case closed. The human face is laced with forty-two small muscles on each side. The facial movements that we see each other make every day-winks and blinks, smirks and grimaces, raised and wrinkled brows-occur when combinations of facial muscles contract and relax, causing connective tissue and skin to move. Even when your face seems completely still to the naked eye, your muscles are still contracting and relaxing. Figure 1-1: Muscles of the human face According to the classical view, each emotion is displayed on the face as a particular pattern of movements-a “facial expression.” When you're happy, you're supposed to smile. When you're angry, you're supposed to furrow your brow. These movements are said to be part of the fingerprint of their respective emotions. Back in the 1960s, the psychologist Silvan S. Tomkins and his protégés Carroll E. Izard and Paul Ekman decided to test this in the lab. They created sets of meticulously posed photographs, such as those in figure 1-2, to represent six so-called basic emotions they believed had biological fingerprints: anger, fear, disgust, surprise, sadness, and happiness. These photos, which featured actors who were carefully coached, were supposed to be the clearest examples of facial expressions for these emotions. (They might look exaggerated or artificial to you, but they were designed this way on purpose, because Tomkins believed they gave the strongest, clearest signals for emotion.)5 Figure 1-2: Some facial photographs from basic emotion method studies Using posed photos like these, Tomkins and his crew applied an experimental technique to study how well people “recognize” emotional expressions, or, more precisely, how well they perceive facial movements as expressions of emotion. Hundreds of published experiments have used this method, and it's still considered the gold standard today. A test subject is given a photograph and a set of emotion words, as in figure 1-3. Figure 1-3: Basic emotion method: picking a word to match the face The subject then chooses the word that best matches the face. In this case, the intended word is “Surprise.” Or, using a slightly different setup, a test subject is given two posed photos and a brief story, as in figure 1-4, and then picks which face best matches the story. In this case, the intended face is on the right. Figure 1-4: Basic emotion method: picking a face to match the story This research technique-let's call it the basic emotion method- revolutionized the scientific study of what Tomkins's group called “emotion recognition.” Using this method, scientists showed that people from around the world could consistently match the same emotion words (translated into the local language) to posed faces. In one famous study, Ekman and his colleagues traveled to Papua New Guinea and ran experiments with a local population, the Fore people, who had little contact with the Western world. Even this remote tribe could consistently match the faces to the expected emotion words and stories. In later years, scientists ran similar studies in many other countries such as Japan and Korea. In each case, subjects easily matched the posed scowls, pouts, smiles, and so on to the provided emotion words or stories. From this evidence, scientists concluded that emotion recognition is universal: no matter where you are born or grow up, you should be able to recognize American-style facial expressions like those in the photos. The only way expressions could be universally recognized, the reasoning went, is if they are universally produced: thus, facial expressions must be reliable, diagnostic fingerprints of emotion. Other scientists, however, worried that the basic emotion method was too indirect and subjective to reveal emotion fingerprints because it involves human judgment. A more objective technique, called facial electromyography (EMG), removes human perceivers altogether. Facial EMG places electrodes on the surface of the skin to detect the electrical signals that make facial muscles move. It precisely identifies the parts of the face as they move, how much, and how often. In a typical study, test subjects wear electrodes over their eyebrows, forehead, cheeks, and jaw as they view films or photos, or as they remember or imagine situations, to evoke a variety of emotions. Scientists record the electrical changes in muscle activity and calculate the degree of movement in each muscle during each emotion. If people move the same facial muscles in the same pattern each time they experience a given emotion-scowling in anger, smiling in happiness, pouting in sadness, and so on-and only when they experience that emotion, then the movements might be a fingerprint. As it turns out, facial EMG presents a serious challenge to the classical view of emotion. In study after study, the muscle movements do not reliably indicate when someone is angry, sad, or fearful; they don't form predictable fingerprints for each emotion. At best, facial EMG reveals that these movements distinguish pleasant versus unpleasant feeling. Even more damning, the facial movements recorded in these studies do not reliably match the posed photos created for the basic emotion method. Figure 1-5: Facial electromyography Let's take a moment and consider the implications of these findings. Hundreds of experiments have shown that people worldwide can match emotion words to so-called expressions of emotion, posed by actors who aren't actually feeling those emotions. However, those expressions can't be consistently and specifically detected by objective measures of facial muscle movements when people are actually feeling emotion. We all move our facial muscles all the time, of course, and when we look at each other, we effortlessly see emotion in some of these movements. Nevertheless, from a purely objective standpoint, when scientists measure just the muscle movements themselves, those movements do not conform to the photographs. It's conceivable that facial EMG is too limited to capture all the meaningful actions in a face during an emotional experience. A scientist can place about six electrodes on each side of the face before a test subject starts to feel uncomfortable, too few to capture all forty-two facial muscles meaningfully. So scientists also employ an alternative technique called facial action coding (FACS), in which trained observers laboriously classify a subject's individual facial movements as they occur. It's less objective than facial EMG, since it relies on human perceivers, but presumably more objective than matching words to posed faces in the basic emotion method. Nevertheless, the movements observed during facial action coding also don't consistently match the posed photos. These same inconsistencies show up in infants. If facial expressions are universal, then babies should be even more likely than adults to express anger with a scowl and sadness with a pout, because they're too young to learn rules of social appropriateness. And yet when scientists observe infants in situations that should evoke emotion, the infants do not make the expected expressions. For example, the developmental psychologists Linda A. Camras and Harriet Oster and their colleagues videotaped babies from various cultures, employing a growling gorilla toy to startle them (to induce fear) or restraining their arm (to induce anger). Camras and Oster found, using FACS, that the range of babies' facial movements in the two situations was indistinguishable. Nevertheless, when adults watched these videos, they somehow identified the infants in the gorilla film as afraid and infants in the arm restraint film as angry, even when Camras and Oster blanked out the babies' faces electronically! The adults were distinguishing fear from anger based on the context, without seeing facial movements at all. Don't get me wrong: newborns and young infants move their faces in meaningful ways. They make many distinctive facial movements when the situation implies that they might be interested or puzzled, or when they feel distress in response to pain or distaste in response to offending smells and tastes. But newborns don't show differentiated, adult-like expressions like the photographs from the basic emotion method. Other scientists also have demonstrated, as Camras and Oster did, that you take tremendous information from the surrounding context. They graft photographs of faces and bodies that don't belong together, like an angry scowling face attached to a body that's holding a dirty diaper, and their test subjects nearly always identify the emotion appropriate to the body, not the face-in this case, disgust rather than anger. Faces are constantly moving, and your brain relies on many different factors at once-body posture, voice, the overall situation, your lifetime of experience-to figure out which movements are meaningful and what they mean. When it comes to emotion, a face doesn't speak for itself. In fact, the poses of the basic emotion method were not discovered by observing faces in the real world. Scientists stipulated those facial poses, inspired by Darwin's book, and asked actors to portray them. And now these faces are simply assumed to be the universal expressions of emotion. But they aren't universal. To further demonstrate this, my lab conducted a study using photos from a group of emotion experts-accomplished actors. The photos came from the book In Character: Actors Acting, in which actors portray emotions by posing their faces to match written scenarios. We divided our U.S. test subjects into three groups. The first group read only the scenarios, for example, “He just witnessed a shooting on his quiet, tree- shaded block in Brooklyn.” A second group saw only the facial configurations, such as Martin Landau's pose for the shooting scenario (figure 1-6, center). A third group saw the scenarios and the faces. In each case, we handed subjects a short list of emotion words to categorize whatever emotion they saw. For the shooting scenario I just mentioned, 66 percent of subjects who read the scenario alone or with Landau's face rated the scenario as a fearful situation. But for subjects who saw Landau's face alone, devoid of context, only 38 percent of them rated it as fear and 56 percent rated it as surprise. (Figure 1-6 compares Landau's facial configuration to basic emotion method photos for “fear” and “surprise.” Does Landau look afraid or surprised? Or both?) Figure 1-6: Actor Martin Landau (center) flanked by basic emotion method faces for fear (left) and surprise (right) Other actors' poses for fear were strikingly different from Landau's. In one case, the actress Melissa Leo portrayed fear for the scenario: “She is trying to decide if she should tell her husband about a rumor going around that she is gay before he hears it from someone else.” Her mouth is closed and downturned, and her brow is slightly knitted. Nearly three-quarters of our test subjects who saw her face alone rated it as sad, but when presented with the scenario, 70 percent of subjects rated her face as displaying fear. This sort of variation held true for every emotion that we studied. An emotion like “Fear” does not have a single expression but a diverse population of facial movements that vary from one situation to the next.* (Think about it: When is the last time an actor won an Academy Award for pouting when sad?) This may seem obvious once you pause to consider your own emotional experiences. When you experience an emotion such as fear, you might move your face in a variety of ways. While cowering in your seat at a horror movie, you might close your eyes or cover them with your hands. If you're uncertain whether a person directly in front of you could harm you, you might narrow your eyes to see the person's face better. If danger is potentially lurking around the next corner, your eyes might widen to improve your peripheral vision. “Fear” takes no single physical form. Variation is the norm. Likewise, happiness, sadness, anger, and every other emotion you know is a diverse category, with widely varying facial movements. If facial movements have so much variation within an emotion category like “Fear,” you might wonder why we find it so natural to believe that a wide-eyed face is the universal fear expression. The answer is that it's a stereotype, a symbol that fits a well-known theme for “Fear” within our culture. Preschools teach these stereotypes to children: “People who scowl are angry. People who pout are sad.” They are cultural shorthands or conventions. You see them in cartoons, in advertisements, in the faces of dolls, in emojis- in an endless array of imagery and iconography. Textbooks teach these stereotypes to psychology students. Therapists teach them to their patients. The media spreads them widely throughout the Western world. “Now, wait just a minute,” you might be thinking. “Is she saying that our culture has created these expressions, and we all have learned them?” Well . . yes. And the classical view perpetuates these stereotypes as if they are authentic fingerprints of emotion. To be sure, faces are instruments of social communication. Some facial movements have meaning, but others do not, and right now, we know precious little about how people figure out which is which, other than that context is somehow crucial (body language, social situation, cultural expectation, etc.). When facial movements do convey a psychological message-say, raising an eyebrow-we don't know if the message is always emotional, or even if its meaning is the same each time. If we put all the scientific evidence together, we cannot claim, with any reasonable certainty, that each emotion has a diagnostic facial expression. In my search for unique fingerprints of emotion, I clearly needed a more reliable source than the human face, so next I looked to the human body. Perhaps some telling changes in heart rate, blood pressure, and other body functions would provide the necessary fingerprints to teach people to recognize their emotions more accurately. Some of the strongest experimental support for bodily fingerprints comes from a famous study by Paul Ekman, the psychologist Robert W. Levenson, and their colleague Wallace V. Friesen, published in the journal Science in 1983. They hooked up test subjects to machines to measure changes in the autonomic nervous system: variations in heart rate, temperature, and skin conductance (a measure of sweat). They also measured variations in arm tension, rooted in the skeletomotor nervous system. They then used an experimental technique to evoke anger, sadness, fear, disgust, surprise, and happiness, and observed the physical changes during each emotion. After analyzing the data, Ekman and his colleagues concluded that they had measured clear and consistent changes in these bodily responses, relating them to particular emotions. This study seemingly established objective, biological fingerprints in the body for each of the studied emotions, and today it remains a classic in the scientific literature. The famous 1983 study evoked emotion in a curious way-by having test subjects make and hold a facial pose from the basic emotion method. To evoke sadness, for example, a subject would frown for ten seconds. To evoke anger, a subject would scowl. While face-posing, subjects could use a mirror and were coached by Ekman himself to move particular facial muscles. The idea that a posed, so-called facial expression can trigger an emotional state is known as the facial feedback hypothesis. Allegedly, contorting your face into a particular configuration causes the specific physiological changes associated with that emotion in your body. Try it yourself. Knit your brows and pout for ten seconds-do you feel sad? Smile broadly. Do you feel happier? The facial feedback hypothesis is highly controversial-there is wide disagreement on whether a full-blown emotional experience can be evoked this way. The 1983 study did, in fact, observe bodily changes as people posed the required facial configurations. This is a remarkable finding: just posing a particular facial configuration changed the test subjects' peripheral nervous system activity, even while they were comfortably motionless in a chair. Their fingertips were warmer when posing a scowl (anger pose). Their heartbeats were faster when posing scowls, wide-eyed startle (fear pose), and pouts (sad pose) when compared to the poses for happiness, surprise, and disgust. The remaining two measures, skin conductance and arm tension, did not distinguish one facial configuration from another. Even so, you must take some additional steps before you can claim that you've found a bodily fingerprint for an emotion. For one thing, you must show that the response during one emotion, say, anger, is different from that of other emotions-that is, it's specific to instances of anger. Here, the 1983 study starts having some difficulty. It showed some specificity for anger but not for the other emotions tested. That means the bodily responses for different emotions were too similar to be distinct fingerprints. In addition, you must show that no other explanations can account for your results. Then, and only then, can you claim to have found physical fingerprints for anger, sadness, and the rest. The 1983 study is, for this reason, subject to an alternative explanation, because the test subjects were given instructions for how to pose their faces. Western subjects could conceivably identify most of the target emotions from these instructions. This understanding can actually produce the heart rate and other physical changes Ekman and colleagues observed, a fact that was unknown when these studies were conducted. This alternative explanation is borne out by their later experiment with an African tribe, the Minangkabau of West Sumatra. These volunteers had less understanding of Western emotions and did not show the same physical changes as Western test subjects; they also reported feeling the expected emotion much less frequently than the Western subjects did. Other subsequent research has evoked emotions using a variety of different methods but has not replicated the original physiological differences observed in the 1983 paper. Quite a few studies employ horror movies, tearful chick flicks, and other evocative material to bring on particular emotions, while scientists measure subjects' heart rate, respiration, and other bodily functions. Many such studies found great variability in physical measurements, meaning no clear pattern of bodily changes that distinguished emotions. In other studies, scientists did find distinguishing patterns, but different studies often found different patterns, even when using exactly the same film clips. In other words, when studies distinguished anger from sadness from fear, they did not always replicate one another, implying that the instances of anger, sadness, and fear cultivated in one study were different from those cultivated in another. When faced with a large collection of diverse experiments like this, it's hard to extract a consistent story. Fortunately, scientists have a technique to analyze all the data together and reach a unified conclusion. It's called a “meta-analysis.” Scientists comb through large numbers of experiments conducted by different researchers, combining their results statistically. As a simple example, suppose you wanted to check if increased heart rate is part of the bodily fingerprint of happiness. Rather than run your own experiment, you could do a meta-analysis of other experiments that measured heart rate during happiness, even incidentally (e.g., the study could be about the relationship between sex and heart attacks and have nothing centrally to do with emotion). You would search for all the relevant scientific papers, collect the relevant statistics from them, and analyze them en masse to test the hypothesis. Where emotions and the autonomic nervous system are concerned, four significant meta-analyses have been conducted in the last two decades, the largest of which covered more than 220 physiology studies and nearly 22,000 test subjects. None of these four meta-analyses found consistent and specific emotion fingerprints in the body. Instead, the body's orchestra of internal organs can play many different symphonies during happiness, fear, and the rest. You can see this variation easily in an experimental procedure used by laboratories around the world, where test subjects perform a difficult task such as counting backward by thirteen as fast as possible, or speaking about a polarizing topic like abortion or religion, while being ridiculed. As they struggle, the experimenter berates them for poor performance, making critical and even insulting remarks. Do all the test subjects get angry? No, they don't. More importantly, those who do feel angry show different patterns of bodily changes. Some people fume in anger, but some cry. Others become quiet and cunning. Still others just withdraw. Each behavior (fuming, crying, planning, withdrawing) is supported by a different physiological pattern in the body, a detail long known by physiologists who study the body for its own sake. Even small changes in body posture, like lying back versus leaning forward with arms crossed, can completely alter an angry person's physiological response. When I address audiences at conferences and present these meta-analyses, some people become incredulous: “Are you saying that in a frustrating, humiliating situation, not everyone will get angry so that their blood boils and their palms sweat and their cheeks flush?” And my answer is yes, that is exactly what I am saying. As a matter of fact, earlier in my career, when I was giving my first talks about these ideas, you could see variations in anger firsthand in audience members who really didn't like the evidence. Sometimes they would shift around in their seats. Other times they shook their head in a silent “no.” Once a colleague yelled at me while his face turned red and he stabbed his finger in the air. Another colleague asked me, in a sympathetic tone, if I had ever felt real fear, because if I'd ever been seriously harmed, I would never be suggesting such a preposterous idea. Yet another colleague said he would tell my brother-in-law (a sociologist of his acquaintance) that I was damaging the science of emotion. My favorite example involved a much more senior colleague, built like a linebacker and towering a foot above me, who cocked his fist and offered to punch me in the face to demonstrate what real anger looks like. (I smiled and thanked him for the thoughtful offer.) In these examples, my colleagues demonstrated the variability of anger far more handily than my presentation did. What does it mean that four meta-analyses, summarizing hundreds of experiments, revealed no consistent, specific fingerprints in the autonomic nervous system for different emotions? It doesn't mean that emotions are an illusion, or that bodily responses are random. It means that on different occasions, in different contexts, in different studies, within the same individual and across different individuals, the same emotion category involves different bodily responses. Variation, not uniformity, is the norm. These results are consistent with what physiologists have known for over fifty years: different behaviors have different patterns of heart rate, breathing, and so on to support their unique movements. Despite tremendous time and investment, research has not revealed a consistent bodily fingerprint for even a single emotion. My first two attempts to find objective fingerprints of emotion-in the face and body-had led me smack into a closed door. But as they say, when a door closes, sometimes a window opens. My window was the unexpected realization that an emotion is not a thing but a category of instances, and any emotion category has tremendous variety. Anger, for example, varies far more than the classical view of emotion predicts or can explain. When you're angry at someone, do you shout and swear or do you seethe quietly? Do you tease back in reproach? How about widening your eyes and raising your eyebrows? During these times, your blood pressure might go up or down or stay the same. You might feel your heart beating in your chest, or not. Your hands might become clammy, or they might remain dry . . whatever best prepares your body for action in that situation. How does your brain create and keep track of all these diverse angers? How does it know which one fits the situation best? If I asked how you felt in each of these situations, would you give a detailed answer like “aggravated,” “irritated,” “outraged,” or “vengeful” automatically with little effort? Or would you answer “angry” in each case, or simply, “I feel bad”? How do you even know the answer? These are mysteries that the classical view of emotion doesn't acknowledge. I didn't know it at the time, but as I considered emotion categories in all their diversity, I was unwittingly applying a standard way of thinking in biology called population thinking, which was proposed by Darwin. A category, such as a species of animal, is a population of unique members who vary from one another, with no fingerprint at their core. The category can be described at the group level only in abstract, statistical terms. Just as no American family consists of 3. people, no instance of anger must include an average anger pattern (should we be able to identify one). Nor will any instance necessarily resemble the elusive fingerprint of anger. What we have been calling a fingerprint might just be a stereotype. Once I adopted a mindset of population thinking, my whole landscape shifted, scientifically speaking. I began to see variation not as error but as normal and even desirable. I continued my quest for an objective way to distinguish one emotion from another, but it wasn't quite the same quest anymore. With growing skepticism, I had only one place left to look for fingerprints. It was time to turn to the brain.* Scientists have long studied people with brain damage (brain lesions) to try to locate an emotion in a specific area of the brain. If someone with a lesion in a particular area of the brain has difficulty experiencing or perceiving a particular emotion, and only that emotion, then this would be considered evidence that the emotion specifically depends on the neurons in that region. It's a bit like finding out which circuit breakers in your house control which parts of your electrical system. Initially, all breakers are on and your house runs normally. When you shut off one breaker (giving your electrical system a lesion of sorts) and observe that your kitchen lights no longer function, you've discovered a purpose of the breaker. The search for fear in the brain is an instructive example because for many years, scientists have considered it a textbook case of localizing emotion to a single brain area-namely, the amygdala, a group of nuclei found deep in the brain's temporal lobe.* The amygdala was first linked to fear in the 1930s when two scientists, Heinrich Klüver and Paul C. Bucy, removed the temporal lobes of rhesus monkeys. Lacking an amygdala, these monkeys approached objects and animals that would normally frighten them, like snakes, unfamiliar monkeys, or others that they'd avoided before the surgery, without hesitation. Klüver and Bucy attributed these deficits to an “absence of fear.”30 Not long afterward, other scientists began studying humans with amygdala damage to see if those patients continued to experience and perceive fear. The most intensively studied case is a woman known as “SM,” afflicted with a genetic disease that gradually obliterates the amygdala during childhood and adolescence, called Urbach-Wiethe disease. Overall, SM was (and still is) mentally healthy and of normal intelligence, but her relationship to fear seemed quite unusual in laboratory tests. Scientists showed her horror movies like The Shining and The Silence of the Lambs, exposed her to live snakes and spiders, and even took her through a haunted house, but she reported no strong feelings of fear. When SM was shown wide-eyed facial configurations from the basic emotion method's set of photos, she had difficulty identifying them as fearful. SM experienced and perceived other emotions normally. Scientists tried unsuccessfully to teach SM to feel fear, using a procedure commonly called fear learning. They showed her a picture and then immediately blasted a boat horn at one hundred decibels to startle her. This sound was meant to trigger SM's fear response if she had one. At the same time, they measured SM's skin conductance, which many scientists believe to be a measure of fear and is related to amygdala activity. After many repetitions of the picture followed by the horn blast, they showed SM the picture alone and measured her response. People with intact amygdalae would have learned to associate the picture with the startling sound, so if just shown the picture, their brain would predict the horn blast and their skin conductance would jump. But no matter how many times scientists paired the picture and the loud sound, SM's skin conductance didn't increase when viewing the picture alone. The experimenters concluded that SM could not learn to fear new objects. Overall, SM seemed fearless, and her damaged amygdalae seemed to be the reason. From this and other similar evidence, scientists concluded that a properly functioning amygdala was the brain center for fear. But then, a funny thing happened. Scientists found that SM could see fear in body postures and hear fear in voices. They even found a way to make SM feel terror, by asking her to breathe air that was loaded with extra carbon dioxide. Lacking the normal degree of oxygen, SM panicked. (Don't worry, she was not in danger.) So SM could clearly feel and perceive fear under some circumstances, even without her amygdalae. As brain lesion research progressed, other people with amygdala damage were discovered and tested, and the clear and specific link between fear and the amygdala dissolved. Perhaps the most important counterevidence came from a pair of identical twins who lost the supposed fear-related parts of their amygdalae to Urbach-Wiethe disease. Both were diagnosed at the age of twelve, have normal intelligence, and have a high school education. Despite their identical DNA, equivalent brain damage, and a common environment both as children and adults, the twins have very different profiles regarding fear. One twin, BG, is much like SM: she has similar fear-related deficits yet experiences fear when breathing carbon dioxide-loaded air. The other twin, AM, has basically normal responses during fear: other brain networks are compensating for her missing amygdalae. So we have identical twins, with identical DNA, suffering from identical brain damage, living in highly similar environments, but one has some fear-related deficits while the other has none. These findings undermine the idea that the amygdala contains the circuit for fear. They point instead to the idea that the brain must have multiple ways of creating fear, and therefore the emotion category “Fear” cannot be necessarily localized to a specific region. Scientists have studied other emotion categories in lesion patients besides fear, and the results have been similarly variable. Brain regions like the amygdala are routinely important to emotion, but they are neither necessary nor sufficient for emotion. This is one of the most surprising things I learned as I began to study neuroscience: a mental event, such as fear, is not created by only one set of neurons. Instead, combinations of different neurons can create instances of fear. Neuroscientists call this principle degeneracy. Degeneracy means “many to one”: many combinations of neurons can produce the same outcome. In the quest to map emotion fingerprints in the brain, degeneracy is a humbling reality check. My lab has observed degeneracy while performing brain scans on volunteers. We showed them evocative photos, with subject matter like skydiving and bloody corpses, and asked them how much bodily arousal they felt. Men and women reported equivalent feelings of arousal, and both had increased activity in two brain areas, the anterior insula and early visual cortex. However, women's feelings of arousal were more strongly linked to the anterior insula, while men's were more strongly linked to visual cortex. This is evidence that the same experience-feelings of arousal-was associated with different patterns of neural activity, an example of degeneracy. Another surprising thing I learned while training to be a neuroscientist, along with degeneracy, is that many parts of the brain serve more than one purpose. The brain contains core systems that participate in creating a wide variety of mental states. A single core system can play a role in thinking, remembering, decision-making, seeing, hearing, and experiencing and perceiving diverse emotions. A core system is “one to many”: a single brain area or network contributes to many different mental states. The classical view of emotion, in contrast, considers particular brain areas to have dedicated psychological functions, that is, they are “one to one.” Core systems are therefore the antithesis of neural fingerprints. To be clear, I'm not saying that every neuron in the brain does exactly the same thing, nor that every neuron can stand in for every other. (That view is called equipotentiality, and it's been long disproved.) I am saying that most neurons are multipurpose, playing more than one part, much as flour and eggs in your kitchen can participate in many recipes. The reality of core systems has been established through virtually every experimental method in neuroscience, but it's most easily seen with brain- imaging techniques that observe the brain in action. The most common method is called functional magnetic resonance imaging (fMRI), which can peer harmlessly into the heads of living people who are experiencing emotion or perceiving emotion in others, recording the changes in magnetic signals related to firing neurons. Even so, scientists employ fMRI to search for emotion fingerprints throughout the brain. If a particular blob of brain circuitry shows increased activation during a particular emotion, researchers reason, that would be evidence that the blob computes the emotion. Scientists initially focused their scanners on the amygdala and whether it contains the neural fingerprint for fear. One key piece of evidence came from test subjects who looked at photos of so-called fear poses from the basic emotion method while in the scanner. Their amygdalae increased in activity compared to when they viewed faces with neutral expressions. As research continued, however, anomalies emerged. Yes, the amygdala was showing an increase in activity, but only in certain situations, like when the eyes of a face were staring directly at the viewer. If the eyes were gazing off to the side, the neurons in the amygdala barely changed their firing rates. Also, if test subjects viewed the same stereotyped fear pose over and over again, their amygdala activation rapidly tapered off. If the amygdala truly housed the circuit for fear, then this habituation should not occur-the circuit should fire in an obligatory way whenever it is presented with a triggering “fear” stimulus. From these contrary results, it became clear to me-and ultimately to many other scientists-that the amygdala is not the home of fear in the brain. In 2008, my lab along with neurologist Chris Wright demonstrated why the amygdala increases in activity in response to the basic emotion fear faces. The activity increases in response to any face-whether fearful or neutral-as long as it is novel (i.e., the test subjects have not seen it before). Since the wide-eyed, fearful facial configurations of the basic emotion method occur rarely in everyday life, they are novel when test subjects view them in brain- imaging experiments. These findings, and others like them, provide an alternative explanation for the original experiments that don't require the amygdala to be the brain locus of fear. Over the past two decades, this back-and-forth trajectory, with evidence followed by counterevidence, has occurred in research on every brain region that has ever been identified as the neural fingerprint of an emotion. So my lab set out to settle the question of whether brain blobs are really emotion fingerprints once and for all. We examined every published neuroimaging study on anger, disgust, happiness, fear, and sadness, and combined those that were usable statistically in a meta-analysis. Altogether, this comprised nearly 100 published studies involving nearly 1,300 test subjects across almost 20 years. To make sense of this large amount of data, we divided the human brain virtually into tiny cubes called voxels, the 3-D version of pixels. Then, for every voxel in the brain during every emotion studied in every experiment, we recorded whether or not an increase in activation was reported. Now we could compute the probability that each voxel would show an increase in activation during the experience or perception of each emotion. When the probability was greater than chance, we called it statistically significant. Figure 1-7: The human brain divided into voxels Our comprehensive meta-analysis found little to support the classical view of emotion. The amygdala, for example, did show a consistent increase in activity for studies of fear, more than what you'd expect by chance, but only in a quarter of fear experience studies and about 40 percent of fear perception studies. These numbers fall short of what you'd expect for a neural fingerprint. Not only that, but the amygdala also showed a consistent increase during studies of anger, disgust, sadness, and happiness, indicating that whatever functions the amygdala was performing in some instances of fear, it was also performing those functions during some instances of those other emotions. Interestingly, amygdala activity likewise increases during events usually considered non-emotional, such as when you feel pain, learn something new, meet new people, or make decisions. It's probably increasing now as you read these words. In fact, every supposed emotional brain region has also been implicated in creating non-emotional events, such as thoughts and perceptions. Overall, we found that no brain region contained the fingerprint for any single emotion. Fingerprints are also absent if you consider multiple connected regions at once (a brain network), or stimulate individual neurons with electricity. The same results hold in experiments with other animals that allegedly have emotion circuits, such as monkeys and rats. Emotions arise from firing neurons, but no neurons are exclusively dedicated to emotion. For me, these findings have been the final, definitive nail in the coffin for localizing emotions to individual parts of the brain. By now, I hope you see that for a very long time, people have held a mistaken view of emotions. Many research studies claim to have identified physical fingerprints that distinguish one emotion from another. Nevertheless, these supportive studies are found within a much larger scientific context that doesn't support the classical view.* Some scientists might say that the contrary studies are simply wrong; after all, experiments on emotion can be pretty tricky to pull off. Some areas of the brain are really difficult to see. Heart rate is influenced by all kinds of factors that have nothing to do with emotion, like how much sleep test subjects had the night before, whether they had any caffeine in the last hour, and whether they are sitting, standing, or lying down. It's also challenging to make test subjects experience emotion on cue. Trying to evoke blood-curdling fear or brain-boiling anger is against the rules: all universities have Institutional Review Boards that prevent people like me from inflicting too much emotional agony on innocent volunteers. But even considering all these caveats, far more experiments call the classical view into doubt than we would expect by chance, or even due to inadequate experimental methods. Facial EMG studies demonstrate that people move their facial muscles in many different ways, not one consistent way, when feeling an instance of the same emotion category. Large meta- analyses conclude that a single emotion category involves different bodily responses, not a single, consistent response. Brain circuitry operates by the many-to-one principle of degeneracy: instances of a single emotion category, such as fear, are handled by different brain patterns at different times and in different people. Conversely, the same neurons can participate in creating different mental states (one-to-many). I hope you've caught the pattern emerging here: variation is the norm. Emotion fingerprints are a myth. If we want to truly understand emotions, we must start taking that variation seriously. We must consider that an emotion word, like “anger,” does not refer to a specific response with a unique physical fingerprint but to a group of highly variable instances that are tied to specific situations. What we colloquially call emotions, such as anger, fear, and happiness, are better thought of as emotion categories, because each is a collection of diverse instances. Just as instances of the category “Cocker Spaniel” vary in their physical attributes (tail length, nose length, coat thickness, running speed, and so on) more than genes alone can account for, so might instances of “Anger” vary in their physical manifestations (facial movements, heart rate, hormones, vocal acoustics, neural activity, and so on), and this variation might be related to the environment or context. When you adopt a mindset of variation and population thinking, so-called emotion fingerprints give way to better explanations. Here's an example of what I mean. Some scientists, using techniques from artificial intelligence, can train a software program to recognize many, many brain scans of people experiencing different emotions (say, anger and fear). The program computes a statistical pattern that summarizes each emotion category and then-here's the cool part-can actually analyze new scans and determine if they are closer to the summary pattern for anger or fear. This technique, called pattern classification, works so well that it's sometimes called “neural mind-reading.” Some of these scientists claim that the statistical summaries depict neural fingerprints for anger and fear. But that's a gigantic logical error. The statistical pattern for fear is not an actual brain state, just an abstract summary of many instances of fear. These scientists are mistaking a mathematical average for the norm. My collaborators and I applied pattern classification to our meta-analysis of brain-imaging studies of emotion. Our computer program learned to classify scans from about 150 different studies. We found patterns across the brain that predict better than chance whether the test subjects in a specific study were experiencing anger, disgust, fear, happiness, or sadness. These patterns are not emotion fingerprints, however. The pattern for anger, for example, consists of a set of voxels across the brain, but that pattern need not appear in any individual brain scan for anger. The pattern is an abstract summary. In fact, no individual voxel appeared in all the scans of anger. When properly applied, pattern classification is an example of population thinking. A species, you may recall, is a collection of diverse individuals, so it can be summarized only in statistical terms. The summary is an abstraction that does not exist in nature-it does not describe any individual member of the species. Where emotion is concerned, on different occasions and in different people, different combinations of neurons can create instances of an emotion category like anger. Even when two experiences of anger feel the same to you, they can have different brain patterns via degeneracy. But we can still summarize many varying instances of anger to describe how, in abstract terms, they might be distinguishable from all the varying instances of fear. (Analogy: no two Labrador Retrievers are identical, but they're all distinguishable from Golden Retrievers.) My long search for fingerprints in the face, body, and brain brought me to a realization that I had not expected-that we need a new theory of what emotions are and where they come from. In the chapters that follow, I introduce you to this new theory, which accounts for all the findings of the classical view as well as all the inconsistencies you've just seen. By moving beyond fingerprints and following the evidence, we will seek a better and more scientifically justified understanding, not only of emotion but also of ourselves."
  },
  {
    "index": 7,
    "level": 1,
    "start_page": 35,
    "end_page": 49,
    "title": "Emotions Are Constructed",
    "content": "Emotions Are Constructed. Please take a look at the black splotches in figure 2-1. Figure 2-1: Mystery blobs If this is your first time viewing these blobs, your brain is working hard to make sense of them. Neurons in your visual cortex are processing the lines and edges. Your amygdala is firing rapidly because the input is novel. Other brain regions are sifting through your past experiences to determine if you've encountered anything like this input before and are conversing with your body to prepare it for an as-yet-undetermined action. Most likely, you are in a state called experiential blindness, seeing only black blobs of unknown origin. To cure your experiential blindness, look at the image on page 308 (appendix B). Then come back to this page. You should no longer see formless blobs but a familiar object. What just happened in your brain to change your perception of these blobs? Your brain added stuff from the full photograph into its vast array of prior experiences and constructed the familiar object you now see in the blobs. Neurons in your visual cortex changed their firing to create lines that aren't present, linking the blobs into a shape that isn't physically there. You are, in a manner of speaking, hallucinating. Not the scary “I'd better get to the hospital” kind of hallucination, but the everyday “my brain is built to work like this” hallucination. Your experience with figure 2-1 reveals a couple of insights. Your past experiences-from direct encounters, from photos, from movies and books- give meaning to your present sensations. Additionally, the entire process of construction is invisible to you. No matter how hard you try, you cannot observe yourself or experience yourself constructing the image. We needed a specially designed example to unmask the fact that construction is occurring. You consciously experienced the shift from unknown to known because you saw figure 2-1 both before and after you had the relevant knowledge to draw on. The process of construction is so habitual that you might never again see this figure as formless shapes, even if you try hard to un-see it and recapture experiential blindness. This little magic trick of the brain is so common and normal that psychologists discovered it time and time again before they understood how it worked. We will call it simulation. It means that your brain changed the firing of its own sensory neurons in the absence of incoming sensory input. Simulation can be visual, as with our picture, or involve any of your other senses. Ever have a song playing in your head that you can't get rid of ? That audio hallucination is also a simulation. Think of the last time someone handed you a red, juicy apple. You reached out for it, took a bite, and experienced the tart flavor. During those moments, neurons were firing in the sensory and motor regions of your brain. Motor neurons fired to produce your movements, and sensory neurons fired to process your sensations of the apple, like its red color with a blush of green; its smoothness against your hand; its crisp, floral scent; the audible crunch when you bit into it; and its tangy taste with a hint of sweetness. Other neurons made your mouth water to release enzymes and begin digestion, released cortisol to prepare your body to metabolize the sugars in the apple, and perhaps made your stomach churn a bit. But here's the cool thing: just now, when you read the word “apple,” your brain responded to a certain extent as if an apple were actually present. Your brain combined bits and pieces of knowledge of previous apples you've seen and tasted, and changed the firing of neurons in your sensory and motor regions to construct a mental instance of the concept “Apple.” Your brain simulated a nonexistent apple using sensory and motor neurons. Simulation happens as quickly and automatically as a heartbeat. For my daughter's twelfth birthday, we exploited the power of simulation (and had some fun) by throwing a “gross foods” party. When her guests arrived, we served them pizza doctored with green food coloring so the cheese looked like fuzzy mold, and peach gelatin laced with bits of vegetables to look like vomit. For drinks, we served white grape juice in medical urine sample cups. Everybody was exuberantly disgusted (it was perfect twelve- year-old humor), and several guests could not bring themselves to touch the food as they involuntarily simulated vile tastes and smells. The pièce de résistance, however, was the party game we played after lunch: a simple contest to identify foods by their smell. We used mashed baby food- peaches, spinach, beef, and so on-and artfully smeared it on diapers, so it looked exactly like baby poo. Even though the guests knew that the smears were food, several actually gagged from the simulated smell. Simulations are your brain's guesses of what's happening in the world. In every waking moment, you're faced with ambiguous, noisy information from your eyes, ears, nose, and other sensory organs. Your brain uses your past experiences to construct a hypothesis-the simulation-and compares it to the cacophony arriving from your senses. In this manner, simulation lets your brain impose meaning on the noise, selecting what's relevant and ignoring the rest. The discovery of simulation in the late 1990s ushered in a new era in psychology and neuroscience. Scientific evidence shows that what we see, hear, touch, taste, and smell are largely simulations of the world, not reactions to it. Forward-looking thinkers speculate that simulation is a common mechanism not only for perception but also for understanding language, feeling empathy, remembering, imagining, dreaming, and many other psychological phenomena. Our common sense might declare that thinking, perceiving, and dreaming are different mental events (at least to those of us in Western cultures), yet one general process describes them all. Simulation is the default mode for all mental activity. It also holds a key to unlocking the mystery of how the brain creates emotions. Outside your brain, simulation can cause tangible changes in your body. Let's try a little creative simulation with our bee. In your mind's eye, see the bee bouncing lightly on the petal of a fragrant white flower, buzzing around as it searches for pollen. If you're fond of bees, then the flutter of imaginary wings is right now causing other neurons to prepare your body to move in for a closer look-preparing your heart to beat faster, your sweat glands to fill, and your blood pressure to decrease. Or if you have been badly stung in the past, your brain may ready your body to run away or make a swatting motion, formulating some other pattern of physical changes. Each time your brain simulates sensory input, it prepares automatic changes in your body that have the potential to change your feeling. Your bee-related simulations are rooted in your mental concept of what a “Bee” is. This concept not only includes information about the bee itself (what it looks and sounds like, how you act on it, what changes in your autonomic nervous system allow your action, etc.), but also information contained in other concepts related to bees (“Meadow,” “Flower,” “Honey,” “Sting,” “Pain,” etc.). All this information is integrated with your concept “Bee,” guiding how you simulate the bee in this particular context. So, a concept like “Bee” is actually a collection of neural patterns in your brain, representing your past experiences. Your brain combines these patterns in different ways to perceive and flexibly guide your action in new situations. Using your concepts, your brain groups some things together and separates others. You can look at three mounds of dirt and perceive two of them as “Hills” and one as a “Mountain,” based on your concepts. Construction treats the world like a sheet of pastry, and your concepts are cookie cutters that carve boundaries, not because the boundaries are natural, but because they're useful or desirable. These boundaries have physical limitations of course; you'd never perceive a mountain as a lake. Not everything is relative. Your concepts are a primary tool for your brain to guess the meaning of incoming sensory inputs. For example, concepts give meaning to changes in sound pressure so you hear them as words or music instead of random noise. In Western culture, most music is based on an octave divided into twelve equally spaced pitches: the equal-tempered scale codified by Johann Sebastian Bach in the seventeenth century. All people of Western culture with normal hearing have a concept for this ubiquitous scale, even if they can't explicitly describe it. Not all music uses this scale, however. When Westerners hear Indonesian gamelan music for the first time, which is based on seven pitches per octave with varied tunings, it's more likely to sound like noise. A brain that's been wired by listening to twelve-tone scales doesn't have a concept for that music. Personally, I am experientially blind to dubstep, although my teenage daughter clearly has that concept. Concepts also give meaning to the chemicals that create tastes and smells. If I served you pink ice cream, you might expect (simulate) the taste of strawberry, but if it tasted like fish, you would find it jarring, perhaps even disgusting. If I instead introduced it as “chilled salmon mousse” to give your brain fair warning, you might find the same taste delicious (assuming you enjoy salmon). You might think of food as existing in the physical world, but in fact the concept “Food” is heavily cultural. Obviously, there are some biological constraints; you can't eat razor blades. But there are some perfectly edible substances that we don't all perceive as food, such as hachinoko, a Japanese delicacy made of baby bees, which most Americans would vigorously avoid. This cultural difference is due to concepts. Every moment that you are alive, your brain uses concepts to simulate the outside world. Without concepts, you are experientially blind, as you were with the blobby bee. With concepts, your brain simulates so invisibly and automatically that vision, hearing, and your other senses seem like reflexes rather than constructions. Now consider this: what if your brain uses this same process to make meaning of the sensations from inside your body-the commotion arising from your heartbeat, breathing, and other internal movements? From your brain's perspective, your body is just another source of sensory input. Sensations from your heart and lungs, your metabolism, your changing temperature, and so on, are like the ambiguous blobs of figure 2-1. These purely physical sensations inside your body have no objective psychological meaning. Once your concepts enter the picture, however, those sensations may take on additional meaning. If you feel an ache in your stomach while sitting at the dinner table, you might experience it as hunger. If flu season is just around the corner, you might experience that same ache as nausea. If you are a judge in a courtroom, you might experience the ache as a gut feeling that the defendant cannot be trusted. In a given moment, in a given context, your brain uses concepts to give meaning to internal sensations as well as to external sensations from the world, all simultaneously. From an aching stomach, your brain constructs an instance of hunger, nausea, or mistrust. Now consider that same stomachache if you're sniffing a diaper heavy with pureed lamb, as my daughter's friends did at her gross foods birthday party. You might experience the ache as disgust. Or if your lover has just walked into the room, you might experience the ache as a pang of longing. If you're in a doctor's office waiting for the results of a medical test, you might experience that same ache as an anxious feeling. In these cases of disgust, longing, and anxiety, the concept active in your brain is an emotion concept. As before, your brain makes meaning from your aching stomach, together with the sensations from the world around you, by constructing an instance of that concept. An instance of emotion. And that just might be how emotions are made. Back when I was in graduate school, a guy in my psychology program asked me out on a date. I didn't know him very well and was reluctant to go because, honestly, I wasn't particularly attracted to him, but I had been cooped up too long in the lab that day, so I agreed. As we sat together in a coffee shop, to my surprise, I felt my face flush several times as we spoke. My stomach fluttered and I started having trouble concentrating. Okay, I realized, I was wrong. I am clearly attracted to him. We parted an hour later- after I agreed to go out with him again-and I headed home, intrigued. I walked into my apartment, dropped my keys on the floor, threw up, and spent the next seven days in bed with the flu. The same neural process of construction that simulates a bee from blobs also constructs feelings of attraction from a fluttering stomach and a flushing face. An emotion is your brain's creation of what your bodily sensations mean, in relation to what is going on around you in the world. Philosophers have long proposed that your mind makes sense of your body in the world, from René Descartes in the seventeenth century to William James (considered the father of American psychology) in the nineteenth; as you will learn, however, neuroscience now shows us how this process-and much more- occurs in the brain to make an emotion on the spot. I call this explanation the theory of constructed emotion:9 In every waking moment, your brain uses past experience, organized as concepts, to guide your actions and give your sensations meaning. When the concepts involved are emotion concepts, your brain constructs instances of emotion. If a swarm of buzzing bees is squeezing underneath your front door while your heart is pounding in your chest, your brain's prior knowledge of stinging insects gives meaning to the sensations from your body and to the sights, sounds, smells, and other sensations from the world, simulating the swarm, the door, and an instance of fear. The exact same bodily sensations in another context, like watching a fascinating film about the hidden lives of bees, might construct an instance of excitement. Or if you see a picture of a smiling cartoon bee in a children's book, reminding you of a beloved niece whom you took to a Disney movie, you could mentally construct the bee, the niece, and an instance of pleasant nostalgia. My experience in the coffee shop, where I felt attraction when I had the flu, would be called an error or misattribution in the classical view, but it's no more a mistake than seeing a bee in a bunch of blobs. An influenza virus in my blood contributed to fever and flushing, and my brain made meaning from the sensations in the context of a lunch date, constructing a genuine feeling of attraction, in the normal way that the brain constructs any other mental state. If I'd had exactly the same bodily sensations while at home in bed with a thermometer, my brain might have constructed an instance of “Feeling Sick” using the same manufacturing process. (The classical view, in contrast, would require feelings of attraction and malaise to have different bodily fingerprints triggered by different brain circuitry.)10 Emotions are not reactions to the world. You are not a passive receiver of sensory input but an active constructor of your emotions. From sensory input and past experience, your brain constructs meaning and prescribes action. If you didn't have concepts that represent your past experience, all your sensory inputs would just be noise. You wouldn't know what the sensations are, what caused them, nor how to behave to deal with them. With concepts, your brain makes meaning of sensation, and sometimes that meaning is an emotion. The theory of constructed emotion and the classical view of emotion tell vastly different stories of how we experience the world. The classical view is intuitive-events in the world trigger emotional reactions inside of us. Its story features familiar characters like thoughts and feelings that live in distinct brain areas. The theory of constructed emotion, in contrast, tells a story that doesn't match your daily life-your brain invisibly constructs everything you experience, including emotions. Its story features unfamiliar characters like simulation and concepts and degeneracy, and it takes place throughout the whole brain at once. This unfamiliar story creates a challenge because people expect stories with familiar structures. Every superhero story is assumed to have a villain. Every romantic comedy requires an attractive couple faced with a humorous misunderstanding that turns out all right in the end. Our challenge here is that the dynamics of the brain, and how emotions are made, do not follow a linear, cause-and-effect sort of story. (This challenge is common in science; for example, in quantum mechanics, the distinction between a cause and an effect is not meaningful.) Nevertheless, every book must tell a story, even for a nonlinear subject like brain function. Mine will occasionally have to defy the usual linear framework of human storytelling. For now, my aim is simply to give you some intuition about the construction of emotion and why this scientific explanation makes sense. We'll see later that this theory incorporates the most up-to-date, neuroscientific understanding of how the brain works, and it explains the great variation in emotional experiences and perceptions in everyday life. It can help us figure out how instances of happiness, sadness, anger, fear, and other emotion categories are constructed by the same brain mechanism that constructed the blobby bee, the juicy apple, and the smell of poo from mashed baby food, with no need for emotion circuits or other biological fingerprints. I'm not the first person to propose that emotions are made. The theory of constructed emotion belongs to a broader scientific tradition called construction, which holds that your experiences and behaviors are created in the moment by biological processes within your brain and body. Construction is based on a very old set of ideas that date back to Ancient Greece, when the philosopher Heraclitus famously wrote, “No man ever steps in the same river twice,” because only a mind perceives an ever-changing river as a distinct body of water. Today, constructionism spans many topics including memory, perception, mental illness, and, of course, emotion. A constructionist approach to emotion has a couple of core ideas. One idea is that an emotion category such as anger or disgust does not have a fingerprint. One instance of anger need not look or feel like another, nor will it be caused by the same neurons. Variation is the norm. Your range of angers is not necessarily the same as mine, although if we were raised in similar circumstances, we will likely have some overlap. Another core idea is that the emotions you experience and perceive are not an inevitable consequence of your genes. What's inevitable is that you'll have some kinds of concepts for making sense of sensory input from your body in the world because, as we learn in chapter 5, your brain has wiring for this purpose. Even single-celled animals can make sense of changes in their environment. But particular concepts like “Anger” and “Disgust” are not genetically predetermined. Your familiar emotion concepts are built-in only because you grew up in a particular social context where those emotion concepts are meaningful and useful, and your brain applies them outside your awareness to construct your experiences. Heart rate changes are inevitable; their emotional meaning is not. Other cultures can and do make other kinds of meaning from the same sensory input. The theory of constructed emotion incorporates ideas from several flavors of construction. One flavor, called social construction, studies the role of social values and interests in determining how we perceive and act in the world. An example would be whether or not Pluto is a planet, which is a decision not based in astrophysics but in culture. Spherical rocks in space are objectively real and come in various sizes, but the idea of a “Planet,” representing a particular combination of features of interest, is made up by people. Each of us understands the world in a way that is useful but not necessarily true in some absolute, objective sense. Where emotion is concerned, social construction theories ask how feelings and perceptions are influenced by our social roles or beliefs. For example, my perceptions are influenced by the fact that I am a woman, a mother, an atheist who is culturally Jewish, and a rather pale person living in a country that once enslaved people for having more melanin in their skin than I do. Social construction tends to ignore biology, however, as irrelevant to emotion. Instead, the theories suggest that emotions are triggered differently depending on your social role. Social constructionist theories, then, are primarily concerned with social circumstances in the world outside you, without considering how those circumstances affect the brain's wiring. Another flavor of construction, known as psychological construction, turns this focus inward. It proposes that your perceptions, thoughts, and feelings are themselves constructed from more basic parts. Some nineteenth-century philosophers viewed the mind like a big chemistry set, combining simpler sensations into thoughts and emotions the way that atoms combine to make molecules. Others saw the mind as a set of all-purpose parts, like Lego blocks, that contribute to various mental states like cognitions and emotions. William James proposed that our incredibly varied emotional experiences are constructed from common ingredients. “Emotional brain processes,” he wrote, “not only resemble the ordinary sensorial brain-processes, but in very truth are nothing but such processes variously combined.” In the 1960s, the psychologists Stanley Schachter and Jerome Singer famously injected test subjects with adrenaline-without the subjects' knowledge-and saw them experience this mysterious arousal as anger or euphoria, depending on the context surrounding them. In all these views, an instance of anger or elation does not reveal its causal mechanisms-a marked contrast to the classical view, where each emotion has a dedicated mechanism in the brain, and the same word (e.g., “sadness”) names the mechanism and its product. In recent years, a new generation of scientists has been crafting psychological construction-based theories for understanding emotions and how they work. Not every theory agrees on every assumption, but together they assert that emotions are made, not triggered; emotions are highly variable, without fingerprints; and emotions are not, in principle, distinct from cognitions and perceptions. You might be surprised to learn that these same principles of construction appear to hold for the brain's physical architecture, an idea called neuroconstruction. Consider two neurons that are connected by a synapse. Clearly these brain cells exist in an objective sense. But there is no objective way to tell whether the two neurons are part of a unit called a “circuit” or “system,” or whether each neuron belongs to a separate circuit where one “regulates” the other. The answer depends entirely on human perspective. Similarly, your brain's interconnections are not inevitable consequences of your genes alone. We know today that experience is a contributing factor. Your genes turn on and off in different contexts, including the genes that shape your brain's wiring. (Scientists call this phenomenon plasticity.) That means some of your synapses literally come into existence because other people talked to you or treated you in a certain way. In other words, construction extends all the way down to the cellular level. The macro structure of your brain is largely predetermined, but the microwiring is not. As a consequence, past experience helps determine your future experiences and perceptions. Neuroconstruction explains how human infants are born without the ability to recognize a face but can develop that capacity within the first few days after birth. It also explains how early cultural experiences-for instance, how often your caregivers were in physical contact with you, and whether you slept alone in a crib or in a family bed-differentially shape the wiring of the brain. The theory of constructed emotion incorporates elements of all three flavors of construction. From social construction, it acknowledges the importance of culture and concepts. From psychological construction, it considers emotions to be constructed by core systems in the brain and body. And from neuroconstruction, it adopts the idea that experience wires the brain. The theory of constructed emotion tosses away the most basic assumptions of the classical view. For instance, the classical view assumes that happiness, anger, and other emotion categories each have a distinctive bodily fingerprint. In the theory of constructed emotion, variation is the norm. When you are angry, you might scowl, frown mildly or severely, shout, laugh, or even stand in eerie calmness, depending on what works best in the situation. Your heart rate likewise might increase, decrease, or stay the same, whatever is necessary to support the action you are performing. When you perceive someone else as angry, your perceptions are similarly varied. An emotion word such as “anger,” therefore, names a population of diverse instances, each one constructed to best guide action in the immediate circumstance. There is no single difference between anger and fear, because there's no single “Anger” and no single “Fear.” These ideas are inspired by William James, who wrote at length on the variability of emotional life, and by Charles Darwin's revolutionary idea that a biological category, such as a species, is a population of unique individuals. You can think about emotion categories like cookies. There are crisp ones, chewy ones, sweet ones, savory ones, large, small, flat, rounded, rolled, sandwiched, floured, flourless, and more. The members of the category “Cookie” vary tremendously but are deemed equivalent for some purpose: to be a tasty snack or dessert. Cookies need not look the same or be created with the same recipe; they are a population of diverse instances. Even within a more fine-grained category like “Chocolate Chip Cookie,” there is still diversity created by the type of chocolate, the amount of flour, the ratio of brown sugar to white sugar, the fat content of the butter, and the time spent chilling the dough. Likewise, any category of emotion such as “Happiness” or “Guilt” is filled with variety. The theory of constructed emotion dispenses with fingerprints not only in the body but also in the brain. It avoids questions that imply a neural fingerprint exists, like “Where are the neurons that trigger fear?” The word “where” has a built-in assumption that a particular set of neurons activates every time you and everyone else on the planet feel afraid. In the theory of constructed emotion, a category of emotion such as sadness, fear, or anger has no distinct brain location, and each instance of emotion is a whole-brain state to be studied and understood. Therefore we ask how, not where, emotions are made. The more neutral question, “How does the brain create an instance of fear?” does not presume a neural fingerprint behind the scenes, only that experiences and perceptions of fear are real and worthy of study. If instances of emotion are like cookies, then the brain is like a kitchen, stocked with common ingredients such as flour, water, sugar, and salt. Beginning with these ingredients, we can create diverse foods such as cookies, bread, cake, muffins, biscuits, and scones. Likewise, your brain has core “ingredients,” which we called core systems in chapter 1. They combine in complex ways, roughly analogous to recipes, to produce diverse instances of happiness, sadness, anger, fear, and so on. The ingredients themselves are multipurpose, not dedicated to emotions but participating in their construction. Instances of two different emotion categories, such as fear and anger, can be made from similar ingredients, just as cookies and bread both contain flour. Conversely, two instances of the same emotion category, like fear, will have some variation in their ingredients, just as some cookies have nuts and others do not. This phenomenon is our old friend degeneracy at work: different instances of fear are constructed by different combinations of the core systems throughout the brain. We can describe the instances of fear together by a pattern of brain activity, but this pattern is a statistical summary and need not describe any actual instance of fear. My kitchen analogy, like all analogies in science, has its limits. A brain network, as a core system, is not a “thing” like flour or salt. It's a collection of neurons that we view as a unit, statistically speaking, but only a subset of those neurons participate at any given time. If you have ten feelings of fear that involve a particular brain network, each feeling can involve different neurons from the network.* This is degeneracy at the network level. Additionally, cookies and bread are discrete, physical objects, whereas instances of emotion are momentary snapshots of continuous brain activity, and we merely perceive these snapshots as discrete events. Nevertheless, you may find the kitchen analogy useful to imagine how interacting networks produce diverse mental states. The core systems that construct the mind interact in complex ways, without any central manager or chef to run the show. However, these systems cannot be understood independently like the disassembled parts of a machine, or like so-called emotion modules or organs. That's because their interactions produce new properties that are not present in the parts alone. By analogy, when you bake bread with flour, water, yeast, and salt, a new product emerges from the complex, chemical interplay of the ingredients. Bread has its own emergent properties, like “crustiness” and “chewiness,” that are not present in its ingredients alone. In fact, if you try to identify all the ingredients by tasting the finished bread, you are in for a difficult time. Consider the salt: bread doesn't taste salty even though salt is absolutely essential. Similarly, an instance of fear cannot be reduced to mere ingredients. Fear is not a bodily pattern-just as bread is not flour-but emerges from the interactions of core systems. An instance of fear has irreducible, emergent properties not found in the ingredients alone, such as unpleasantness (as your car skids out of control on a slippery highway) or pleasantness (on an undulating rollercoaster). You cannot reverse-engineer a recipe for an instance of fear from a feeling of fear. Even if we did know the ingredients of emotion but studied them only in isolation, we'd get an inaccurate understanding of how they work together to construct emotion. If we study salt in isolation by tasting and weighing it, we will not understand how it contributes to the creation of bread. That's because salt interacts chemically with the other ingredients during baking: controlling yeast growth, shoring up the gluten in the dough, and, most importantly, enhancing flavor. To understand how salt transforms a recipe of bread, you must watch it work in context. Likewise, each ingredient of emotion must be studied in the context of the rest of the brain that influences it. This philosophy, known as holism, explains why I get different results each time I bake bread in my own kitchen, even using exactly the same recipe. I weigh every ingredient. I knead the dough for the same amount of time. I set the oven to the same temperature. I count the number of sprays of water I spritz into the oven to make the bread crusty. It's all very systematic, and yet, the result is sometimes lighter, sometimes heavier, sometimes sweeter. That's because baking has additional context that the recipe doesn't mention, like the amount of force I use in kneading, the humidity in the kitchen, and the precise temperature at which the dough rises. Holism explains why bread baked in my home in Boston is never as tasty as bread baked at my friend Ann's house in Berkeley, California. The Berkeley loaf has a superior flavor because of the different yeasts floating naturally in the air and the elevation above sea level. These additional variables can dramatically impact the end product, and expert bakers know this. Holism, emergent properties, and degeneracy are the very antithesis of fingerprints. After bodily and neural fingerprints, the next core assumption of the classical view we discard is how emotions evolved. The classical view proposes that we have a gift-wrapped animal brain-ancient emotion circuits passed down from ancestral animals, wrapped in uniquely human circuitry for rational thought-like icing on an already-baked cake. This view is often touted as “the” evolutionary theory of emotion, when in reality it is just one evolutionary theory. Construction incorporates the latest scientific findings about Darwinian natural selection and population thinking. For example, the many-to-one principle of degeneracy-many different sets of neurons can produce the same outcome-brings about greater robustness for survival. The one-to- many principle-any single neuron can contribute to more than one outcome -is metabolically efficient and increases the computational power of the brain. This kind of brain creates a flexible mind without fingerprints. The final major assumption of the classical view is that certain emotions are inborn and universal: all healthy people around the world are supposed to display and recognize them. The theory of constructed emotion, in contrast, proposes that emotions are not inborn, and if they are universal, it's due to shared concepts. What's universal is the ability to form concepts that make our physical sensations meaningful, from the Western concept “Sadness” to the Dutch concept Gezellig (a specific experience of comfort with friends), which has no exact English translation. By analogy, think about cupcakes and muffins. These two types of baked goods have the same shape and are based on the same set of ingredients: flour, sugar, shortening, and salt. Both have similar accompanying ingredients such as raisins, nuts, chocolate, carrots, and bananas. You cannot distinguish a muffin from a cupcake by its chemistry, in the way you can easily distinguish flour from salt, or a bee from a bird. And yet, one is a breakfast food while the other is a dessert. Their major distinguishing feature is the time of day at which they are eaten. This difference is entirely cultural and learned, not physical. The muffin-cupcake distinction is social reality: when objects in the physical world, like baked goods, take on additional functions by social agreement. Likewise, emotions are social reality. A physical event like a change in heart rate, blood pressure, or respiration becomes an emotional experience only when we, with emotion concepts that we have learned from our culture, imbue the sensations with additional functions by social agreement. From the widened eyes of a friend we may perceive fear or surprise, again depending on which concepts we use. We must not confuse physical reality, such as changes in heart rate or widened eyes, with the social reality of emotion concepts. Social reality is not just about words-it gets under your skin. If you perceive the same baked good as a decadent “cupcake” or a healthful “muffin,” research suggests that your body metabolizes it differently. Likewise, the words and concepts of your culture help to shape your brain wiring and your physical changes during emotion. Now that we've discarded so many assumptions of the classical view, we need a new vocabulary to discuss emotion. Familiar phrases like “facial expression” seem like common sense but tacitly assume that emotion fingerprints exist and that the face broadcasts emotion. You may have noticed in chapter 1 that I coined a more neutral term, facial configuration, because the English language has no word for “the set of facial muscle movements that the classical view treats as a coordinated unit.” I've also disambiguated the word “emotion,” because it could refer to a single instance of (say) feeling happy, or it could mean the whole category of happiness. When you construct an emotional experience of your own, I call it an instance of emotion. I refer to fear, anger, happiness, sadness, and so on, in general as emotion categories, because each word names a population of diverse instances, just like the word “cookie” names a population of diverse instances. If I were very strict, I would banish the phrase “an emotion” from our vocabulary so we don't imply its objective existence in nature, and always speak of instances and categories. But that's a bit too Orwellian, so I'll just take care to indicate when I mean an instance versus the category. Likewise, we do not “recognize” or “detect” emotions in others. These terms imply that an emotion category has a fingerprint that exists in nature, independent of any perceiver, waiting to be found. Any scientific question about “detecting” emotion automatically presumes a certain kind of answer. In the construction mindset, I speak of perceiving an instance of emotion. Perception is a complex mental process that does not imply a neural fingerprint behind the emotion, merely that an instance of emotion occurred somehow. I also avoid verbs like “triggering” emotion, and phrases like “emotional reaction” and emotions “happening to you.” Such wording implies that emotions are objective entities. Even when you feel no sense of agency when experiencing emotion, which is most of the time, you are an active participant in that experience. I also do not speak of perceiving someone's emotion “accurately.” Instances of emotion have no objective fingerprints in the face, body, and brain, so “accuracy” has no scientific meaning. It has a social meaning-we certainly can ask whether two people agree in their perceptions of emotion, or whether a perception is consistent with some norm. But perceptions exist within the perceiver. These linguistic guidelines might seem picky at first, but I hope you will come to see their importance. This new vocabulary is critical for understanding emotions and how they are made. At the beginning of this chapter, you looked upon a bunch of blobs, applied a collection of concepts, and the image of a bee materialized. This was no trick of your brain but a demonstration of how your brain works all the time-you actively participate in determining what you see, and most of the time you have no awareness you are doing so. The same processes that construct meaning from mere visual input provide a solution to the puzzle of human emotion. After conducting hundreds of experiments in my lab, and reviewing thousands more by other researchers, I've come to a profoundly unintuitive conclusion shared by a growing number of scientists. Emotions do not shine forth from the face nor from the maelstrom of your body's inner core. They don't issue from a specific part of the brain. No scientific innovation will miraculously reveal a biological fingerprint of any emotion. That's because our emotions aren't built-in, waiting to be revealed. They are made. By us. We don't recognize emotions or identify emotions: we construct our own emotional experiences, and our perceptions of others' emotions, on the spot, as needed, through a complex interplay of systems. Human beings are not at the mercy of mythical emotion circuits buried deep within animalistic parts of our highly evolved brain: we are architects of our own experience. These ideas do not match our experiences in daily life, where emotions seem to emerge like little bombs to disrupt whatever we were thinking or doing a moment before. Likewise, when we look at other people's faces and bodies, they seem to announce what their owners are feeling, without input or effort on our part, even when the owners themselves might be unaware. And when we look at our growling dogs and purring cats, we seem to detect their emotions too. But these personal experiences, no matter how compelling they may seem, do not reveal how the brain creates emotion, any more than our experience watching the sun move across the sky means that it revolves around the Earth. If you're a newcomer to construction, then ideas like “emotion concepts” and “emotion perceptions” and “facial configurations” are probably not second nature for you yet. To really understand emotions-in a way that is consistent with contemporary knowledge of evolution and neuroscience-you have to give up some deeply ingrained ways of thinking. To help you along that path, in the next chapter I give you some practice with construction. We'll take a close look at a famous scientific finding about emotion that many people consider a fact, and which propelled the classical view into a dominant position in psychology for five decades. We'll unpack it from the perspective of construction and watch certainty transform into doubt. Strap on your seatbelt."
  },
  {
    "index": 8,
    "level": 1,
    "start_page": 50,
    "end_page": 63,
    "title": "The Myth of Universal Emotions",
    "content": "The Myth of Universal Emotions. Take a look at the woman in figure 3-1, who is screaming in terror. Most people who were born and raised in a Western culture can effortlessly see this emotion in her face, even with no other context in the photograph. Figure 3-1: Perceiving terror in a woman's face Except . . she isn't feeling terror. This photograph actually shows Serena Williams immediately after she beat her sister Venus in the 2008 U.S. Open tennis finals. Turn to page 310 (appendix C) to see the full photograph. In context, the facial configuration takes on new meaning. If Williams's face subtly transformed before your eyes once you knew the context, you are not alone. This is a common experience. How did your brain accomplish this shift? The first emotion word I used, “terror,” caused your brain to simulate past facial configurations that you have seen of people feeling fear. You were almost certainly not aware of these simulations, but they shaped your perception of Williams's face. When I explained the photo's context-winning a crucial tennis match-your brain applied its conceptual knowledge of tennis and winning to simulate facial configurations that you've seen of people experiencing exultation. These simulations again influenced how you perceived Williams's face. In each case, your emotion concepts helped you make meaning from the image. In real life, we usually encounter faces in context, attached to bodies and associated with voices, smells, and other surrounding details. These details cue your brain to use particular concepts to simulate and construct your perception of emotion. That's why, in the full photo of Serena Williams, you perceive triumph, not terror. In fact, you depend on emotion concepts each time you experience another person as emotional. Knowledge of the concept “Sadness” is required to see a pout as sadness, knowledge of “Fear” to see widened eyes as fearful, and so on. According to the classical view, you shouldn't need concepts to perceive emotion, because emotions are supposed to have universal fingerprints that everyone around the world can recognize from birth. You're about to learn otherwise. By applying the theory of constructed emotion, combined with a little reverse engineering, you'll see that concepts are a key ingredient for perceiving emotions. We'll begin with the best experimental technique for demonstrating that certain emotions are universal: the basic emotion method used by Silvan Tomkins, Carroll Izard, and Paul Ekman (chapter 1). Then we'll systematically reduce the amount of emotion concept knowledge available to our test subjects. If their emotion perception becomes more and more impaired, then we've revealed that concepts are a critical ingredient to constructing emotion perceptions. We'll also learn how emotions can appear to be universally recognized under certain conditions, opening the door to a new, better understanding of how emotions are made. The basic emotion method, you may recall, was designed to study “emotion recognition.” On each trial of an experiment, a test subject views the photograph of a face, carefully posed by a trained actor, to represent the so- called expressions of certain emotions: smiling for happiness, scowling for anger, pouting for sadness, and so on. Accompanying the photo is a small set of English emotion words, depicted in figure 3-2, and the subject chooses the word that best matches the face. The same words appear trial after trial. In another version of the basic emotion method, a test subject selects the best of two or three photos to match a brief story or descriptive phrase, such as “Her mother died, and she feels very sad.” Figure 3-2: Basic emotion method: picking a word to match the face Test subjects from all around the world (Germany, France, Italy, United Kingdom, Scotland, Switzerland, Sweden, Greece, Estonia, Argentina, Brazil, and Chile) choose the expected word or face about 85 percent of the time on average. In cultures that are less like the United States, such as Japan, Malaysia, Ethiopia, China, Sumatra, and Turkey, subjects match faces and words slightly less well, responding as expected about 72 percent of the time. Hundreds of scientific studies have used these findings to conclude that facial expressions are universally recognized and therefore universally produced, even by people in faraway cultures that had little contact with Western civilization. Ultimately, these emotion “recognition” findings have been so well replicated over the last several decades that universal emotions seem to qualify as one of those rare bulletproof scientific facts, like the law of gravity. The thing is, universal laws have this annoying habit of losing their universality. Newton's law of universal gravitation was only universal until the theory of relativity showed that it wasn't. Watch what happens when we change the basic emotion method very slightly. Simply remove the list of emotion words. Test subjects must now freely label the same posed photographs from the dozens (or even hundreds) of emotion words that they know, as depicted in figure 3-3, instead of choosing a response from a short list of possibilities, as depicted in figure 3-2. When we do this, the subjects' success rate plummets. In one of the first free labeling studies ever conducted, subjects named the faces with the expected emotion words (or synonyms) only 58 percent of the time, and in subsequent studies the results were even lower. In fact, if you ask a more neutral question without referring to emotion at all-“What word best describes what's going on inside this person?”-the performance is even worse. Figure 3-3: Basic emotion method with the emotion words removed Why does such a small change make such a large difference? Because the short list of emotion words in the basic emotion method-a technique called a forced choice-is an unintentional cheat sheet for the test subjects. The words not only limit the available choices but also prompt the subjects to simulate facial configurations for the corresponding emotion concepts, preparing them to see certain emotions and not others. This process is called priming. When you first looked at Serena Williams's face, I primed you in a similar way by telling you the woman was “screaming in terror.” Your simulation influenced how you categorized the sensory input from her face to see a meaningful expression. Likewise, test subjects who see a list of emotion words are primed with (i.e., they simulate) the corresponding emotion concepts to categorize the posed faces they see. Your knowledge of concepts is a key ingredient for experiencing other people as emotional, and emotion words invoke this ingredient. And they could be largely responsible for producing what looks like universal emotion perception in the hundreds of studies that use the basic emotion method. Free labeling reduced the ingredient of concept knowledge, but only somewhat. In my own lab, we went a step further and removed all emotion words, printed or spoken. If the theory of constructed emotion is correct, then this small change should impair emotion perception even more. On each trial of an experiment, we presented subjects with two wordless photographs side by side (figure 3-4) and asked, “Do these people feel the same emotion?” The expected answer was merely yes or no. The results of this face-matching task were telling: subjects identified the expected matches only 42 percent of the time. Figure 3-4: Basic emotion method with no words at all. Do these faces show the same emotion? Next, our team reduced the ingredients even further. We actively interfered with our test subjects' access to their own emotion concepts, using a simple experimental technique. We had them repeat an emotion word like “anger” over and over. Eventually, the word becomes just a sound to the subject (“ang-gurr”) that's mentally disconnected from its meaning. This technique has the same effect as creating a temporary brain lesion, but it's completely safe and lasts less than one second. Then we immediately showed subjects two wordless faces side by side as before. Their performance dropped to a dismal 36 percent: nearly two-thirds of their yes/no decisions were incorrect!9 We also tested subjects with permanent brain lesions who suffer from a neurodegenerative illness called semantic dementia. These patients have trouble remembering words and concepts, including those for emotion. We gave them thirty-six photographs: six actors each posing six different basic emotion facial configurations (smiles depicting happiness, pouts depicting sadness, scowls depicting anger, wide-eyed gasping depicting fear, nose- wrinkling depicting disgust, and neutral). The patients then sorted the photos into piles in any way that was meaningful to them. They were unable to group all scowling faces into an anger pile, all pouting faces into a sadness pile, and so on. Instead, the patients produced only positive, negative, and neutral piles, an arrangement that merely reflects pleasant versus unpleasant feeling. We now had solid evidence that emotion concepts are necessary for seeing emotion in faces. Our findings are reinforced by research on young children and infants, whose emotion concepts aren't fully developed yet. A series of experiments by psychologists James A. Russell and Sherri C. Widen showed that two- and three-year-old children, when shown basic emotion facial configurations, are not able to freely label them until they possess clearly differentiated concepts for “Anger,” “Sadness,” “Fear,” and so on. Such young children use words like “sad,” “mad,” and “scared” interchangeably, like adults who exhibit low emotional granularity. It's not an issue of understanding the emotion words; even when these kids learn the meanings, they struggle to match up two pouting faces, whereas they find it easy to match a pouting face to the word “sad.” Results for infants are similarly telling. Infants who are four to eight months old, for example, can distinguish smiling faces from scowling faces. This ability, however, turned out not to be related to emotion per se. In those experiments, the posed faces for happiness showed teeth while those for anger did not, and that's the cue that infants picked up on. From this sequence of experiments-removing the list of emotion words, then using wordless photographs, then temporarily disabling emotion concepts, then testing lesion patients who can no longer process emotion concepts, and finally testing infants who don't yet possess clearly defined emotion concepts-a theme emerges. As emotion concepts become more remote, people do worse and worse at recognizing the emotions that the posed stereotypes are supposedly displaying. This progression is strong evidence that people see an emotion in a face only if they possess the corresponding emotion concept, because they require that knowledge to construct perceptions in the moment. To really see the power of emotion concepts, my lab visited a remote culture in Africa with little or no knowledge of Western practices and norms. With the fast pace of globalization, very few such isolated cultures exist anymore. My doctoral student Maria Gendron traveled to Namibia, Africa, to study emotion perception in a tribe known as the Himba, along with the cognitive psychologist Debi Roberson. Visiting the Himba was no simple task. Maria and Debi flew to South Africa and then drove for about twelve hours to their base camp in Opuwo, northern Namibia. From there, Debi, Maria, and their translator traveled many hours to reach individual villages near the Angola border, following tracks through the bush in an all-terrain vehicle, using the mountains and sun as landmarks. At night, they slept in a tent mounted on top of the car to avoid snakes and scorpions, which were numerous. I unfortunately could not join them, so they were equipped with a satellite phone and a generator so we could speak whenever a signal was available. Life among the Himba is decidedly non-Western. The people live mainly outdoors and in communal compounds made from saplings, mud, and dung. The men tend cattle day and night, while the women prepare food and care for the children. The children tend goats near the compound. The Himba speak a dialect of Otji-Herero, and they use no written language. The Himba's reaction to the research team was fairly low-key. The children were curious and would hang around in the early morning before their chores. Some of the women were initially unsure if Maria was female since she was wearing (from their perspective) boyish clothing, which led to some finger pointing and laughter. The men must have figured it out, however, because at one point, one proposed marriage. Maria's Namibian translator took the simple approach by explaining politely, in Otji-Herero, that Maria was “already married to another man with a very big gun.” Maria used the face-sorting experiment with the thirty-six posed faces. It doesn't depend on words at all, let alone emotion words, so it worked nicely across the language and culture barriers. We'd created a set of photos using dark-skinned actors, because our originals featured Western faces that didn't look like Himba tribespeople. Our Himba subjects understood the task immediately, as we had hoped, and were able to sort the faces spontaneously by actor. When asked to sort the faces by emotion, the Himba clearly diverged from Westerners. They placed all the smiling faces into a single pile, and most of the wide-eyed faces into a second pile, but then made many different piles with mixtures of the remaining faces. If emotion perception is universal, then the Himba subjects should have sorted the photographs into six piles. When we asked our Himba subjects to freely label their piles, smiling faces were not “happy” (ohange) but “laughing” (ondjora). Wide- eyed faces were not “fearful” (okutira) but “looking” (tarera). In other words, the Himba participants categorized facial movements as behaviors rather than inferring mental states or feelings. Overall, our Himba subjects showed no evidence of universal emotion perception. And since we omitted all reference to English emotion concepts in our experiments, those concepts are a prime suspect for why the basic emotion method appears to give evidence of universality. Figure 3-5: Maria Gendron (right) working with a Himba subject in Namibia, beneath a tent attached to Maria's truck There was still one mystery remaining, however: another group of researchers, led by psychologist Disa A. Sauter, had visited the Himba a few years earlier and reported evidence of universal emotion “recognition.” Sauter and her colleagues brought the basic emotion method to the Himba using vocal sounds (laughs, grunts, snorts, sighs, etc.) instead of photos of posed faces. In their experiment, they offered brief emotion stories (translated into Otji-Herero) and asked their Himba participants to select which of two vocalizations matched each story. The Himba did this well enough that Sauter and her colleagues concluded that emotion perception was universal. We were unable to replicate these results with a different group of Himba participants, even using the published method and the same translator as Sauter did. Maria also asked another group of Himba subjects to freely label the vocal sounds, without accompanying stories, and again, only the laughing sounds were categorized as expected (although they labeled the sounds as “laughing” rather than “happy”). So why did Sauter and her team observe universality when we did not?15 In late 2014, Sauter and her colleagues inadvertently solved the mystery. They revealed that their experiment included an extra step not reported in their original publication: a step that's rich in conceptual knowledge. After the Himba participants heard an emotion story but before they listened to any sound pairs, they were asked to describe how the target person in the story was feeling. To help them in this task, Sauter and colleagues “allowed participants to listen several times to a given recorded story (if needed), until they could explain the intended emotion in their own words.” Whenever Himba participants described something other than the English emotion concept, they received negative feedback and were told to try again. Test subjects who were unable to provide the expected description were disqualified from the experiment. In effect, Himba participants were not permitted to listen to any sounds, let alone pick the ones that matched the story, until they had learned the corresponding English emotion concepts. When we attempted to replicate Sauter and colleagues' experiment, we used only the methods in their published paper, without the extra, unreported step, so our Himba test subjects did not have the opportunity to learn English emotion concepts before listening to the vocalizations. There was one other difference between our experimental method and the one used by Sauter and her colleagues. Once a Himba participant had explained the emotion concept satisfactorily-let's say it was sadness- Sauter's team played a pair of sounds, such as a cry and a laugh, and the subject chose the better match for sadness. The participant then heard more pairs of sounds, each one containing a cry: perhaps a cry and a sigh, then a cry and a scream, and so on. From each pair, the participant selected one sound as the better match for sadness. If the Himba participants were not confident of the link between cries and sadness at the beginning of these trials, they certainly were by the end. Our experiments avoided this problem. In each trial, Maria would read a story (through the translator), then present a pair of sounds, and then have the participant choose the best match. Trials were in random order (e.g., a sadness trial, followed by an anger trial, followed by a happiness trial, and so on), which is a standard way to avoid learning within this type of experiment. We saw no evidence of universality. There is one emotion category that people seem able to perceive without the influence of emotion concepts: happiness. Regardless of the experimental method used, people in numerous cultures agree that smiling faces and laughing voices express happiness. So “Happy” might be the closest thing we have to a universal emotion category with a universal expression. Or it might not. For one thing, “Happiness” is usually the only pleasant emotion category that is tested using the basic emotion method, so it's trivial for subjects to distinguish it from the negative categories. And consider this fun fact: the historical record implies that ancient Greeks and Romans did not smile spontaneously when they were happy. The word “smile” doesn't even exist in Latin or Ancient Greek. Smiling was an invention of the Middle Ages, and broad, toothy-mouthed smiles (with crinkling at the eyes, named the Duchenne smile by Ekman) became popular only in the eighteenth century as dentistry became more accessible and affordable. The classics scholar Mary Beard summarizes the nuances of the point: This is not to say that Romans never curled up the edges of their mouths in a formation that would look to us much like a smile; of course they did. But such curling did not mean very much in the range of significant social and cultural gestures in Rome. Conversely, other gestures, which would mean little to us, were much more heavily freighted with significance. Perhaps sometime in the last few hundred years, smiling became a universal, stereotyped gesture symbolizing happiness.* Or . . perhaps smiling in happiness is simply not universal. Emotion concepts are the secret ingredient behind the success of the basic emotion method. These concepts make certain facial configurations appear universally recognizable as emotional expressions when, in fact, they're not. Instead, we all construct perceptions of each other's emotions. We perceive others as happy, sad, or angry by applying our own emotion concepts to their moving faces and bodies. We likewise apply emotion concepts to voices and construct the experience of hearing emotional sounds. We simulate with such speed that emotion concepts work in stealth, and it seems to us as if emotions are broadcast from the face, voice, or any other body part, and we merely detect them. A perfectly reasonable question for you to ask at this point is: how can my colleagues and I have the audacity to claim that our handful of experiments disconfirm hundreds of others that found evidence that emotions are universally recognized in expressions? The psychologist Dacher Keltner, for example, estimates that “there are a zillion data points on a perspective that conforms to Ekman.”19 The answer is that most of these zillion experiments use the basic emotion method, which you have just seen contains a secret stash of concept knowledge about emotion. If humans actually had an inborn ability to recognize emotional expressions, then removing the emotion words from the method should not matter . . but it did, every single time. There is very little doubt that emotion words have a powerful influence in experiments, instantly casting into doubt the conclusions of every study ever performed that used the basic emotion method. To date, my lab has made two expeditions to Namibia and one to Tanzania (visiting a hunter-gatherer group called the Hadza) with consistent results. The social psychologist José-Miguel Fernández-Dols has also replicated our results in an isolated culture on the Trobriand Islands in New Guinea. So, science now has a reasonable, alternative explanation for those “zillions of data points.” The basic emotion method guides people to construct perceptions of Western-style emotions. That is, emotion perception is not innate but constructed. If you look closely at the original cross-cultural experiments from the 1960s, you can see clues that the conceptual elements within the basic emotion method pushed the results toward the appearance of universality. Of the seven samples using test subjects from remote cultures, the four that used the basic emotion method provided strong evidence for universality, but the remaining three used free labeling and did not show evidence of universality. These three contrary samples were not published in peer-reviewed journals but only as book chapters-a lesser form of publishing in the world of academia-and are rarely cited. As a result, the four samples supporting universality were lauded as a major breakthrough in research on our underlying human nature and set the stage for the research avalanche to come. Hundreds of subsequent studies employed the basic emotion method with forced choice, largely in cultures that had exposure to Western cultural practices and norms, taking a key condition for universality out of the experimental design but still claiming it as fact. This explains why today, many scientists and the public fundamentally misunderstand what is known about “emotional expressions” and “emotion recognition” from a scientific point of view. What might the science of emotion look like today had someone drawn different conclusions from those original studies? Consider Ekman's account of his first visit to the Fore tribe in New Guinea: I asked them to make up a story about each facial expression [photograph]. “Tell me what is happening now, what happened before to make the person show this expression, and what is going to happen next.” It was like pulling teeth. I am not certain whether it was the translation process, or the fact that they have no idea what it was I wanted to hear or why I wanted them to do this. Perhaps making up stories about strangers was just something the Fore didn't do. Ekman might be right, but it is also possible that the Fore did not understand or accept the concept of a facial “expression,” which implies an internal feeling that seeks release in a set of facial movements. Not all cultures understand emotions as internal mental states. Himba and Hadza emotion concepts, for example, appear to be more focused on actions. This is also true of certain Japanese emotion concepts. The Ifaluk of Micronesia consider emotions as transactions between people. To them, anger is not a feeling of rage, a scowl, a pounding fist, or a loud yelling voice, all within the skin of one person, but a situation in which two people are engaged in a script-a dance, if you will-around a common goal. In the Ifaluk view, anger does not “live” inside either participant. When you look at the development and history of the basic emotion method, there's a surprising amount to criticize from a scientific standpoint. Over twenty years ago, the psychologist James A. Russell catalogued many of the concerns. And remember that the “six basic facial expressions” were not a scientific discovery; the Western architects of the basic emotion method stipulated them, actors posed them, and a science was built around them. There is no known validity to these particular facial poses, and studies that use more objective methods like facial EMG and facial coding do not find evidence that people routinely make these movements in real life during episodes of emotion. Yet scientists continue to use the basic emotion method regardless. After all, it produces very consistent results. Each time a scientific “fact” is overturned it leads to new avenues for discovery. The physicist Albert Michelson won a Nobel Prize in 1907 for disproving a conjecture made by Aristotle, that light travels through empty space via a hypothetical substance called luminiferous ether. His detective work set the stage for Albert Einstein's theory of relativity. In our case, we've cast substantial doubt on the evidence for universal emotions. They only appear to be universal under certain conditions-when you give people a tiny bit of information about Western emotion concepts, intentionally or not. These observations, and others like them, set the stage for the new theory of emotion that you are about to learn. So Tomkins, Ekman, and their colleagues did contribute to a remarkable discovery. It just wasn't the discovery that they expected. The many cross-cultural studies employing the basic emotion method suggest something else exciting: it may be easy to teach emotion concepts across cultural boundaries, even unintentionally. Such a worldwide understanding would be hugely beneficial. If Saddam Hussein's half-brother had only understood the American emotion concept of anger, he might have perceived anger in Secretary of State James Baker, which might have averted the first Gulf War with the United States, saving thousands of lives. Given how easy it is to teach emotion concepts by accident, there is also a danger in using Western stereotypes of emotion in cultural research. For instance, an ongoing series of studies called the Universal Expressions Project is attempting to document what is universal about emotional expressions in the face, body, and voice. So far, they've identified “about 30 facial expressions and 20 vocal expressions that are very similar around the world.” The catch is that the project uses only the basic emotion method, so it's investigating universality with a tool that cannot provide such evidence. (Also, they're asking people to pose what they believe are their cultural expressions, which is not the same thing as observing actual body movements during emotion.) More importantly, if the project reaches its goal, everyone in the world might learn the Western stereotypes for emotions. In the long run, scientists who still subscribe to the basic emotion method are very likely helping to create the universality that they believe they are discovering. Closer to home, if people believe that a face alone displays emotion, it can lead to serious mistakes with damaging repercussions. In one case, this belief changed the course of a U.S. presidential election. In 2003-2004, Governor Howard Dean of Vermont was seeking the Democratic nomination for president of the United States, an honor that ultimately went to Senator John Kerry of Massachusetts. Voters saw a lot of negative campaigning that season, and one of the most misleading examples was a video of Dean taken during a speech. In a snippet of video that went viral, Dean's face was shown alone, without context, and he looked furious. But if you watched the entire video in context, it becomes obvious that Dean was not enraged but excited, firing up the crowd with his enthusiasm. The snippet circulated on the news, spread widely, and, ultimately, Dean dropped out of the race. We can only wonder what might have happened if viewers had understood how emotions are made when they saw those misleading images. Guided by a constructionist approach, scientists continue to replicate my lab's findings in other cultures (data from China, East Africa, Melanesia, and other regions are looking promising at press time). As they do, we are speeding the paradigm shift to a new understanding of emotion that goes beyond Western stereotypes. We can cast aside questions like “How accurately can you recognize fear?” and instead study the variety of facial movements that people actually make in fear. We can also try to understand why people hold stereotypes about facial configurations in the first place, and what their value might be. The basic emotion method has shaped the scientific landscape and influenced public understanding of emotion. Thousands of scientific studies claim that emotions are universal. Popular books, magazine articles, radio broadcasts, and TV shows casually assume that everyone makes and recognizes the same facial configurations as expressions of emotion. Games and books teach preschool children these allegedly universal expressions. International political and business negotiation strategies are likewise based on this assumption. Psychologists assess and treat emotion deficits in people suffering from mental illness using similar methods. The growing economy of emotion-reading gadgets and apps also assumes universality, as if emotions can be read in the face or in patterns of bodily changes in the absence of context, as easily as reading words on a page. The sheer amount of time, effort, and money going into these efforts is mind-boggling. But what if the fact of universal emotions isn't a fact at all? What if it's evidence for something else entirely . . namely, our ability to use concepts to shape perception? This is the crux of the theory of constructed emotion: a full-fledged, alternative explanation for the mystery of human emotion that does not rely on universal emotion fingerprints. The next four chapters dive into the details of this theory and the scientific evidence that supports it."
  },
  {
    "index": 9,
    "level": 1,
    "start_page": 64,
    "end_page": 90,
    "title": "The Origin of Feeling",
    "content": "The Origin of Feeling. Think about the last time you were awash in pleasure. I don't necessarily mean sexual pleasure but everyday delights: gazing at a vivid sunrise, sipping a cold glass of water when you are hot and sweaty, or enjoying a brief moment of peace at the end of a troubling day. Now contrast this with feeling unpleasant, like the last time you were sick with a cold, or just after an argument with a close friend. Pleasure and displeasure feel qualitatively different. You and I might not agree that a specific object or event produces pleasure or displeasure-I find walnuts delicious whereas my husband calls them an offense against nature-but each of us can, in principle, distinguish one from the other. These feelings are universal, even as emotions like happiness and anger are not, and they flow like a current through every waking moment of your life. Simple pleasant and unpleasant feelings come from an ongoing process inside you called interoception. Interoception is your brain's representation of all sensations from your internal organs and tissues, the hormones in your blood, and your immune system. Think about what's happening within your body right this second. Your insides are in motion. Your heart sends blood rushing through your veins and arteries. Your lungs fill and empty. Your stomach digests food. This interoceptive activity produces the spectrum of basic feeling from pleasant to unpleasant, from calm to jittery, and even completely neutral. Interoception is in fact one of the core ingredients of emotion, just as flour and water are core ingredients of bread, but these feelings that come from interoception are much simpler than full-blown emotional experiences like joy and sadness. In this chapter, you'll learn how interoception works, and how it contributes to emotional experiences and perceptions. We'll need a little background first about the brain in general and how it budgets the energy in your body to keep you alive and well. That will prepare you to understand the gist of interoception, which is the origin of feeling. After that, we'll discover the unexpected and frankly astonishing influence that interoception has over your thoughts, decisions, and actions every day. Whether you're a generally calm person, floating unperturbed in a stream of tranquility, unaffected by the vicissitudes of life; a more reactive person awash in a river of agony and ecstasy, easily moved by every little change in your surroundings; or somewhere in between, the science behind interoception, grounded in the wiring of your brain, will help you see yourself in a new light. It also demonstrates that you're not at the mercy of emotions that arise unbidden to control your behavior. You are an architect of these experiences. Your river of feelings might feel like it's flowing over you, but actually you're the river's source. For the bulk of human history, the most learned members of our species have wildly underestimated the human brain's capabilities. This is understandable, since your brain occupies only about 2 percent of your body mass, and it looks like a blob of gray gelatin. Ancient Egyptians deemed it a useless organ and tugged it out of dead pharaohs through the nose. The brain eventually earned its due as the seat of the mind, but it still received insufficient credit for its remarkable abilities. Brain regions were thought to be primarily “reactive,” spending most of their time dormant and awakening to fire only when a stimulus arrives from the outside world. This stimulus-response view is simple and intuitive, and, in fact, neurons in your muscles work this way, lying still until stimulated, then firing to make a muscle cell respond. So scientists assumed that neurons in the brain operated similarly. When a gigantic snake slithers across your path, this stimulus was thought to launch a chain reaction in your brain. Neurons would fire in sensory regions, causing neurons in cognitive or emotional regions to fire, causing neurons in motor regions to fire, and then you'd react. The classical view typifies this mindset: when the snake appears, a “fear circuit” in your brain, which is usually in the “off” position, supposedly flips into the “on” position, causing preset changes in your face and body. Your eyes widen, you scream, and you run away. The stimulus-response view, while intuitive, is misguided. Your brain's 86 billion neurons, which are connected into massive networks, never lie dormant awaiting a jump-start. Your neurons are always stimulating each other, sometimes millions at a time. Given enough oxygen and nutrients, these huge cascades of stimulation, known as intrinsic brain activity, continue from birth until death. This activity is nothing like a reaction triggered by the outside world. It's more like breathing, a process that requires no external catalyst. The intrinsic activity in your brain is not random; it is structured by collections of neurons that consistently fire together, called intrinsic networks. These networks operate somewhat like sports teams. A team has a pool of players; at any given moment, some players are in the game and others sit on the bench, ready to jump in when needed. Likewise, an intrinsic network has a pool of available neurons. Each time the network does its job, different groupings of its neurons play (fire) in synchrony to fill all the necessary positions on the team. You might recognize this behavior as degeneracy, because different sets of neurons in the network are producing the same basic function. Intrinsic networks are considered one of neuroscience's great discoveries of the past decade. You might wonder what this hotbed of continuous, intrinsic activity is accomplishing, besides keeping your heart beating, your lungs breathing, and your other internal functions working smoothly. In fact, intrinsic brain activity is the origin of dreams, daydreams, imagination, mind wandering, and reveries, which we collectively called simulation in chapter 2. It also ultimately produces every sensation you experience, including your interoceptive sensations, which are the origins of your most basic pleasant, unpleasant, calm, and jittery feelings. To understand why this is the case, let's take your brain's perspective for a moment. Like those ancient, mummified Egyptian pharaohs, the brain spends eternity entombed in a dark, silent box. It cannot get out and enjoy the world's marvels directly; it learns what is going on in the world only indirectly via scraps of information from the light, vibrations, and chemicals that become sights, sounds, smells, and so on. Your brain must figure out the meaning of those flashes and vibrations, and its main clues are your past experiences, which it constructs as simulations within its vast network of neural connections. Your brain has learned that a single sensory cue, such as a loud bang, can have many different causes-a door being slammed, a bursting balloon, a hand clap, a gunshot. It distinguishes which of these different causes is most relevant only by their probability in different contexts. It asks, Which combination of my past experiences provides the closest match to this sound, given this particular situation with its accompanying sights, smells, and other sensations?7 And so, trapped within the skull, with only past experiences as a guide, your brain makes predictions. We usually think of predictions as statements about the future, like “It's going to rain tomorrow” or “The Red Sox will win the World Series” or “You will meet a tall, dark stranger.” But here, I'm focusing on predictions at a microscopic scale as millions of neurons talk to one another. These neural conversations try to anticipate every fragment of sight, sound, smell, taste, and touch that you will experience, and every action that you will take. These predictions are your brain's best guesses of what's going on in the world around you, and how to deal with it to keep you alive and well. At the level of brain cells, prediction means that the neurons over here, in this part of your brain, tweak the neurons over there, in that part of your brain, without any need for a stimulus from the outside world. Intrinsic brain activity is millions and millions of nonstop predictions. Through prediction, your brain constructs the world you experience. It combines bits and pieces of your past and estimates how likely each bit applies in your current situation. This happened when you simulated the bee in chapter 2; once you'd seen the full photograph, your brain had a new experience to draw on, so it could instantly construct a bee from the blobs. And right now, with each word that you read, your brain is predicting what the next word will be, based on probabilities from your lifetime of reading experience. In short, your experience right now was predicted by your brain a moment ago. Prediction is such a fundamental activity of the human brain that some scientists consider it the brain's primary mode of operation. Predictions not only anticipate sensory input from outside the skull but explain it. Let's do a quick thought experiment to see how this works. Keep your eyes open and imagine a red apple, just like you did in chapter 2. If you are like most people, you will have no problem conjuring some ghostly image of a round, red object in your mind's eye. You see this image because neurons in your visual cortex have changed their firing patterns to simulate an apple. If you were in the fruit section of a supermarket right now, these same firing neurons would be a visual prediction. Your past experience in that context (a supermarket aisle) leads your brain to predict that you would see an apple rather than a red ball or the red nose of a clown. Once the prediction is confirmed by an actual apple, the prediction has, in effect, explained the visual sensations as being an apple. If your brain predicts perfectly-say, you predicted a McIntosh apple as you came upon a display of them-then the actual visual input of the apple, captured by your retina, carries no new information beyond the prediction. The visual input merely confirms the prediction is correct, so the input needn't travel any further in the brain. The neurons in your visual cortex are already firing as they should be. This efficient, predictive process is your brain's default way of navigating the world and making sense of it. It generates predictions to perceive and explain everything you see, hear, taste, smell, and touch. Your brain also uses prediction to initiate your body's movements, like reaching your arm out to pick up an apple or dashing away from a snake. These predictions occur before you have any conscious awareness or intent about moving your body. Neuroscientists and psychologists call this phenomenon “the illusion of free will.” The word “illusion” is a bit of a misnomer; your brain isn't acting behind your back. You are your brain, and the whole cascade of events is caused by your brain's predictive powers. It's called an illusion because movement feels like a two-step process-decide, then move-when in fact your brain issues motor predictions to move your body well before you become aware of your intent to move. And even before you actually encounter the apple (or the snake)!11 If your brain were merely reactive, it would be too inefficient to keep you alive. You are always being bombarded by sensory input. One human retina transmits as much visual data as a fully loaded computer network connection in every waking moment; now multiply that by every sensory pathway you have. A reactive brain would bog down like your Internet connection does when too many of your neighbors are streaming movies from Netflix. A reactive brain would also be too expensive, metabolically speaking, because it would require more interconnections than it could maintain. Evolution literally wired your brain for efficient prediction. As an example of this wiring in your visual system, have a look at figure 4-1, which shows how your brain predicts far more visual input than it receives. Consider what this means: events in the world, such as a snake slithering at your feet, merely tune your predictions, roughly the way that your breathing is tuned by exercise. Right now, as you read these words and understand what they mean, each word barely perturbs your massive intrinsic activity, like a small stone skipping on a rolling ocean wave. In brain-imaging experiments, when we show photographs to test subjects or ask them to perform tasks, only a small portion of the signal we measure is due to the photos and tasks; most of the signal represents intrinsic activity. You might think that your perceptions of the world are driven by events in the world, but really, they are anchored in your predictions, which are then tested against those little skipping stones of incoming sensory input. Figure 4-1: Your brain contains complete maps of your visual field. One map is located in your primary visual cortex, known as V1. If your brain merely reacted to the light waves that hit your retina and traveled to primary visual cortex (V1) via your thalamus, then it would have many neurons to carry that visual information to V1. But it has far fewer than one would expect (top image), and ten times as many projections going in the other direction, carrying visual predictions from V1 to the thalamus (center image). Likewise, 90 percent of all connections coming into V1 (lower image) carry predictions from neurons in other parts of cortex. Only a small fraction carries visual input from the world. Through prediction and correction, your brain continually creates and revises your mental model of the world. It's a huge, ongoing simulation that constructs everything you perceive while determining how you act. But predictions aren't always correct, when compared to actual sensory input, and the brain must make adjustments. Sometimes a skipping stone is large enough to make a splash. Consider this sentence: Once upon a time, in a magical kingdom far beyond the most distant mountains, there lived a beautiful princess who bled to death. Did you find the last three words unexpected? That's because your brain predicted incorrectly based on its stored knowledge of fairy tales-it made a prediction error-and then adjusted its prediction in the blink of an eye based on the final words: a few skipping stones of visual information. The same process happens when you mistake a stranger's face for someone you know, or step off a moving walkway in an airport and feel surprised by the change in your pace. Your brain computes prediction errors speedily by comparing the prediction to actual sensory input, and then it reduces the prediction error quickly and efficiently. For example, your brain can change the prediction: the stranger looks different from your friend; the moving walkway came to its end. Prediction errors aren't problems. They're a normal part of the operating instructions of your brain as it takes in sensory input. Without prediction error, life would be a yawning bore. Nothing would be surprising or novel, and therefore your brain would never learn anything new. Most of the time, at least when you are an adult, your predictions aren't too far off-base. If they were, you would go through life feeling constantly startled, uncertain . . or hallucinating. Your brain's colossal, ongoing storm of predictions and corrections can be thought of as billions of tiny droplets. Each little drop represents a certain wiring arrangement that I'll call a prediction loop, shown in figure 4-2. This arrangement holds at many levels throughout your entire brain. Neurons participate in prediction loops with other neurons. Brain regions participate in prediction loops with other regions. Your multitudes of prediction loops run in a massive parallel process that continues nonstop for your whole life, creating the sights, sounds, smells, tastes, and touches that make up your experiences and dictate your actions. Figure 4-2: Structure of a prediction loop. Predictions become simulations of sensations and movement. These simulations are compared to actual sensory input from the world. If they match, the predictions are correct and the simulation becomes your experience. If they don't match, your brain must resolve the errors. Suppose you are playing baseball. Someone throws the ball in your direction, and you reach out and catch it. Most likely, you'd experience this as two events: seeing a ball and then catching it. If your brain actually reacted like this, however, baseball couldn't exist as a sport. Your brain has about half a second to prepare to catch a baseball in a typical game. This isn't enough time to process the visual input, calculate where the ball will land, make the decision to move, coordinate all the muscle movements, and send the motor commands to move you into position for the catch. Prediction makes the game possible. Your brain launches predictions well before you consciously see the ball, just like it predicts a red apple in the grocery store, using your past experience. As each prediction propagates through millions of prediction loops, your brain simulates the sights, sounds, and other sensations that the predictions represent, as well as the actions you will take to catch the ball. Your brain then compares the simulations to actual sensory input. If they match . . success! The prediction is correct, and the sensory input proceeds no further into your brain. Your body is now prepared to catch the ball, and your movement is based on your prediction. Finally, you consciously see the ball, and you catch it. That's what happens when the prediction is correct, like when I throw a baseball to my husband, who has some skill at the sport. On the other hand, when he tosses the ball back to me, my brain's predictions aren't particularly good, since I cannot play baseball to save my life. My predictions become simulations of the catch I hope to make, but when they get compared to the information I actually receive from the world, they do not match. This is a prediction error. My brain then adjusts its earlier predictions so that I can (in theory) catch the ball. The entire prediction loop process repeats, predicting and correcting many times as the ball hurtles toward me. All of this activity happens in milliseconds. In the end, most likely, I become aware of the ball sailing past my outstretched arm. When prediction errors occur, the brain can resolve them in two general ways. The first, which we've just seen in my lame attempt to catch a baseball, is that the brain can be flexible and change the prediction. In this situation, my motor neurons would adjust my body movements, and my sensory neurons would simulate different sensations, leading to further predictions involving prediction loops. I could dive for the ball, for example, when it is in a different place than I expected it to be. The brain's second alternative is to be stubborn and stick with the original prediction. It filters the sensory input so it's consistent with the prediction. In this situation, I could be standing in a baseball field but daydreaming (predicting and simulating) as the ball sails toward me. Even though the ball is fully within my visual field, I don't notice it until it thumps at my feet. Another example would be the food-filled diapers at my daughter's disgusting foods birthday party: our guests' prediction of a baby poo aroma dominated their actual sensory input of mashed carrots. In short, the brain is not a simple machine reacting to stimuli in the outside world. It's structured as billions of prediction loops creating intrinsic brain activity. Visual predictions, auditory predictions, gustatory (taste) predictions, somatosensory (touch) predictions, olfactory (smell) predictions, and motor predictions travel throughout the brain, influencing and constraining each other. These predictions are held in check by sensory inputs from the outside world, which your brain may prioritize or ignore. If this talk of prediction and correction seems unintuitive, think about it this way: your brain works like a scientist. It's always making a slew of predictions, just as a scientist makes competing hypotheses. Like a scientist, your brain uses knowledge (past experience) to estimate how confident you can be that each prediction is true. Your brain then tests its predictions by comparing them to incoming sensory input from the world, much as a scientist compares hypotheses against data in an experiment. If your brain is predicting well, then input from the world confirms your predictions. Usually, however, there is some prediction error, and your brain, like a scientist, has some options. It can be a responsible scientist and change its predictions to respond to the data. Your brain can also be a biased scientist and selectively choose data that fits the hypotheses, ignoring everything else. Your brain can also be an unscrupulous scientist and ignore the data altogether, maintaining that its predictions are reality. Or, in moments of learning or discovery, your brain can be a curious scientist and focus on input. And like the quintessential scientist, your brain can run armchair experiments to imagine the world: pure simulation without sensory input or prediction error. Figure 4-3: A variety of mental phenomena can be understood as a combination of prediction and sensory input. The balance between prediction and prediction error, shown in figure 4-3, determines how much of your experience is rooted in the outside world versus inside your head. As you can see, in many cases, the outside world is irrelevant to your experience. In a sense, your brain is wired for delusion: through continual prediction, you experience a world of your own creation that is held in check by the sensory world. Once your predictions are correct enough, they not only create your perception and action but also explain the meaning of your sensations. This is your brain's default mode. And marvelously, your brain does not just predict the future: it can imagine the future at will. As far as we know, no other animal brain can do that. Your brain is always predicting, and its most important mission is predicting your body's energy needs, so you can stay alive and well. These crucial predictions, and their associated prediction error, turn out to be a key ingredient for making emotions. For hundreds of years, scholars believed that emotional “reactions” were caused by certain brain regions. As you'll now discover, those brain regions do the opposite of what everyone expected, helping to make emotion in a way that overturns centuries of scientific belief. And once again, the story begins with movement-not the large-scale movements of a baseball game, but the inner motion of your body. Any movement of your body is accompanied by movement in your body. When you shift position quickly to catch a baseball, you have to breathe more deeply. To escape from a poisonous snake, your heart pumps blood faster through dilated blood vessels to rush glucose to your muscles, which increases your heart rate and changes your blood pressure. Your brain represents the sensations that result from this inner motion; this representation, you may remember, is called interoception. Your inner-body movements, and their interoceptive consequences, occur every moment of your life. Your brain must keep your heart beating and your blood pumping and your lungs breathing and your glucose metabolizing even when you are not playing sports or fleeing from a snake, even when you are sleeping or resting. Interoception is therefore continuous, just as the mechanics of hearing and vision are always operating, even when you aren't actively listening or looking at anything in particular. From your brain's point of view, locked inside the skull, your body is just another part of the world that it must explain. Your pumping heart, your expanding lungs, and your changing temperature and metabolism send sensory input to your brain that is noisy and ambiguous. A single interoceptive cue, such as a dull ache in your abdomen, could mean a stomachache, hunger, tension, an overly tight belt, or a hundred other causes. Your brain must explain bodily sensations to make them meaningful, and its major tool for doing so is prediction. So, your brain models the world from the perspective of someone with your body. Just as your brain predicts the sights, smells, sounds, touches, and tastes from the world in relation to the movements of your head and limbs, it also predicts the sensory consequences of movements inside your body. Most of the time, you're unaware of the miniature maelstrom of movement inside you. (When's the last time you thought, “Hmm, my liver seems to be producing a lot of bile today”?) Of course, there are times when you directly feel a headache, a full stomach, or your heart pounding in your chest. But your nervous system isn't built for you to experience these sensations with precision, which is fortunate, because otherwise they'd overwhelm your attention. Usually, you experience interoception only in general terms: those simple feelings of pleasure, displeasure, arousal, or calmness that I mentioned earlier. Sometimes, however, you experience moments of intense interoceptive sensations as emotions. That is a key element of the theory of constructed emotion. In every waking moment, your brain gives your sensations meaning. Some of those sensations are interoceptive sensations, and the resulting meaning can be an instance of emotion. In order to understand how emotions are made, you'll need to understand a bit about some key brain regions. Interoception is actually a whole-brain process, but several regions work together in a special way that is critical for interoception. My lab has discovered that these regions form an interoceptive network that is intrinsic in your brain, analogous to your networks for vision, hearing, and other senses. The interoceptive network issues predictions about your body, tests the resulting simulations against sensory input from your body, and updates your brain's model of your body in the world. To simplify our discussion drastically, I'll describe this network as having two general parts with distinct roles. One part is a set of brain regions that send predictions to the body to control its internal environment: speed up the heart, slow down breathing, release more cortisol, metabolize more glucose, and so on. We'll call them your body-budgeting regions.* The second part is a region that represents sensations inside your body, called your primary interoceptive cortex. Figure 4-4: The cortical regions of the interoceptive network. Body-budgeting regions are dark gray, and primary interoceptive cortex is given its technical name, the posterior insula. Subcortical regions of this network are not shown. The interoceptive network encompasses two networks commonly known as the salience network and the default mode network. Visual cortex is shown for reference. The two parts of your interoceptive network participate in a prediction loop. Each time your body-budgeting regions predict a motor change, like speeding up the heart, they also predict the sensory consequences of that change, like a pounding feeling in your chest. These sensory predictions are called interoceptive predictions, and they flow to your primary interoceptive cortex, where they are simulated in the usual way. Primary interoceptive cortex also receives sensory inputs from the heart, lungs, kidneys, skin, muscles, blood vessels, and other organs and tissue as they perform their usual duties. The neurons in your primary interoceptive cortex compare the simulation to the incoming sensory input, computing any relevant prediction error, completing the loop, and ultimately creating interoceptive sensations. Your body-budgeting regions play a vital role in keeping you alive. Each time your brain moves any part of your body, inside or out, it spends some of its energy resources: the stuff it uses to run your organs, your metabolism, and your immune system. You replenish your body's resources by eating, drinking, and sleeping, and you reduce your body's spending by relaxing with loved ones, even having sex. To manage all of this spending and replenishing, your brain must constantly predict your body's energy needs, like a budget for your body. Just as a company has a finance department that tracks deposits and withdrawals and moves money between accounts, so its overall budget stays in balance, your brain has circuitry that is largely responsible for your body budget. That circuitry is within your interoceptive network. Your body- budgeting regions make predictions to estimate the resources to keep you alive and flourishing, using past experience as a guide. Why is this relevant to emotion? Because every brain region that's claimed to be a home of emotion in humans is a body-budgeting region within the interoceptive network. These regions, however, don't react in emotion. They don't react at all. They predict, intrinsically, to regulate your body budget. They issue predictions for sights, sounds, thoughts, memories, imagination, and, yes, emotions. The idea of an emotional brain region is an illusion caused by the outdated belief in a reactive brain. Neuroscientists understand this today, but the message hasn't trickled down to many psychologists, psychiatrists, sociologists, economists, and others who study emotion. Whenever your brain predicts a movement, whether it's getting out of bed in the morning or taking a sip of coffee, your body-budgeting regions adjust your budget. When your brain predicts that your body will need a quick burst of energy, these regions instruct the adrenal gland in your kidneys to release the hormone cortisol. People call cortisol a “stress hormone,” but this is a mistake. Cortisol is released whenever you need a surge of energy, which happens to include the times when you are stressed. Its main purpose is to flood the bloodstream with glucose to provide immediate energy to cells, allowing, for example, muscle cells to stretch and contract so you can run. Your body-budgeting regions also make you breathe more deeply to get more oxygen into your bloodstream and dilate your arteries to get that oxygen to your muscles more quickly so your body can move. All of this internal motion is accompanied by interoceptive sensations, though you are not wired to experience them precisely. So, your interoceptive network controls your body, budgets your energy resources, and represents your internal sensations, all at the same time. Withdrawals from your body's budget don't require actual physical movement. Suppose you see your boss, teacher, or baseball coach walking toward you. You believe that she judges everything you say and do. Even though no physical movement seems called for, your brain predicts that your body needs energy and makes a budget withdrawal, releasing cortisol and flooding glucose into your bloodstream. You also have a surge in interoceptive sensations. Stop and think about this for a minute. Someone merely walks toward you while you are standing still, and your brain predicts that you need fuel! In this manner, any event that significantly impacts your body budget becomes personally meaningful to you. Not long ago, my lab was evaluating a portable device for monitoring the heart. Whenever the wearer's heart rate sped up 15 percent above normal, the device would beep. One of my graduate students, Erika Siegel, was wearing the device as she worked quietly at her desk, and it remained silent for some time. At one point, I walked into the room. When Erika turned and saw me (her Ph.D. advisor), the device beeped loudly, to her embarrassed surprise and to the amusement of everyone else around us. Later in the day, I spent time wearing the device, and during a meeting with Erika, it beeped several times as I received emails from a granting agency. (So Erika had the last laugh that day.)31 My lab has experimentally demonstrated the brain's budgeting efforts hundreds of times (as have other labs), observing as people's body-budgeting circuitry shifts resources around, and sometimes as their body budgets fluctuate in and out of balance. We ask volunteers to sit completely motionless in front of a computer screen and view pictures of animals, flowers, babies, food, money, guns, surfers, skydivers, car crashes, and other objects and scenes. These pictures impact their body budget; heart rates go up, blood pressures change, blood vessels dilate. These budgetary changes, which prepare the body to fight or flee, occur even though the volunteers are not moving and have no conscious plan to move. When our volunteers view these pictures during an fMRI experiment, we observe their body-budgeting regions controlling these inner-body movements. And even though our subjects are lying down, completely motionless, they simulate motor movements like running and surfing, as well as the sensations from moving muscles, joints, and tendons. The pictures also change our volunteers' feelings as interoceptive changes in their bodies are being simulated and corrected. Based on these and hundreds of other studies, we now have good evidence that your brain predicts your body's responses by drawing on prior experiences with similar situations and objects, even when you're not physically active. And the consequence is interoceptive sensation. To perturb your budget, you don't even require another person or object to be present. You can just imagine your boss, teacher, coach, or anything else relevant to you. Every simulation, whether it becomes an emotion or not, impacts your body budget. As it turns out, people spend at least half their waking hours simulating rather than paying attention to the world around them, and this pure simulation strongly drives their feelings. When it comes to managing your body budget, your brain does not have to go it alone. Other people regulate your body budget too. When you interact with your friends, parents, children, lovers, teammates, therapist, or other close companions, you and they synchronize breathing, heart beats, and other physical signals, leading to tangible benefits. Holding hands with loved ones, or even keeping their photo on your desk at work, reduces activation in your body-budgeting regions and makes you less bothered by pain. If you're standing at the bottom of a hill with friends, it will appear less steep and easier to climb than if you are alone. If you grow up in poverty, a situation that leads to chronic body-budget imbalance and an overactive immune system, these body-budgeting problems are reduced if you have a supportive person in your life. In contrast, when you lose a close, loving relationship and feel physically ill about it, part of the reason is that your loved one is no longer helping to regulate your budget. You feel like you've lost a part of yourself because, in a sense, you have. Every person you encounter, every prediction you make, every idea you imagine, and every sight, sound, taste, touch, and smell that you fail to anticipate all have budgetary consequences and corresponding interoceptive predictions. Your brain must contend with this continuous, ever-changing flow of interoceptive sensations from the predictions that keep you alive. Sometimes you're aware of them, and other times you're not, but they are always part of your brain's model of the world. They are, as I've said, the scientific basis for simple feelings of pleasure, displeasure, arousal, and calmness that you experience every day. For some, the flow is like the trickle of a tranquil brook. For others, it's like a raging river. Sometimes the sensations are transformed into emotions, but as you will now learn, even when they're only in the background, they influence what you do, what you think, and what you perceive. When you wake up in the morning, do you feel refreshed or crabby? In the middle of the day, do you feel dragged out or full of energy? Consider how you feel right now. Calm? Interested? Energetic? Bored? Tired? Cranky? These are the simple feelings we discussed at the beginning of the chapter. Scientists call them affect.* Affect is the general sense of feeling that you experience throughout each day. It is not emotion but a much simpler feeling with two features. The first is how pleasant or unpleasant you feel, which scientists call valence. The pleasantness of the sun on your skin, the deliciousness of your favorite food, and the discomfort of a stomachache or a pinch are all examples of affective valence. The second feature of affect is how calm or agitated you feel, which is called arousal. The energized feeling of anticipating good news, the jittery feeling after drinking too much coffee, the fatigue after a long run, and the weariness from lack of sleep are examples of high and low arousal. Anytime you have an intuition that an investment is risky or profitable, or a gut feeling that someone is trustworthy or an asshole, that's also affect. Even a completely neutral feeling is affect. Philosophers from the West and the East describe valence and arousal as basic features of human experience. Scientists largely agree that affect is present from birth and that babies can feel and perceive pleasure and displeasure, even as they disagree whether newborns emerge into the world with fully formed emotions. Affect, you may recall, depends on interoception. That means affect is a constant current throughout your life, even when you are completely still or asleep. It does not turn on and off in response to events you experience as emotional. In this sense, affect is a fundamental aspect of consciousness, like brightness and loudness. When your brain represents wavelengths of light reflected from objects, you experience brightness and darkness. When your brain represents air pressure changes, you experience loudness and softness. And when your brain represents interoceptive changes, you experience pleasantness and unpleasantness, and agitation and calmness. Affect, brightness, and loudness all accompany you from birth until death. Let's be clear on one thing: interoception is not a mechanism dedicated to manufacturing affect. Interoception is a fundamental feature of the human nervous system, and why you experience these sensations as affect is one of the great mysteries of science. Interoception did not evolve for you to have feelings but to regulate your body budget. It helps your brain track your temperature, how much glucose you are using, whether you have any tissue damage, whether your heart is pounding, whether your muscles are stretching, and other bodily conditions, all at the same time. Your affective feelings of pleasure and displeasure, and calmness and agitation, are simple summaries of your budgetary state. Are you flush? Are you overdrawn? Do you need a deposit, and if so, how desperately?39 When your budget is unbalanced, your affect doesn't instruct you how to act in any specific way, but it prompts your brain to search for explanations. Your brain constantly uses past experience to predict which objects and events will impact your body budget, changing your affect. These objects and events are collectively your affective niche. Intuitively, your affective niche includes everything that has any relevance to your body budget in the present moment. Right now, this book is within your affective niche, as are the letters of the alphabet, the ideas you're reading about, any memories that my words bring to mind, the air temperature around you, and any objects, people, and events from your past that impacted your body budget in a similar situation. Anything outside your affective niche is just noise: your brain issues no predictions about it, and you do not notice it. The feel of your clothing against your skin is usually not in your affective niche (though it is now, since I just mentioned it), unless it happens to be relevant, say, to your physical comfort. The psychologist James A. Russell developed a way of tracking affect, and it's become popular among clinicians, teachers, and scientists. He showed that you can describe your affect in the moment as a single point on a two- dimensional space called a circumplex, a circular structure with two dimensions, as in figure 4-5. Russell's two dimensions represent valence and arousal, with distance from the origin representing intensity. Figure 4-5: An affective circumplex Your affect is always some combination of valence and arousal, represented by one point on the affective circumplex. When you sit quietly, your affect is at a central point of “neutral valence, neutral arousal” on the circumplex. If you're having fun at a lively party, your affect might be in the “pleasant, high arousal” quadrant. If the party turns boring, your affect might be “unpleasant, low arousal.” Younger American adults tend to prefer the upper right quadrant: pleasant, high arousal. Middle-aged and older Americans tend to prefer the lower right quadrant (pleasant, low arousal), as do people from Eastern cultures like China and Japan. Hollywood is a $500 billion industry because people are willing to pay to see movies so that, for a few hours, they can travel within this affective map. You don't even have to open your eyes to have an affective adventure. When you daydream and have a large change in interoception, your brain will swirl with affect. Affect has far-reaching consequences beyond simple feeling. Imagine you are a judge presiding over a prisoner's parole case. You are listening to the inmate's story, hearing about his behavior in prison, and you have a bad feeling. If you agree to parole, he could hurt someone else. Your hunch is that you should keep him locked up. So you deny parole. Your bad feeling, which is unpleasant affect, seems like evidence that your judgment was correct. But could your affect have misled you? This exact situation was the subject of a 2011 study of judges. Scientists in Israel found that judges were significantly more likely to deny parole to a prisoner if the hearing was just before lunchtime. The judges experienced their interoceptive sensations not as hunger but as evidence for their parole decision. Immediately after lunch, the judges began granting paroles with their customary frequency. When you experience affect without knowing the cause, you are more likely to treat affect as information about the world, rather than your experience of the world. The psychologist Gerald L. Clore has spent decades performing clever experiments to better understand how people make decisions every day based on gut feelings. This phenomenon is called affective realism, because we experience supposed facts about the world that are created in part by our feelings. For example, people report more happiness and life satisfaction on sunny days, but only when they are not explicitly asked about the weather. When you apply for a job or college or medical school, make sure you interview on a sunny day, because interviewers tend to rate applicants more negatively when it is rainy. And the next time a good friend snaps at you, remember affective realism. Maybe your friend is irritated with you, but perhaps she didn't sleep well last night, or maybe it's just lunchtime. The change in her body budget, which she's experiencing as affect, might not have anything to do with you. Affect leads us to believe that objects and people in the world are inherently negative or positive.* Photographs of kittens are deemed pleasant. Photographs of rotting human corpses are deemed unpleasant. But these images do not have affective properties inside them. The phrase “an unpleasant image” is really shorthand for “an image that impacts my body budget, producing sensations that I experience as unpleasant.” In these moments of affective realism, we experience affect as a property of an object or event in the outside world, rather than as our own experience. “I feel bad, therefore you must have done something bad. You are a bad person.” In my lab, when we manipulate people's affect without their knowing, it influences whether they experience a stranger as trustworthy, competent, attractive, or likable, and they even see the person's face differently. People employ affect as information, creating affective realism, throughout daily life. Food is “delicious” or “bland.” Paintings are “beautiful” or “ugly.” People are “nice” or “mean.” Women in certain cultures must wear scarves and wigs so as not to “tempt men” by showing a bit of hair. Sometimes affective realism is helpful, but it also shapes some of humanity's most troubling problems. Enemies are “evil.” Women who are raped are perceived as “asking for it.” Victims of domestic violence are said to “bring it on themselves.”46 The thing is, a bad feeling doesn't always mean something is wrong. It just means you're taxing your body budget. When people exercise to the point of labored breathing, for example, they feel tired and crappy well before they run out of energy. When people solve math problems and perform difficult feats of memory, they can feel hopeless and miserable, even when they are performing well. Any graduate student of mine who never feels distress is clearly doing something wrong. Affective realism can also lead to tragic consequences. In July 2007, an American gunner aboard an Apache helicopter in Iraq mistakenly killed a group of eleven unarmed people, including several Reuters photojournalists. The soldier had misjudged a journalist's camera to be a gun. One explanation for this incident is that affective realism caused the soldier, in the heat of the moment, to imbue a neutral object (a camera) with unpleasant valence. Every day, soldiers must make quick decisions about other people, whether they are embedded in a unit during wartime, on a peacekeeping mission, negotiating in a cross-cultural setting, or collaborating with unit members on a stateside base. These quick judgments are extremely difficult to negotiate, especially in such high-stakes, high-arousal settings where errors are often made at the expense of someone's life. A little closer to home, affective realism may also play a role in police shootings of unarmed civilians. The U.S. Department of Justice analyzed shootings by Philadelphia police officers between 2007 and 2013 and found that 15 percent of the victims were unarmed. In half of these cases, an officer reportedly misidentified “a nonthreatening object (e.g., a cell phone) or movement (e.g., tugging at the waistband)” as a weapon. Many factors may contribute to these tragedies, ranging from carelessness to racial bias, but it is also possible that some of the shooters actually perceive a weapon when none is present due to affective realism in a high-pressure and dangerous context.* The human brain is wired for this sort of delusion, in part because moment-to- moment interoception infuses us with affect, which we then use as evidence about the world. People like to say that seeing is believing, but affective realism demonstrates that believing is seeing. The world often takes a backseat to your predictions. (It's still in the car, so to speak, but is mostly a passenger.) And as you're about to learn right now, this arrangement is not limited to vision. Suppose you're walking alone in the forest, and you hear a rustle in the leaves and see a vague movement on the ground. As always, your body-budgeting regions initiate predictions-say, that there's a snake nearby. These predictions prepare you to see and hear a snake. At the same time, these regions predict that your heart rate should increase and your blood vessels should dilate, for instance, in preparation to run. A pounding heart and surging blood would cause interoceptive sensations, so your brain must predict those sensations as well. As a result, your brain simulates the snake, the bodily changes, and the bodily sensations. These predictions translate into feeling; in this case, you'll begin to feel agitated. What happens next? Maybe a snake slithers out from the brush. In this case, the sensory input matches your predictions and you run. Or perhaps no snake is present-the leaves were just rustled by the wind-but you see a snake anyway. That's affective realism. Now consider the third possibility: there is no snake, and you don't see a snake. In this case, your visual predictions of a snake are corrected quickly; however, your interoceptive predictions are not. Your body-budgeting regions keep predicting adjustments to your budget long after the predicted need is over. You therefore may take a long time to calm down, even if you know there is nothing wrong. Remember when I compared your brain to a scientist who makes and tests hypotheses? Your body-budgeting regions are like a mostly deaf scientist: they make predictions but have a hard time listening to the incoming evidence. Some of the time, your body-budgeting regions are sluggish to correct their predictions. Think about the last time you ate too much and felt bloated. You might be able to blame your body-budgeting regions. One of their jobs is to predict your level of circulating glucose, which determines how much food you need, but they don't receive the message “I'm full” from your body in a timely manner, so you keep eating. If you've ever heard the advice, “Wait 20 minutes before you take a second helping, to see if you're really still hungry,” now you know why it works. Whenever you make a big deposit or withdrawal from your body budget-eating, exercising, injuring yourself- you might have to wait for your brain to catch up. Marathon runners learn this; they feel fatigue early in the race when their body budget is still solvent, so they keep running until the unpleasant feeling goes away. They ignore the affective realism that insists they're out of energy. Take a moment and consider what this means for your day-to-day life. You've just learned that the sensations you feel from your body don't always reflect the actual state of your body. That's because familiar sensations like your heart beating in your chest, your lungs filling with air, and, most of all, the general pleasant, unpleasant, aroused, and quiescent sensations of affect are not really coming from inside your body. They are driven by simulations in your interoceptive network. In short, you feel what your brain believes. Affect primarily comes from prediction. You've already learned that you see what your brain believes-that's affective realism. Now you know the same is true for most feelings you've experienced in your life. Even the feeling of the pulse in your wrist is a simulation, constructed in sensory regions of your brain and corrected by sensory input (your actual pulse). Everything you feel is based on prediction from your knowledge and past experience. You are truly an architect of your experience. Believing is feeling. These ideas are not just speculation. Scientists with the right equipment can change people's affect by directly manipulating body-budgeting regions that issue predictions. Helen S. Mayberg, a pioneering neurologist, has developed a deep brain stimulation therapy for people suffering from treatment-resistant depression. These people don't just experience the anguish of a major depressive episode-they are in agony, trapped in a pit of self-loathing and unending torment. Some of them can barely move. During surgery, Mayberg works with a team of neurosurgeons who drill small holes in the skull and sink electrodes into a key predictive area in the patient's interoceptive network. When the neurosurgeons turn on the electrodes, Mayberg's patients report immediate relief from their agony. As the electrical current is turned off and on, the patients' crippling wave of dread approaches and recedes in synchrony with the stimulation. Mayberg's remarkable work might represent the first time in scientific history that direct stimulation of the human brain has consistently changed people's affective feelings, potentially leading to new treatments for mental illness. While predictive brain circuitry is important for affect, it likely is not necessary. Consider the case of Roger, a fifty-six-year-old patient whose relevant circuitry was destroyed by a rare illness. He has an above-normal IQ and a college education but also plenty of mental difficulties, such as severe amnesia and difficulty with smell and taste. Nevertheless, Roger experiences affect. Most likely, his affect is driven by actual sensory inputs from his body; other brain regions could be supplying the predictions, an example of degeneracy (different sets of neurons producing the same outcome). The opposite situation can also occur. Patients with spinal cord damage or Pure Autonomic Failure, a degenerative disease of the autonomic nervous system, have interoceptive predictions but don't receive sensory inputs from their organs and tissue. These patients likely experience affect based primarily on uncorrected predictions. Figure 4-6: Deep brain stimulation Your interoceptive network doesn't just help determine how you feel. Its body-budgeting regions are some of the most powerful and well-connected predictors in your entire brain. These regions are loud and bossy, like a mostly deaf scientist with a big megaphone. They launch predictions for vision, hearing, and your other senses; your primary sensory regions, which don't issue predictions of their own, are wired to listen. Let me show you what this means. You might think that in everyday life, the things you see and hear influence what you feel, but it's mostly the other way around: that what you feel alters your sight and hearing. Interoception in the moment is more influential to perception, and how you act, than the outside world is. You might believe that you are a rational creature, weighing the pros and cons before deciding how to act, but the structure of your cortex makes this an implausible fiction. Your brain is wired to listen to your body budget. Affect is in the driver's seat and rationality is a passenger. It doesn't matter whether you're choosing between two snacks, two job offers, two investments, or two heart surgeons-your everyday decisions are driven by a loudmouthed, mostly deaf scientist who views the world through affect-colored glasses. Antonio Damasio, in his bestseller Descartes' Error, observes that a mind requires passion (what we would call affect) for wisdom. He documents that people with damage to their interoceptive network, particularly in one key body-budgeting region, have impaired decision-making. Robbed of the capacity to generate interoceptive predictions, Damasio's patients were rudderless. Our new knowledge of brain anatomy now compels us to go one step further. Affect is not just necessary for wisdom; it's also irrevocably woven into the fabric of every decision. The shouting power of body-budgeting circuitry has serious implications for the financial world. It helped to precipitate the greatest economic disasters of our time, most recently the global financial meltdown of 2008 that cast countless families into economic ruin. The science of economics used to employ a concept called the rational economic person (homo economicus), who controls his or her emotions to make reasoned economic judgments. This concept was a foundation of Western economic theory, and though it has fallen out of favor among academic economists, it has continued to guide economic practice. However, if body-budgeting regions drive predictions to every other brain network, then the model of the rational economic person is based on a biological fallacy. You cannot be a rational actor if your brain runs on interoceptively infused predictions. An economic model at the foundation of the U.S. economy- some might say the global economy-is rooted in a neural fairy tale. Every economic crisis in the last thirty years has been related, at least in some part, to the rational economic person model. According to journalist Jeff Madrick, author of Seven Bad Ideas: How Mainstream Economists Have Damaged America and the World, several of economists' most fundamental ideas caused a series of financial crises leading up to the Great Recession. A common theme running through these ideas is that unregulated free-market economies work well. In these economies, decisions regarding investments, production, and distribution are based on supply and demand with no government regulation or oversight. Mathematical models indicate that under certain conditions, unregulated free-market economies do work well. But one of those “certain conditions” is that people are rational decision makers. I have lost count of the number of experiments published over the past fifty years showing that people are not rational actors. You cannot overcome emotion through rational thinking, because the state of your body budget is the basis for every thought and perception you have, so interoception and affect are built into every moment. Even when you experience yourself as rational, your body budget and its links to affect are there, lurking beneath the surface. If the idea of the rational human mind is so toxic to the economy, and it's not backed up by neuroscience, why does it persist? Because we humans have long believed that rationality makes us special in the animal kingdom. This origin myth reflects one of the most cherished narratives in Western thought, that the human mind is a battlefield where cognition and emotion struggle for control of behavior. Even the adjective we use to describe ourselves as insensitive or stupid in the heat of the moment-“thoughtless”-connotes a lack of cognitive control, of failing to channel our inner Mr. Spock. This origin myth is so strongly held that scientists even created a model of the brain based on it. The model begins with ancient subcortical circuits for basic survival, which we allegedly inherited from reptiles. Sitting atop those circuits is an alleged emotion system, known as the “limbic system,” that we supposedly inherited from early mammals. And wrapped around the so-called limbic system, like icing on an already-baked cake, is our allegedly rational and uniquely human cortex. This illusory arrangement of layers, which is sometimes called the “triune brain,” remains one of the most successful misconceptions in human biology. Carl Sagan popularized it in The Dragons of Eden, his bestselling (some would say largely fictional) account of how human intelligence evolved. Daniel Goleman employed it in his bestseller Emotional Intelligence. Nevertheless, humans don't have an animal brain gift- wrapped in cognition, as any expert in brain evolution knows. “Mapping emotion onto just the middle part of the brain, and reason and logic onto the cortex, is just plain silly,” says neuroscientist Barbara L. Finlay, editor of the journal Behavior and Brain Sciences. “All brain divisions are present in all vertebrates.” So how do brains evolve? They reorganize as they expand, like companies do, to keep themselves efficient and nimble. Figure 4-7: The “triune brain” idea, with so-called cognitive circuitry layered on top of so-called emotion circuitry. This illusory arrangement depicts how thinking supposedly regulates feeling. The bottom line is this: the human brain is anatomically structured so that no decision or action can be free of interoception and affect, no matter what fiction people tell themselves about how rational they are. Your bodily feeling right now will project forward to influence what you will feel and do in the future. It is an elegantly orchestrated, self-fulfilling prophecy, embodied within the architecture of your brain. Your brain, with its billions of neurons, has much more going on than I've sketched out in this chapter. Most neuroscientists agree that we are decades away from knowing the intricacies of how a brain works, let alone how it creates consciousness. Still, we can be fairly sure of some things. Right now, as your brain makes meaning from these words, it is predicting changes in your body budget. Every thought, memory, perception, or emotion that you construct includes something about the state of your body: a little piece of interoception. A visual prediction, for example, doesn't just answer the question, “What did I see last time I was in this situation?” It answers, “What did I see last time I was in this situation when my body was in this state?” Any change in affect you feel while reading these words-more or less pleasant, or more or less calm-is a result of those interoceptive predictions. Affect is your brain's best guess about the state of your body budget. Interoception is also one of the most important ingredients in what you experience as reality. If you didn't have interoception, the physical world would be meaningless noise to you. Consider this: Your interceptive predictions, which produce your feelings of affect, determine what you care about in the moment-your affective niche. From the perspective of your brain, anything in your affective niche could potentially influence your body budget, and nothing else in the universe matters. That means, in effect, that you construct the environment in which you live. You might think about your environment as existing in the outside world, separate from yourself, but that's a myth. You (and other creatures) do not simply find yourself in an environment and either adapt or die. You construct your environment-your reality-by virtue of what sensory input from the physical environment your brain selects; it admits some as information and ignores some as noise. And this selection is intimately linked to interoception. Your brain expands its predictive repertoire to include anything that might impact your body budget, in order to meet your body's metabolic demands. This is why affect is a property of consciousness. Interoception, as a fundamental part of the predictive process, is a key ingredient of emotion. However, interoception alone cannot explain emotion. An emotion category like anger or sadness is far more complex than a simple feeling of unpleasantness and arousal. When Connecticut Governor Dannel Malloy's voice wavered during his speech after the Sandy Hook Elementary School massacre, he didn't cry, he didn't pout, and at one point he actually smiled. And yet, somehow, viewers inferred that he was experiencing intense sadness. Sensation and simple feeling are not sufficient to explain how an audience of thousands perceived the depth of Malloy's anguish. Affect alone also doesn't explain how we construct our own experiences of sadness, nor how one instance of sadness differs from another. Nor does affect tell you what sensations mean or what to do about them. That's why people eat when they are tired or find a defendant guilty when they are hungry. You must make the affect meaningful so your brain can execute a more specific action. One way to make meaning is to construct an instance of emotion. So, how do interoceptive sensations become emotions? And why do we experience these sensations (really predictions) in such diverse ways: as physical symptoms, as perceptions of the world, as simple affective feeling, and sometimes as emotion? That is the next mystery we'll address."
  },
  {
    "index": 10,
    "level": 1,
    "start_page": 91,
    "end_page": 115,
    "title": "Concepts, Goals, and Words",
    "content": "Concepts, Goals, and Words. When you look at a rainbow, you see discrete stripes of color, roughly like the drawing on the left side of figure 5-1. But in nature, a rainbow has no stripes-it's a continuous spectrum of light, with wavelengths that range from approximately 400 to 750 nanometers. This spectrum has no borders or bands of any kind. Why do you and I see stripes? Because we have mental concepts for colors like “Red,” “Orange,” and “Yellow.” Your brain automatically uses these concepts to group together the wavelengths in certain ranges of the spectrum, categorizing them as the same color. Your brain downplays the variations within each color category and magnifies the differences between the categories, causing you to perceive bands of color. Figure 5-1: Rainbows, drawn with stripes (left) and continuous as in nature (right) Human speech also is continuous-a stream of sound-yet when you listen to your native language, you hear discrete words. How does that happen? Once again, you use concepts to categorize the continuous input. Beginning in infancy, you learn regularities in the stream of speech that reveal the boundaries between phonemes, the smallest bits of sound that you can distinguish in a language (for example, the sound of “D” or “P” in English). These regularities become concepts that your brain later uses to categorize the stream of sound into syllables and words. This remarkable process is filled with challenges because the audio stream is ambiguous and highly variable. Consonant sounds vary with context: the sound of “D” is acoustically different in the words “Dad” and “Death,” yet somehow we hear both as a “D.” Vowel sounds vary with the age, sex, and size of the speaker, as well as by context within the same speaker. An incredible 50 percent of the words we hear cannot be understood out of context (when presented in isolation). But using your concepts, your brain learns to categorize, constructing phonemes in tens of milliseconds within all this variable, noisy information, ultimately permitting you to communicate with others. Everything you perceive around you is represented by concepts in your brain. Take a look at any object near you. Then, look slightly to the left of the object. You just accomplished something remarkable without even knowing it. Your head and eye movements seemed inconsequential but caused a gigantic change in the visual input reaching your brain. If you think of your field of vision as a big TV screen, then your slight eye movement just changed millions of pixels on that screen. And yet, you did not experience blurry streaks across your visual field. That's because you don't see the world in terms of pixels: you see objects, and they changed very little as you moved your eyes. You perceive low-level regularities like lines, contours, streaks, and blurs, as well as higher-level regularities like complex objects and scenes. Your brain learned these regularities as concepts long ago, and it uses those concepts now to categorize your continually changing visual input. Without concepts, you'd experience a world of ever-fluctuating noise. Everything you ever encountered would be unlike everything else. You'd be experientially blind, like when you first saw the blobby picture in chapter 2, but permanently so. You'd be incapable of learning. All sensory information is a massive, constantly changing puzzle for your brain to solve. The objects you see, the sounds you hear, the odors you smell, the touches you feel, the flavors you taste, and the interoceptive sensations you experience as aches and pains and affect . . they all involve continuous sensory signals that are highly variable and ambiguous as they reach your brain. Your brain's job is to predict them before they arrive, fill in missing details, and find regularities where possible, so that you experience a world of objects, people, music, and events, not the “blooming, buzzing confusion” that is really out there. To achieve this magnificent feat, your brain employs concepts to make the sensory signals meaningful, creating an explanation for where they came from, what they refer to in the world, and how to act on them. Your perceptions are so vivid and immediate that they compel you to believe that you experience the world as it is, when you actually experience a world of your own construction. Much of what you experience as the outside world begins inside your head. When you categorize using concepts, you go beyond the information available, just as you did when you perceived a bee within blobs. In this chapter, I explain that each time you experience emotion or perceive it in others, you are again categorizing with concepts, making meaning of sensations from interoception and the five senses. This is a key theme of the theory of constructed emotion. My point is not to say, “You construct instances of emotion by categorization: isn't that unique?” Rather, it's to show that categorization constructs every perception, thought, memory, and other mental event that you experience, so of course you construct instances of emotion in the same manner. This is not effortful, conscious categorization, as when an entomologist pores over some new specimen of weevil, deciding whether it's a member of the anthribidae or nemonychidae family. I'm speaking of the rapid, automatic categorization performed constantly by your brain, in every waking moment, in milliseconds, to predict and explain the sensory input that you encounter. Categorization is business as usual for your brain, and it explains how emotions are made without needing fingerprints. We'll be informal for now about the inner workings (i.e., the neuroscience) of categorization and just deal with some of the more basic questions. What are concepts? How are they formed? What sort of concepts are emotion concepts? And in particular, what superpower must a human mind possess to create meaning from scratch? Many of these questions are still active areas of research. When solid evidence exists, I present it. When there is less evidence, I make educated guesses. The answers not only explain how emotions are made but reveal a glimpse at the core of what it means to be human. Philosophers and scientists define a category as a collection of objects, events, or actions that are grouped together as equivalent for some purpose. They define a concept as a mental representation of a category. Traditionally, categories are supposed to exist in the world, while concepts exist in your head. For example, you have a concept of the color “Red.” When you apply this concept to wavelengths of light to perceive a red rose in a park, that red color is an instance of the category “Red.”* Your brain downplays the differences between the members of a category, such as the diverse shades of red roses in a botanical garden, to consider those members equivalent as “red.” Your brain also magnifies differences between members and nonmembers (say, red versus pink roses) so that you perceive firm boundaries between them. Imagine walking down the street in your city or town with a brain full of concepts. You see many objects all at once: flowers, trees, cars, houses, dogs, birds, bees. You see people walking, moving their bodies and faces. You hear sounds and smell diverse scents. Your brain puts this information together to perceive events like children playing in a park, a person gardening, an old couple holding hands on a bench. You create your experience of these objects, actions, and events by categorizing using concepts. Your ever- predicting brain swiftly anticipates sensory input, asking “Which of my concepts is this like?” For example, if you view a car head-on and then from the side, and you have a concept for that car, you can know it's the same one even though the visual information hitting your retina from these two angles is entirely different. When your brain instantly categorizes sensory input as (say) a car, it's utilizing a concept of “Car.” The deceptively simple phrase “concept of Car” stands for something more complex than you might expect. So, what exactly is a concept? That depends on which scientists you ask, which is business as usual in science. We must expect a certain amount of controversy around a topic as fundamental as “how knowledge is organized and represented in the human mind.” And the answer is crucial to understanding how emotions are made. If I asked you to describe the concept “Car,” you might say a method of transportation that typically has four wheels, is made of metal, has an engine, and runs on some kind of fuel. Early scientific approaches assumed that a concept works exactly like this: a dictionary definition stored in your brain, describing necessary and sufficient features. “A car is a vehicle with an engine, four wheels, seats, doors, and a roof.” “A bird is an egg-laying, flying animal with wings.” This classical view of concepts assumes that their corresponding categories have firm boundaries. Instances of the category “Bee” are never in the category “Bird.” Also in this view, every instance is an equivalently good representative of the category. Any bee is representative, so it goes, because all bees have something in common, either the way they look or what they do, or an underlying fingerprint that makes them bees. Any variation from bee to bee is considered irrelevant to the fact that they are bees. You might notice a parallel here to the classical view of emotion, in which every instance of the category “Fear” is similar, and instances of “Fear” are distinct from instances of “Anger.”9 Classical concepts dominated philosophy, biology, and psychology from antiquity until the 1970s. In real life, the instances of a category vary tremendously from one another. There exist cars with no doors, such as a golf cart, or with six wheels like the Covini C6W. And some instances of a category really are more representative than others: nobody would call an ostrich a representative bird. In the 1970s, the classical view of concepts finally collapsed. Well, except in the science of emotion. From the ashes of classical concepts, a new view arose. It said that a concept is represented in the brain as the best example of its category, known as the prototype. For example, the prototypical bird has feathers and wings and can fly. Not all instances of “Bird” have these features, such as ostriches and emus, but they are still birds. Variation from the prototype is perfectly fine, but not too much variation: a bee is still not a bird, even though it has wings and can fly. In this view, as you learn about a category, your brain supposedly represents the concept as a single prototype. It might be the most frequent example of the category, or the most typical example, meaning the instance that is the closest match or has a majority of the category's features. Where emotion is concerned, people seem to have an easy time describing prototypical features of a given emotion category. Ask an American to describe prototypical sadness and he'll say it features a frowning or pouting face, a slumped posture, crying, moping around, a monotonous tone of voice, and that it begins with a loss of some sort and ends with an overall feeling of fatigue or powerlessness. Not every instance of sadness has every feature, but the description should be typical of sadness. So, prototypes might seem to be a good model for emotion concepts, if not for one paradoxical detail. When we measure actual instances of sadness using scientific tools, this frowning/pouting prototype of loss is not the most frequently or typically observed pattern. Everybody seems to know the prototype, but it's rarely found in real life. Instead, as you learned throughout chapter 1, we find great variability in sadness and every other emotion category. If there are no emotion prototypes stored in the brain, how do people list their features so easily? Most likely, your brain constructs prototypes as you need them, on the spot. You have experienced a diverse population of instances of the concept “Sadness,” which reside in bits and pieces in your head, and in the blink of an eye, your brain constructs a summary of sadness that best fits the situation. (An example of population thinking in the brain.)14 Scientists have shown that people can construct similar prototypes in the lab. Print a random pattern of dots on a sheet of paper, then create a dozen variations of that pattern, and show people only the dozen variations. People can produce the original prototype pattern even though they've never seen it, simply by finding similarities in the variations. This means a prototype need not be found in nature, yet the brain can construct one when needed. Emotion prototypes, if that's what they indeed are, could be constructed in the same manner. Thus, concepts aren't fixed definitions in your brain, and they're not prototypes of the most typical or frequent instances. Instead, your brain has many instances-of cars, of dot patterns, of sadness, or anything else-and it imposes similarities between them, in the moment, according to your goal in a given situation. For example, your usual goal for a vehicle is to use it for transportation, so if an object meets that goal for you, then it's a vehicle, whether it's a car, a helicopter, or a sheet of plywood with four wheels nailed on. This explanation of concepts comes from Lawrence W. Barsalou, one of the world's leading cognitive scientists studying concepts and categories. Figure 5-2: Inferring a “prototype” pattern (step 5) from examples (steps 1- 4). Test subjects first saw a variety of 9-dot patterns on a 30×30 grid. They classified each pattern into one of two categories, A and B. This was called the “learning phase” of the experiment. Next, they classified more patterns, some old and some new, including the prototypes of categories A and B, which the subjects had never seen. Subjects easily categorized the prototypes but had a more difficult time with the other, new variants. That meant each subject's brain must have constructed the prototypes despite not having seen them during the learning phase. Goal-based concepts are super flexible and adaptable to the situation. If you're in a pet shop to replenish your home aquarium and the salesperson asks, “What kind of fish would you like?” you might say “a goldfish” or “a black molly” but probably not “a poached salmon.” Your concept “Fish” in this situation serves a goal to purchase a pet, not to order dinner, so you'll construct instances of the concept “Fish” that best suit your fish tank. If you're on a snorkeling expedition, you will use “Fish” in service of a goal to find exciting wildlife, so the best instance might be a huge nurse shark or a colorful spotted boxfish. Concepts are not static but remarkably malleable and context-dependent, because your goals can change to fit the situation. A single object can also be part of different concepts. For example, a car does not always serve the goal of transportation. Sometimes a car is an instance of the concept “Status Symbol.” In the right circumstances, a car can be a “Bed” for a homeless person, or even a “Murder Weapon.” Drive a car into the ocean and it becomes an “Artificial Reef.” Figure 5-3: Concepts and goals. Row 1 illustrates concepts centered on a perceptual similarity, such as wings. Row 2 demonstrates that categories of objects can be goal-based. Bats, helicopters, and Frisbees share no perceptual features but can be described by a mental similarity: a common goal to move through the air. Row 3 illustrates similarity that is purely mental. The concept “Love” can be associated with different goals depending on context. To see the real power of goal-based concepts, consider a purely mental concept such as “Things That Can Protect You from Stinging Insects.” Instances of the category are remarkably diverse: a flyswatter, a beekeeper's suit, a house, a Maserati, a large trash can, a vacation in Antarctica, a calm demeanor, even a university degree in entomology. They share no perceptual features. This category is clearly and entirely a construction of the human mind. Not all instances work in every context: for example, when you're gardening, whacking away at a bed of overgrown iris, and you accidentally disturb a bees' nest and unleash a swarm in your direction, a nearby house would be far better protection than a flyswatter. Yet your brain lumps all these instances into the same category because they can achieve the same goal, safety from stings. In fact, the goal is the only thing that holds together the category. When you categorize, you might feel like you're merely observing the world and finding similarities in objects and events, but that cannot be the case. Purely mental, goal-based concepts such as “Things That Can Protect You from Stinging Insects” reveal that categorization cannot be so simple and static. A flyswatter and a house have no perceptual similarities. Goal-based concepts therefore free you from the shackles of physical appearance. When you walk into an entirely new situation, you don't experience it based solely on how things look, sound, or smell. Your experience it based on your goal. So, what's happening in your brain when you categorize? You are not finding similarities in the world but creating them. When your brain needs a concept, it constructs one on the fly, mixing and matching from a population of instances from your past experience, to best fit your goals in a particular situation. And herein lies a key to understanding how emotions are made. Emotion concepts are goal-based concepts. Instances of happiness, for example, are highly variable. You can smile in happiness, sob in happiness, scream in happiness, raise your arms in happiness, clench your fists in happiness, jump up and down doling out high fives in happiness, or even be stunned motionless in happiness. Your eyes might be wide or narrowed; your breathing rapid or slow. You can have the heart-pounding, exciting happiness of winning the lottery or the calm, relaxed happiness of lying on a picnic blanket with your lover. You've also perceived many other people as happy in various ways. Altogether, this motley assortment of experiences and perceptions can involve different actions and inner-body changes, they may feel affectively different, and they can include different sights, sounds, and smells. To you, in the moment, however, these sets of physical changes are equivalent for some goal. Perhaps your goal is to feel accepted, to feel pleasure, to achieve an ambition, or to find meaning in life. Your concept of “Happiness” in the moment is centered on such a goal, binding together the diverse instances from your past. Let's unpack an example. Suppose that you are in an airport waiting for your close friend to arrive for a visit, her first one in a long time. As you stare at the exit gates and await her imminent arrival, your brain is busily issuing thousands of predictions based on your concepts, in milliseconds, all outside of your awareness. After all, there are a host of different emotions you might experience in such a situation. You could experience the happiness of seeing your friend, the anticipation that she's about to appear, the fear that she won't arrive, or worry that you might no longer have anything in common. You could also have a non-emotional experience, like the exhaustion of your long drive to the airport, or the perception of tightness in your chest as a symptom that you're coming down with a cold. Using this storm of predictions, your brain makes meaning of sensations based on your past experiences with airports and friends and illnesses and related situations. Your brain weighs its predictions based on probabilities; they compete to explain what caused your sensations, and they determine what you perceive, how you act, and what you feel in this situation. Ultimately, the most probable predictions become your perception: say, you are happy and your friend is walking through the gates right now. Not every instance of “Happiness” from your past matches the present situation, because “Happiness” is a goal-based concept composed of wildly diverse instances, but some of them had bits and pieces that matched well enough to win the competition. Do these predictions match the actual sensory input from the world and your body? Or is there prediction error that must be resolved? That's a matter for your prediction loops to work out and, if necessary, to correct. Let's suppose your friend arrived safely, and later over coffee, she describes her turbulent plane flight that scared her out of her wits. She constructs an instance of “Fear” with the goal of communicating what it feels like to be strapped into the airplane seat, eyes closed, hot and queasy as the plane bumped up and down, her mind racing about her safety. When she says the word “frightened,” you also construct an instance of “Fear,” but it needn't have exactly the same physical features as hers; you probably won't squeeze your eyes shut, for example. Yet you can still perceive her fear and feel empathy for her. As long as your instances concern the same goal (detecting danger) in the same situation (a turbulent airplane ride), you and your friend are communicating clearly enough. On the other hand, if you constructed some other instance of “Fear,” such as the exuberant fear of riding a rollercoaster, you might have trouble understanding why your friend was so upset by the flight. Successful communication requires that you and your friend are using synchronized concepts. Think back to Darwin's ideas about the importance of variation within a species (chapter 1). Each animal species is a population of unique individuals who vary from one another. No feature or set of features is necessary, sufficient, or even frequent or typical of every individual in the population. Any summary of the population is a statistical fiction that applies to no individual. And most importantly, variation within a species is meaningfully related to the environment in which individuals live. Some individuals are more fit than others to pass their genetic material to the next generation. In a similar manner, some instances of concepts are more effective in a particular context to achieve a particular goal. Their competition in your brain is like Darwin's theory of natural selection but carried out in milliseconds; the most suitable instances outlive all rivals to fit your goal in the moment. That is categorization. Where do emotion concepts come from? How can a concept like “Awe” have such diversity: awe of the vastness of the universe; awe of Erik Weihenmayer, who scaled Mount Everest while blind; and awe that a tiny worker ant can carry five thousand times its body weight? The classical view proposes that you are born with these concepts, or that your brain finds emotion fingerprints in people's expressions and internalizes them as concepts. But we know that scientists haven't found such fingerprints, and infants show no evidence of being born knowing “Awe.” The human brain, it turns out, bootstraps a conceptual system into its wiring within the first year of life. This system is responsible for the wealth of emotion concepts that you now employ to experience and perceive emotions. The newborn brain has the ability to learn patterns, a process called statistical learning. The moment that you burst into this strange new world as a baby, you were bombarded with noisy, ambiguous signals from the world and from your body. This barrage of sensory input was not random: it had some structure. Regularities. Your little brain began computing probabilities of which sights, sounds, smells, touches, tastes, and interoceptive sensations go together and which don't. “Those edges form a boundary. Those two blobs are part of a bigger blob. That brief silence was a separator.” Little by little, but with surprising speed, your brain learned to resolve this ocean of vague sensation into patterns: sights and sounds, smells and tastes, touches and interoceptive sensations, and combinations thereof. Scientists have debated for hundreds of years over what you're born with versus what you learn, and I won't enter that debate. Let's just say that one thing you're born with is a fundamental ability to learn from regularities and probabilities around you. (In fact, you learn statistically even in utero, which makes it complicated to determine whether certain concepts are innate or learned.) Your prodigious capacity for statistical learning set you on the path toward the particular kind of mind, with the particular system of concepts, that you have today. Statistical learning in humans was first discovered in studies of language development. Babies have a natural interest in listening to speech, perhaps because the sounds occurred alongside body budgeting from birth, and even in utero. As they hear the sounds streaming along, they gradually infer the boundaries between phonemes, syllables, and words. From blobs of sound like itstimefordinner, areyouhungryfordinnernow, and dinnertimeyummy yummycarrots, infants learn which syllables are paired together more frequently (“din-ner,” “yum-my”) and therefore likely to be part of a single word. Syllables that co-occur relatively rarely are more likely to be part of different words. Babies learn these regularities extremely quickly, even within a few minutes of exposure. This learning process is so powerful that it changes the wiring in a baby's brain. Babies are born able to hear the differences between all sounds in all languages, but by the time they reach one year of age, statistical learning has reduced this ability to the sounds contained only in the languages they have heard spoken by live humans. Babies become wired for their native languages by statistical learning. Statistical learning is not the only way that humans acquire knowledge, but this learning begins very early in life and goes well beyond language. Studies show that babies easily learn statistical regularities in sound and vision, and it's reasonable to assume the same for the rest of the senses plus interoceptive sensations. What's more, babies can learn complex regularities that span multiple senses. If you fill a box with blue and yellow balls, and the yellow balls make a squeaking sound while the blue ones are silent, infants can generalize the association between color and sound. Babies use statistical learning to make predictions about the world, guiding their actions. Like little statisticians, they form hypotheses, assess probabilities based on their knowledge, integrate new evidence from the environment, and perform tests. In one creative study by the developmental psychologist Fei Xu, ten- to fourteen-month-old children first expressed a preference for pink or black lollipops, then were shown two candy jars: one containing more black lollipops than pink, and one with more pink than black. The experimenter then closed her eyes and drew one lollipop from each jar so infants could see only the stick, not the color. Each lollipop was placed into a separate, opaque cup with only the stick showing. Infants crawled to the cup that was statistically more likely to contain their preferred color, because it came from a jar where that color was in the majority. Experiments like this demonstrate that infants are not merely reactive to the world. Even from a very young age, they actively estimate probabilities based on patterns that they observe and learn, to maximize the outcomes they desire. Humans are not the only animals that learn statistically: non-human primates, dogs, and rats can do it, among others. Even single-celled animals engage in statistical learning and then prediction: they not only respond to changes in their environment but anticipate them. Human infants, however, do more than statistically learn simple concepts. They also quickly learn that some of the information they need about the world resides in the minds of the people around them. You might have noticed that young children assume that other people share their preferences. A one-year-old who likes crackers better than broccoli believes that everyone else in the world does too. She cannot infer mental states in others the way that Governor Malloy's audience inferred that he was filled with sorrow during his speech about the Sandy Hook massacre. Even so, Xu and her students have successfully observed the rudiments of mental inference even in young children as they learn statistically. Sixteen-month-old children were shown two bowls, one containing boring white cubes and the other full of more interesting, colorful Slinky toys. When these toddlers were allowed to choose an object from either bowl, sure enough they chose a favorite Slinky for themselves and for the experimenter. But then the experimenter revealed a third bowl containing many Slinkys and only a few cubes, and in full view of the children, he chose five white cubes for himself. When the children were asked to pick from that bowl, they gave the experimenter a cube! In other words, the children were able to learn a subjective preference of the experimenter that was different from their own. This realization, that an object has positive value for someone else, is an example of mental inference. Going beyond preferences, babies can even infer other people's goals statistically. They can tell the difference when an experimenter chooses a pattern of colored balls randomly versus with intent. In the latter case, they can infer that the experimenter's goal is to choose particular colors, and they'll expect that the experimenter will continue following it.* It seems as if infants automatically try to guess the goal behind another person's actions; they form a hypothesis (based on past experience in similar situations) and predict the outcome that will occur several minutes later. Statistical learning alone, however, does not equip humans to learn purely mental, goal-based concepts whose instances share no perceptual similarities. Take the concept “Money,” for example. You can't learn it simply by viewing a piece of colored paper, a gold nugget, a seashell, and a pile of barley or salt, each of which has been deemed currency by some society in history. Likewise, instances of an emotion category such as “Fear” don't have enough statistical regularity-as demonstrated in chapter 1-to allow a human brain to build a concept based on perceptual similarities. To build a purely mental concept, you need another secret ingredient: words. From infancy, little human brains have an affinity for processing speech signals and quickly realize that speech is one way to access the information inside other people's minds. They're particularly attuned to adult “baby talk” with a higher and more variable pitch, shorter sentences, and strong eye contact. Even before infants understand what words mean in a conventional sense, the sounds of the words introduce statistical regularity that speeds concept learning. The developmental psychologists Sandra R. Waxman and Susan A. Gelman, leaders in this area of research, hypothesize that words invite an infant to form a concept, but only when adults speak with intent to communicate: “Look, sweetie: a flower!”28 Waxman demonstrated this power of words in infants as young as three months. The infants first viewed pictures of different dinosaurs. As each image was shown, infants heard an experimenter speak a made-up word, “toma.” When these infants were later shown pictures of a new dinosaur and a non-dinosaur such as a fish, those who had heard the word could distinguish more reliably which pictures depicted a “toma,” implying that they had formed a simple concept. When the same experiment was performed with audio tones instead of human speech, the effect never materialized. Spoken words give the infant brain access to information that can't be found by observing the world and resides only in the minds of other people, namely, mental similarities: goals, intentions, preferences. Words allow infants to begin growing goal-based concepts, including emotion concepts. A little human brain, bathed in the words of others around it, accumulates simple concepts. Some concepts are learned without words, but words confer distinct advantages to a developing conceptual system. A word might begin as a mere stream of sounds to the infant, just one part of the whole statistical learning package, but it quickly becomes more than that. It becomes an invitation for the infant to create similarities among diverse instances. A word tells the infant, “Do you see all these objects that look different physically? They have an equivalence that is mental.” That equivalence is the basis for a goal-based concept. Fei Xu and her students have demonstrated this experimentally by showing objects to ten-month-old infants, giving the objects nonsense names like “wug” or “dak.” The objects were wildly dissimilar, including dog-like and fish-like toys, cylinders with multicolored beads, and rectangles covered in foam flowers. Each one also made a ringing or rattling noise. Nevertheless, the infants learned patterns. Infants who heard the same nonsense name across several objects, regardless of their appearance, expected those objects to make the same noise. Likewise, if two objects had different names, the infants expected them to make different noises. This is a remarkable feat for infants because they used the sounds of a word to predict whether objects made the same noise or not, learning a pattern that transcended mere physical appearance. Words encourage infants to form goal-based concepts by inspiring them to represent things as equivalent. In fact, studies show that infants can more easily learn a goal-based concept, given a word, than a concept defined by physical similarity without a word. I don't know about you, but every time I think about this, I find it bloody amazing. Any animal can view a bunch of similar-looking objects and form a concept of them. But you can show human infants a bunch of objects that look different, sound different, and feel different, and merely add a word-a WORD-and these little babies form a concept that overcomes the physical differences. They understand that the objects have some kind of psychological similarity that can't be immediately perceived through the five senses. This similarity is what we called the goal of the concept. The infant creates a new piece of reality, a thing called a “wug” with the goal “to make a ringing noise.” From an infant's perspective, the concept “Wug” did not exist in the world before an adult taught it to her. This sort of social reality, in which two or more people agree that something purely mental is real, is a foundation of human culture and civilization. Infants thereby learn to categorize the world in ways that are consistent, meaningful, and predictable to us (the speakers), and eventually to themselves. Their mental model of the world becomes similar to ours, so we can communicate, share experiences, and perceive the same world. When my daughter, Sophia, was a toddler and I bought her a toy car, I didn't realize I was helping to extend her goal-based categories, honing her conceptual system for creating social reality. She'd hold that car close to a toy truck, and they'd transform into “mama” and “baby” as she made them “kiss.” Sometimes our goddaughter, Olivia, would visit, who is the same age, and the two girls would climb into the bathtub and engage in elaborate, imaginary dramas for hours, imposing new functions on toys, bars of soap, towels, and various bathroom items as the props in their water opera. A defining moment of humanity occurs when one child becomes an all-powerful being by draping a washcloth over her head and brandishing a toothbrush, and the second child kneels before her in supplication. When we, as adults, speak a word to a child, an act of great significance takes place without fanfare. In that moment, we offer the child a tool to expand reality-a similarity that is purely mental-and she incorporates it into the patterns that are being laid down inside her own brain for future use. In particular, as we shall now see, we hand her the tools to make and perceive emotions. Infants are born unable to see faces. They have no perceptual concept of “Face” and so are experientially blind. They quickly learn to see human faces, however, from the perceptual regularities alone: two eyes up top, a nose in the middle, and a mouth. If we observe this through the lens of the classical view of emotion, we could tell a story that infants statistically learn emotion concepts the same way, from perceptual regularities in the instances of happiness, sadness, surprise, anger, and other emotion categories that exist in the body or in other people's so-called emotional expressions. Many researchers, inspired by the classical view, have simply assumed that children's emotion concepts are scaffolded onto an inborn or early-to-develop understanding of facial expressions. This supposedly explains how children learn emotion words and also the causes and consequences of emotions. The stumbling block for this whole idea, we have learned, is that consistent emotion fingerprints don't exist in the face and body. Children must be gaining emotion concepts in some other way. We've also just seen that words invite infants to equate wildly dissimilar objects. Words encourage infants to search for similarities beyond the physical, similarities that act like a mental glue for concepts. Babies could reasonably learn emotion concepts in this manner. Instances of “Anger” might share no perceptual similarities, but the word “angry” could be grouping them into a single concept, just as infants grouped “wugs” and “daks.” I'm speculating for the moment, but the idea fits the data we've discussed. I try to imagine how my daughter, Sophia, might have learned emotion concepts when she was an infant, guided by the emotion words that my husband and I spoke to her intentionally. In our culture, one goal in “Anger” is to overcome an obstacle that someone blameworthy has put in your path. So, when a little friend would smack Sophia, sometimes she would cry and other times she'd swat back. When she didn't like her food, sometimes she'd spit it out and other times she'd smile and tip the bowl onto the floor. These physical actions were accompanied by different facial movements, different changes in her body budget (to match her physical actions), and different interoceptive patterns. Within this ongoing stream of activity, her father and I would utter streams of sounds: “Sophie, sweetie, are you angry?” “Don't be angry, honey.” “Sophie, you're feeling angry.”34 At first, these noises must have been novel to Sophia, but over time, if my hypothesis is correct, she learned statistically to associate these diverse body patterns and contexts with the sounds “an-gry,” just like associating a squeaking toy with the sound “wug.” Eventually, the word “angry” invited my daughter to search for a way in which these instances were the same, even if on the surface they looked and felt different. In effect, Sophia formed a rudimentary concept whose instances were characterized by a common goal: overcoming an obstacle. And most importantly, Sophia learned which actions and feelings most effectively achieved this goal in each situation. In this way, Sophia's brain would have bootstrapped the concept “Anger” into its neural architecture. When we first used the word “angry” with Sophia, we constructed her experiences of anger with her. We focused her attention, guiding her brain to store each instance in all its sensory detail. The word helped her to create commonalities with all the other instances of “Anger” already in her brain. Her brain also captured what preceded and followed those experiences. All of this became her concept of “Anger.”35 In our earlier encounter with Connecticut Governor Malloy, I described how viewers inferred his emotional state-intense sadness-by observing his movements and voice in a certain context. I think children learn to do the same thing. As they learn a concept such as “Anger,” they can predict and give meaning to other people's movements and vocalizations-smiles, shrugs, shouts, whispers, tightened jaws, widened eyes, even motionlessness -as well as their own bodily sensations, to construct perceptions of anger. Or, they can focus on predicting and giving meaning to their own interoceptive sensations, along with sensations from the world, to construct an emotional experience. As Sophia grew older, she extended her concept of “Anger” to people who slam doors, adding to her population of instances. And when she encountered a sneezing person and said, “Mama, that man is angry,” and I corrected her, she honed her concept of “Anger” yet again. Her brain gave sensations meaning, using concepts that fit the situation, to construct an instance of emotion. If I am correct, then, as children continue to develop their concept of “Anger,” they learn that not all instances of “Anger” are constructed for the same goal in every situation. “Anger” can also be for protecting oneself against an offense, dealing with someone who acted unfairly, desiring aggression toward another person, wanting to win a competition or to enhance performance in some way, or wishing to appear powerful. Following this line of reasoning, Sophia eventually would learn that anger- related words like “irritation,” “scorn,” and “vengeance” each referred to distinct goals that glued together variable populations of instances. And with this, Sophia developed an expert vocabulary of anger-related concepts that prepared her for the life of a typical American teenager. (For the record, she's not much for experiencing scorn or vengeance on a regular basis, but the concepts come in handy with other adolescents.) My guiding hypothesis, as you can see from my story of Sophia's development, is that emotion words hold the key to understanding how children learn emotion concepts in the absence of biological fingerprints and in the presence of tremendous variation. Not the words in isolation, mind you, but words spoken by other humans in the child's affective niche who use emotion concepts. These words invite a child to form goal-based concepts for “Happiness,” “Sadness,” “Fear,” and every other emotion concept in the child's culture. So far, my hypothesis about emotion words is only reasoned speculation because the science of emotion is missing a systematic exploration of this question. Certainly nothing like the creative studies of Waxman, Xu, Gelman, and other developmental psychologists has yet been conducted for emotion concepts and categories. But we have some compelling evidence that is consistent with this hypothesis. Some of the evidence comes from careful testing of children in the lab, which suggests that they don't develop adult-like emotion concepts like “Anger,” “Sadness,” and “Fear” until around age three. Younger children in Western cultures use words like “sad,” “scared,” and “mad” interchangeably to mean “bad”; they exhibit low emotional granularity, just like my graduate school test subjects for whom “depressed” and “anxious” meant nothing more than “unpleasant.” As parents, we may look at our infants and perceive emotions in their cries, wriggles, and smiles. Certainly infants feel pleasure and distress from birth, and affect-related concepts (pleasant/unpleasant) show up by three to four months of age. But there's a lot of research to indicate that adult-like emotion concepts develop later. Just how much later is an open question. Other evidence for my hypothesis about emotion words comes from a surprising source: people who work with chimpanzees. Jennifer Fugate, a former postdoctoral fellow in my lab, collected photographs of chimpanzee facial configurations that some scientists treat as emotional expressions, including “play” faces, “scream” faces, “bared teeth” faces, and “hoot” faces. She tested chimp experts and novices to see if they could recognize these configurations, and at first, none of them could do it. So we performed an experiment similar to those used with infants: half of our experts and novices viewed pictures of chimp facial configurations alone, and half viewed them labeled with made-up words, such as “peant” for the play face and “sahne” for the scream face. In the end, only our subjects who learned the words could correctly categorize new chimp facial configurations, demonstrating that they had acquired the concepts for the face categories. As children grow up, they definitely form a whole conceptual system for emotion. This includes all the emotion concepts they've learned in their lives, anchored by the words that name those concepts. They categorize different facial and bodily configurations as the same emotion, and a single configuration as many different emotions. Variation is the norm. So where is the statistical regularity that holds together a concept like “Happiness” or “Anger”? In the words themselves. The most visible commonality that all instances of “Anger” share is that they're all called “anger.” Once children have the initial emotion concept, other factors besides words become important to their developing conceptual system for emotion. They come to realize that emotions are events that develop over time. An emotion has a beginning or cause that precedes it (“My mommy walked into the room”). Then there's a middle, the goal itself that is happening now (“I am happy to see my mommy”). Then there's an end, the consequence of meeting the goal, which happens later (“I'll smile and my mommy will smile back and give me a hug”). This means that an instance of an emotion concept helps to make sense of longer continuous streams of sensory input, dividing them into distinct events. You see emotions in blinks, furrowed brows, and other muscle twitches; you hear emotions in the pitch and lilt of voices; you feel emotions in your own body, but the emotional information is not in the signal itself. Your brain was not programmed by nature to recognize facial expressions and other so- called emotional displays and then to reflexively act on them. The emotional information is in your perception. Nature provided your brain with the raw materials to wire itself with a conceptual system, with input from a chorus of helpful adults who spoke emotion words to you in a deliberate and intentional way. Concept learning does not stop in childhood-it continues throughout life. Sometimes a new emotion word appears in your primary language, engendering a new concept. For example, schadenfreude, a German emotion word meaning “pleasure from someone else's misfortune,” has now been incorporated into English. Personally, I'd like to add the Greek word stenahoria to English, which refers to a feeling of doom, hopelessness, suffocation, and constriction. I can think of a few romantic relationships where this emotion concept would have come in handy. Other languages commonly have emotion words whose associated concepts have no equivalent in English. For example, Russian has two distinct concepts for what Americans call “Anger.” German has three distinct “Angers” and Mandarin has five. If you were to learn any of these languages, you'd need to acquire these new emotion concepts to construct perceptions and experiences with them. You'll develop these concepts faster if you live with native speakers of the new language. The new concepts are affected by the older ones from your primary language. Native speakers of English who learn Russian, for example, must learn to distinguish between anger at a person, called serdit'sia, and anger for more abstract reasons such as the political situation, known as zlit'sia. The latter concept is more similar to the English concept of “Anger,” but Russian speakers use the former more frequently; as a result, English speakers use serdit'sia more frequently as well and wind up misapplying it. This is not an error in a biological sense, since neither concept has a biological fingerprint, but in a cultural sense. New emotion concepts from a second language can also modify those of your primary language. A research scientist in my lab, Alexandra Touroutoglou, came from Greece to learn neuroscience. As she became more proficient at speaking English, her Greek and English emotion concepts began to blend. For example, Greek has two concepts for “Guilt,” one for minor infractions and another for serious transgressions. English covers both situations with the single word “guilty.” When Alex would speak with her sister who was still in Greece, Alex would use the “major” guilt word (enohi) when describing, say, that she ate too much pie at our lab's beach party. To her sister, Alex came across as overly dramatic. In this case, Alex constructed her dessert experience using the English concept for guilt. I hope by now you appreciate the drama that is going on here. Emotion words are not about emotional facts in the world that are stored like static files in your brain. They reflect the varied emotional meanings you construct from mere physical signals in the world using your emotion knowledge. You acquired that knowledge, in part, from the collective knowledge contained in the brains of those who cared for you, talked to you, and helped you to create your social world. Emotions are not reactions to the world; they are your constructions of the world. Once your conceptual system is established in your brain, you need not explicitly recall or speak an emotion word to construct an instance of an emotion. In fact, you can experience and perceive an emotion even if you don't have a word for it. Most of us who speak English were able to enjoy someone else's misfortune long before the word schadenfreude entered our language. All you need is a concept. How do you get a concept without a word? Well, your brain's conceptual system has a special power called conceptual combination. It combines existing concepts to create your very first instance of a novel concept of emotion. My friend Batja Mesquita is a Dutch cultural psychologist, and the first time I traveled to visit her in Belgium, she told me that we were sharing the emotion gezellig. Curled up in her living room, sharing wine and chocolates, she explained that this emotion means the comfort, coziness, and togetherness of being at home, with friends and loved ones. Gezellig is not an internal feeling that one person has for another but a way of experiencing oneself in the world. No single word in English describes the experience of gezellig, but once Batja explained it to me, I immediately experienced it. Her use of the word invited me to form a concept as infants do, but through conceptual combination-I automatically employed my concepts of “Close Friend,” “Love,” and “Delight,” with a touch of “Comfort” and “Well-Being.” This translation was not perfect, though, because in my American way of experiencing gezellig, I used emotion concepts that focus more on internal feelings than those that describe the situation. Conceptual combination is a potent capability of the brain. Scientists still debate on the mechanisms responsible for it, but they pretty much agree that it's a basic function of the conceptual system. It allows you to construct a potentially limitless number of novel concepts from your existing ones. This includes goal-based concepts like “Things That Can Protect You from Stinging Insects,” in which the goal is short-lived. Conceptual combination is powerful, but it is far less efficient than having a word. If you asked me what I had for dinner this evening, I could say “baked dough with tomato sauce and cheese,” but this is much less efficient than saying “pizza.” Strictly speaking, you don't need an emotion word to construct an instance of that emotion, but it's easier when you have a word. If you want the concept to be efficient, and you want to transmit the concept to others, then a word is pretty handy. Infants can benefit from this “pizza effect” before they can speak. For example, prelinguistic infants generally can hold about three objects in mind at a time. If you hide toys in a box while an infant watches, she can remember up to three hiding places. However, if you label several toys with a nonsense word like “dax” and several more with “blicket” before hiding them- assigning the toys to categories-the infant can hold up to six objects in mind! This happens even if all six toys are physically identical, strongly suggesting that infants gain the same efficiency benefits from conceptual knowledge that adults do. Conceptual combination plus words equals the power to create reality. In many cultures, you will find people who have hundreds, perhaps thousands of emotion concepts, that is, they exhibit high emotional granularity. In English, for example, they might have concepts for anger, sadness, fear, happiness, surprise, guilt, wonder, shame, compassion, disgust, awe, excitement, pride, embarrassment, gratitude, contempt, longing, delight, lust, exuberance, and love, to name a few. They'll also have distinct concepts for interrelated words like “aggravation,” “irritation,” “frustration,” “hostility,” “rage,” and “disgruntlement.” This person is an emotion expert. A sommelier of emotion. Each word corresponds to its own emotion concept, and each concept can be used in the service of at least one goal, but usually many different goals. If an emotion concept is a tool, then this person has a gigantic toolbox fit for a skilled craftsperson. People who exhibit moderate emotional granularity might have dozens of emotion concepts rather than hundreds. In English, they might have concepts for anger, sadness, fear, disgust, happiness, surprise, guilt, shame, pride, and contempt; perhaps not many more than the so-called basic emotions. For these folks, words like “aggravation,” “irritation,” “frustration,” “hostility,” “rage,” “disgruntlement,” and so on would all belong to the concept “Anger.” This person has your run-of-the-mill little red toolbox, filled with some pretty handy tools. Nothing fancy, but they get the job done. People who exhibit low emotional granularity will have only a few emotion concepts. In English, they might have words in their vocabulary like “sadness,” “fear,” “guilt,” “shame,” “embarrassment,” “irritation,” “anger,” and “contempt,” but those words all correspond to the same concept whose goal is something like “feeling unpleasant.” This person has a few tools-a hammer and Swiss Army knife. Maybe this person gets along fine, but a few new tools wouldn't hurt, at least if he or she lives in a Western cultural setting. (My husband jokes that before we met, he knew only three emotions: happy, sad, and hungry.) When a mind has an impoverished conceptual system for emotion, can it perceive emotion? From scientific experiments in our own lab, we know that the answer is generally no. As you learned in chapter 3, we can easily interfere with people's ability to perceive anger in a scowl, sadness in a pout, and happiness in a smile by impairing their access to their emotion concepts. If people lack a well-developed conceptual system for emotion, what is their emotional life like? Will they feel only affect? These questions are difficult to test scientifically. Emotional experiences have no objective fingerprints in the face, body, or brain that would enable us to compute an answer. The best we can do is ask people how they feel, but they'd have to use emotion concepts to answer the question, defeating the purpose of the experiment! The way around this conundrum is to study people who have a naturally impoverished conceptual system for emotion, a condition called alexithymia, which by one estimate affects about 10 percent of the world's population. Its sufferers do have difficulty experiencing emotion, as the theory of constructed emotion would predict. In a situation where a person with a working conceptual system might experience anger, people with alexithymia are more likely to experience a stomachache. They complain of physical symptoms and report feelings of affect but fail to experience them as emotional. People with alexithymia have difficulty perceiving emotion in others as well. If a person with a working conceptual system saw two men shouting at each other, she might make a mental inference and perceive anger, whereas a person with alexithymia would report perceiving only shouting. People with alexithymia also have a restricted emotion vocabulary and have difficulty remembering emotion words. These clues provide further evidence that concepts are critical for experiencing and perceiving emotion. Concepts are linked to everything you do and perceive. And as you learned in the previous chapter, everything you do and perceive is linked to your body budget. Therefore, concepts must be linked to your body budget. And, in fact, they are. When you were born, you couldn't regulate your budget, so your caregivers did it for you. Each time your mother picked you up to feed you was a multisensory event with regularities: the sight of your mother's face, the sound of her voice, her motherly aroma, her touch, the taste of her milk (or formula), and your interoceptive sensations associated with being held and cuddled and fed. Your brain captured the entire sensory context in the moment, as a pattern of sights, sounds, smells, tastes, touches, and interoceptive sensations. This is how concepts begin to form. You learn in a multisensory way. Your inner-body changes and their interoceptive consequences are part of every concept that you learn, whether you're aware of it or not. When you categorize with your multisensory concepts, you're also regulating your body budget. When you played with a ball as a baby, you categorized it not just by its color and shape and texture (and by the smell of the room, the feel of the floor against your hands and knees, the lingering taste of whatever you last ate, and so on), but also by your interoceptive sensations in the moment. This allowed you to predict your actions, like swatting the ball or putting it into your mouth, which influenced your body budget. As an adult, when you learn that an event is an instance of some emotion, such as “Embarrassment,” you likewise capture the event's sights, sounds, smells, tastes, touches, and interoceptive sensations together as your concept. And when you make meaning using that concept, your brain again takes into account your entire situation. For example, if you surface from under the ocean waves onto the beach and notice that your swimsuit has fallen off, your brain might construct an instance of “Embarrassment.” Your conceptual system samples instances of embarrassed nakedness from your past, which is more taxing on your body budget than the refreshed nakedness after stepping out of a sauna, or the comfortable nakedness after a passionate afternoon with your lover. Depending on the immediate circumstances, your brain might also sample fully clothed instances of “Embarrassment” where you felt exposed, like answering a question wrongly in class, but not more private embarrassment like forgetting your best friend's birthday. Your brain samples from your larger conceptual system, as you've seen, according to your goal in a given situation. The winning instance guides you to regulate your body budget appropriately. All categorizations are based on probabilities. For example, if you are on vacation in Paris and you perceive a stranger frowning at you in a subway car, you might not have any past experience with that stranger or that subway, and you might not have visited Paris before, but your brain does have past experiences of other frowning people in unfamiliar places. Your brain can then construct a sample of concepts, based on past experience and probability, to use as predictions. Each added piece of context (Are you alone or is the car crowded? Is it a man or a woman? With raised or furrowed eyebrows?) allows your brain to hone the probabilities until it settles on the best-fitting concept that will minimize prediction error. This is categorization with emotion concepts. You aren't detecting or recognizing emotion in someone's face. You aren't recognizing a physiological pattern in your own body. You are predicting and explaining the meaning of those sensations based on probability and experience. This happens each time you hear an emotion word or are faced with an array of sensations. All of this categorization, context, and probability may seem remarkably counterintuitive. When I'm walking through the woods and see a monstrous snake in my path, I certainly don't say to myself, “Well, I actively predicted that snake from a population of competing concepts, which were constructed from the past and have some degree of similarity to this current set of sensations, thereby creating my perception.” I just “saw a snake.” And when I gingerly turn on my heels and run, I don't think, “I honed my many predictions down to one winning instance of the emotion category 'Fear,' causing me to run away.” No, I just feel terrified with an urge to flee. The fear comes on suddenly and uncontrollably, as if a stimulus (the snake) triggered a little bomb (a neural fingerprint) causing the response (fear and running). When I relate the snake story to my friends later, over coffee, I don't tell them, “Having constructed an instance of the concept 'Fear' to fit my surroundings using my past experience, my brain changed the firing of my visual neurons before the snake appeared on the path, preparing me to see the snake and to run in the other direction, and once my prediction was confirmed, my sensations were categorized, and I constructed an experience of fear that explained my sensations in terms of a goal, and I made a mental inference to perceive the snake as the cause of my feelings, and the running away as their consequence.” No, my story is much simpler: “I saw a snake. I screamed and fled.” Nothing about my encounter with the snake tells me that I was an architect of the whole experience. Nevertheless, I was that architect, whether I felt it or not, just as you were with the blobby bee. Even before I was aware of the snake, my brain was busy constructing an instance of fear. Or, if I am an eight-year-old girl hoping for a pet snake someday, I might construct an instance of excitement. If I am her parent who will allow a snake into my house over my dead body, I might construct an instance of irritation. The stimulus-response brain is a myth, brain activity is prediction and correction, and we construct emotional experiences outside of awareness. This explanation fits the architecture and operation of the brain. Simply put: I did not see a snake and categorize it. I did not feel the urge to run and categorize it. I did not feel my heart pounding and categorize it. I categorized sensations in order to see the snake, to feel my heart pounding, and to run. I correctly predicted these sensations, and in doing so, explained them with an instance of the concept “Fear.” This is how emotions are made. Right now, as you read these words, your brain is wired with a powerful conceptual system for emotion. It began purely as an information-gaining system, acquiring knowledge about your world through statistical learning. But words allowed your brain to go beyond the physical regularities that you learned, to invent part of your world, in a collective with other brains. You created powerful, purely mental regularities that helped you control your body budget in order to survive. Some of these mental regularities are emotion concepts, and they function as mental explanations for why your heart thumps in your chest, why your face flushes, and why you feel and act the way you do in certain circumstances. When we share those abstractions with each other, by synchronizing our concepts during categorization, we can perceive each other's emotions and communicate. That, in a nutshell, is the theory of constructed emotion-an explanation for how you experience and perceive emotion effortlessly without the need for emotion fingerprints. The seeds of emotion are planted in infancy, as you hear an emotion word (say, “annoyed”) over and over in highly varied situations. The word “annoyed” holds this population of diverse instances together as a concept, “Annoyance.” The word invites you to search for the features that the instances have in common, even if those similarities exist only in other people's minds. Once you have this concept established in your conceptual system, you can construct instances of “Annoyance” in the presence of highly variable sensory input. If the focus of your attention is on yourself during categorization, then you construct an experience of annoyance. If your attention is on another person, you construct a perception of annoyance. And in each case, your concepts regulate your body budget. When another driver cuts you off in traffic and your blood pressure rises, your hands become sweaty, and you shout as you slam on the brakes and feel annoyed . . this is an act of categorization. When your young child picks up a sharp knife and your breathing slows, your hands are dry, you smile, and you calmly ask her to put it down as you feel annoyed inside . . this is an act of categorization. When you see another person staring at you oddly with wide eyes and perceive him as annoyed, this is also an act of categorization. In all these instances, your conceptual knowledge of “Annoyance” drives the categorization, and your brain makes meaning that is tied to context. My story in chapter 2 about the guy in graduate school who asked me to lunch, when I thought I felt attraction but in fact I had the flu, is another example of categorization. My body budget was disrupted by a virus, but I experienced the resulting change in affect as attraction to my lunch partner because I'd constructed an instance of infatuation. If I'd categorized my symptoms in a different context, I might have understood them as something that a few Tylenol and a couple of days' rest could cure. Your genes gave you a brain that can wire itself to its physical and social environment. The people around you, in your culture, maintain that environment with their concepts and help you live in that environment by transmitting those concepts from their brains to yours. And later, you transmit your concepts to the brains of the next generation. It takes more than one human brain to create a human mind. What I have not yet explained, however, is how this all works inside the brain: the biology of categorization. What brain networks are involved? How is this process related to your brain's intrinsic, predictive powers, and how does it affect your all-important body budget? That is what we'll discuss next as you learn the final piece of the puzzle for how emotions are made in the brain."
  },
  {
    "index": 11,
    "level": 1,
    "start_page": 116,
    "end_page": 130,
    "title": "How the Brain Makes Emotions",
    "content": "How the Brain Makes Emotions. Have you ever wanted to punch your boss? I would never advocate workplace violence, of course, and many bosses are terrific work partners. But sometimes we are blessed with supervisors who personify the German emotion word Backpfeifengesicht, meaning “a face in need of a fist.” Suppose you have such a boss, and he's been handing you extra projects for almost a year. You've been expecting a promotion for all your good work, but he has just informed you that the promotion went to someone else. How would you feel? If you live in a Western culture, you'd likely feel angry. Your brain would issue numerous predictions of “Anger” simultaneously. One prediction might be to pound your fist on the desk and yell at your boss. Another is to stand up and walk slowly across the room toward your boss, leaning in menacingly to whisper, “You will regret this.” Or you could sit quietly in your chair as you scheme to undermine your boss's career. These diverse predictions of “Anger” have similarities, such as the boss, the lost promotion, and the common goal to exact vengeance. They also have plenty of differences, because yelling, whispering, and silence require different sensory and motor predictions. Your action also is different in each case (pounding, leaning, sitting), so your inner-body changes are different, as are the consequences for your body budget, and therefore the interoceptive and affective consequences are different as well. Ultimately, through a process we'll discuss shortly, your brain selects a winning instance of “Anger” that best fits your goal in this particular situation. The winning instance determines how you behave and what you experience. This process is categorization. The scenario with your boss could play out differently, however. You could be angry with a different goal, like changing your boss's mind, or maintaining social relations with the coworker who got the promotion in your place. Or you could construct an instance of a different emotion such as “Regret” or “Fear,” or a non-emotion like “Emancipation,” or a physical symptom like a “Headache,” or a perception that your boss is an “Idiot.” In each case, your brain follows a similar process, categorizing to best fit the entire situation and your internal sensations, based on past experience. Categorization means selecting a winning instance that becomes your perception and guides your action. It takes a rich set of concepts to construct emotion, as you read in the preceding chapter. Now you'll learn how your brain acquires and uses your conceptual system from your earliest moments as an infant. Along the way, you'll also learn the neural basis for several important topics you've seen previously: emotional granularity, population thinking, why emotions feel triggered rather than constructed, and why your body-budgeting regions can affect every decision and action you make.* When taken as a whole, these explanations hint at a unifying framework for how the brain makes meaning: one of the most extraordinary mysteries of the human mind. The infant brain is missing most of the concepts that we have as adults. Babies don't know what telescopes are, or sea cucumbers, or picnics, let alone purely mental concepts like “Whimsy” or “Schadenfreude.” A newborn is experientially blind to a great extent. Not surprisingly, the infant brain does not predict well. A grown-up brain is dominated by prediction, but an infant brain is awash in prediction error. So babies must learn about the world from sensory input before their brains can model the world. This learning is a primary task of the infant brain. At first, much of the onslaught of sensory input is new to an infant's brain, and its significance is undetermined, so little will be ignored. If sensory input is like a skipping stone on an ocean wave of brain activity, for infants the stone is a boulder. Infants absorb the sensory input around them and learn, learn, learn. The developmental psychologist Alison Gopnik describes babies as having a “lantern” of attention that is exquisitely bright but diffuse. In contrast, your adult brain has a network to shut out information that might sidetrack your predictions, allowing you to do things like read this book without distraction. You have a built-in “spotlight” of attention that illuminates some things, such as these words, while leaving other things in the dark. The infant brain's “lantern” cannot focus in this manner. As the months pass, if everything is working properly, the infant brain begins to predict more effectively. Sensations from the outside world have become concepts in the infant's model of the world; what was outside is now inside. These sensory experiences, over time, create the opportunity for the infant brain to make coordinated predictions that span the senses. A rumbling tummy in a bright room after awakening means that it's morning, whereas a warm wetness with bright overhead light means that it's evening bath time. When my daughter, Sophia, was only a few weeks old, we capitalized on such multisensory predictions to help her develop sleep patterns that would not reduce us to sleep-deprived zombies. We exposed her to distinct songs, stories, colored blankets, and other rituals to help her distinguish statistically between naptime and bedtime, so she would sleep for shorter or longer stretches. How does the infant brain, equipped with a smattering of concrete concepts and dominated by prediction error, eventually encompass thousands of complex, purely mental concepts like “Awe” and “Despair,” each of which is a population of diverse instances? This is actually a question of engineering, and its solution can be found in the architecture of the human cerebral cortex. It all comes down to some basic problems of efficiency and energy. An infant brain must continually learn and update its concepts in a changing environment. This task requires a mighty powerful, efficient brain. But this brain has practical constraints. Its networks of neurons can grow only so big and still fit inside a skull that can be birthed through a human pelvis. Neurons are also expensive little cells to keep alive (they require a lot of energy), and so a brain has a limit on how many connections it can support metabolically and still run. So the infant brain must transfer information efficiently by passing it to as few neurons as possible. The solution to this engineering challenge is a cortex that represents concepts so that similarities are separated from differences. This separation, as you will now see, leads to a tremendous optimization. Whenever you watch a video on YouTube, you're witnessing efficient information transfer of a similar kind. A video is a sequence of still images or “frames” displayed in rapid succession. There is great redundancy from one frame to the next, however, so when YouTube's server sends the stream of video information over the Internet to your computer or phone, it needn't send every single pixel from every frame. It's more efficient to communicate only what has changed from one frame to the next, because any static areas of the previous frame have already been transmitted. YouTube separates the video's similarities from its differences to speed up transmission, and software on your computer or phone assembles the pieces into a cohesive video. The human brain does much the same thing when it processes prediction error. The sensory information from sight is highly redundant like a video, and the same is true for sound, smell, and the other senses. The brain represents this information as patterns of firing neurons, and it's advantageous (and efficient) to represent it with as few neurons as possible. For example, the visual system represents a straight line as a pattern of neurons firing in primary visual cortex. Suppose that a second group of neurons fires to represent a second line at a ninety-degree angle to the first line. A third group of neurons could summarize this statistical relationship between the two lines efficiently as a simple concept of “Angle.” The infant brain might encounter a hundred different pairs of intersecting line segments of varying length, thickness, and color, but conceptually they are all instances of “Angle,” each of which gets efficiently summarized by some smaller group of neurons. These summaries eliminate redundancy. In this manner, the brain separates statistical similarities from sensory differences. In the same manner, the instances of the concept “Angle” are themselves part of other concepts. For example, an infant receives visual input about her mother's face from many different vantage points: while nursing, while sitting face to face, in the morning and the evening. Her concept of “Angle” will be part of her concept “Eye” that summarizes the continuously changing lines and contours of her mother's eyes seen at different angles and in different luminances. Different groups of neurons fire to represent the various instances of the concept “Eye,” allowing the infant to recognize those eyes as her mother's eyes each time, regardless of the sensory differences. As we go from very specific to increasingly general concepts (in this example, from line to angle to eye), the brain creates similarities that are progressively more efficient summaries of the information. For example, “Angle” is an efficient summary with respect to lines but is a sensory detail with respect to eyes. The same logic works for the concepts “Nose” and “Ear” and so on. Together, these concepts are part of the concept “Face,” whose instances are yet more efficient summaries of the sensory regularities in facial features. Eventually, the infant's brain forms summary representations for enough visual concepts that she can see one stable object, despite incredible variation in low-level sensory details. Think about it: each of your eyes transmits millions of tiny pieces of information to your brain in a moment, and you simply see “a book.” This principle-finding similarities in the service of efficiency-doesn't just describe the visual system; it also operates within each sensory system (sounds, smells, interoceptive sensations, and so on), and for patterns of different senses in combination. Consider a purely mental concept like “Mother.” As a baby nurses one morning, groups of neurons fire in her various sensory systems, in statistically related patterns, to represent the mother's visual image, the sound of her voice, her scent, the tactile sensations of being held, an increase in energy from being fed, the sensations of a full tummy, plus the pleasure of feeding and being cuddled. All of these representations are interrelated, and their summary is represented elsewhere, in the pattern of firing within a smaller group of neurons, as a rudimentary, multisensory instance of “Mother.” During nursing again later in the day, other summaries of the concept “Mother” will be similarly created, using similar, but not identical, groupings of neurons. And as the infant swats at a hanging toy above the crib, watches the toy swing through the air, and feels any associated tactile and interoceptive sensations, all of which are linked with a decrease in energy due to her movement, her brain summarizes these statistically related events as a rudimentary, multisensory instance of the concept “Self.”6 In this manner, an infant's brain distills widely dispersed firing patterns for individual senses into one multisensory summary. This process reduces redundancy and represents the information in a minimal, efficient form for future use. It's like dehydrated food that takes up less space but needs to be reconstituted before eating. This efficiency makes it practical for the brain to form rudimentary concepts such as “Mother” and “Self” that result from learning. As a child gets older, her brain begins to predict more effectively using her concepts-but of course she still makes mistakes. When Sophia was three years old, for instance, we were in a shopping mall when she spotted a man ahead of us, with his hair in dreadlocks. She knew three people with dreadlocks at that time: her beloved Uncle Kevin, who is medium height and dark-skinned; an acquaintance who also has dark skin but is quite tall and broad-shouldered; and one of our neighbors, who is female and short with light skin. In that moment, Sophia's brain was furiously launching multiple, competing predictions that could potentially become her experience. For the sake of argument, let's say this included 100 predictions of Uncle Kevin from Sophia's past experience, from different places and times and angles, along with 14 predictions of her acquaintance, and 60 predictions of her female neighbor. Each prediction was assembled from bits and pieces of patterns in her brain, all mixed and matched. These 174 predictions were also accompanied by many other predictions of people, places, and things from Sophia's prior experiences-anything at all that was statistically related to the scene in front of her. In total, Sophia's population of 174 predictions is what we've been calling a “concept” (in this case, the concept “People with Dreadlocks”). When we say these instances are “grouped” as a concept, be aware that there is no “grouping” stored anywhere in Sophia's brain. Any given concept is not represented in the information flow among one single set of neurons; each concept is itself a population of instances, and these instances are represented in different patterns of neurons on each occasion. (This is degeneracy.) The concept is constructed in the moment, ad hoc. And among these myriad instances, one of them will be the most similar (by pattern matching) to Sophia's current situation. That's what we've been calling the “winning instance.”7 On that particular day, Sophia leaped out of her stroller, ran across the mall, and wrapped her little arms around the man's leg, shouting, “Uncle KEVIN!”. Her delight was short-lived, however, as Uncle Kevin was at home six hundred miles away. She looked up into a total stranger's face and shrieked.* The same general process occurs for purely mental concepts such as “Sadness.” A child hears the word “sad” spoken in three different situations. These three instances are represented in the child's brain in bits and pieces. They are not “grouped together” in any concrete way. On a fourth occasion, the child sees a boy in her classroom crying, and a teacher uses the word “sad.” The child's brain constructs the three prior instances as predictions, along with other predictions that are statistically similar in any way to the current situation. This collection of predictions is a concept created in the moment, by virtue of some purely mental similarity among the instances of “Sadness.” Once again, the prediction that is most similar to the current situation becomes her experience-an instance of emotion. It's time for me to explain something directly what so far I have only implied. Two of the phenomena I've been discussing are actually one and the same. I'm speaking of concepts and predictions. When your brain “constructs an instance of a concept,” such as an instance of “Happiness,” that is equivalent to saying your brain “issues a prediction” of happiness. When Sophia's brain issued 100 predictions about Uncle Kevin, each one was an instance of the momentary concept “Uncle Kevin” that she formed before grabbing the stranger's leg. I separated the ideas of predictions and concepts earlier to simplify some explanations. I could have used the word “prediction” throughout the book and never mentioned the word “concept,” or vice versa, but information transmission is easier to understand in terms of predictions flying across the brain, whereas knowledge is more readily understood in terms of concepts. Now that we're discussing how concepts work in the brain, we must acknowledge that concepts are predictions. Early in life, you build up concepts from detailed sensory input (as prediction error) from your body and the world. Your brain efficiently compresses the sensory input it receives, just like YouTube compresses video, extracting similarities out of differences, eventually creating an efficient, multisensory summary. Once your brain has learned a concept in this manner, it can run this process in reverse, expanding the similarities into differences to construct an instance of the concept, much as your computer or phone expands the incoming YouTube video for display. This is a prediction. Think of prediction as “applying” a concept, modifying the activity in your primary sensory and motor regions, and correcting or refining as needed. Imagine that you're in a shopping mall, as I was with my daughter, strolling from store to store. The mall is filled with sounds, people are bustling about, the shop windows are overflowing with tempting products for sale, and your brain is busy issuing thousands of simultaneous predictions as usual. “There is motion in front of me.” “There is motion to my left.” “My breathing is slowing down.” “My stomach is rumbling.” “I hear laughter.” “I am calm.” “I am lonely.” “I see my neighbor.” “I see that nice guy who works at the post office.” “I see my Uncle Kevin.” Let's say that those last three predictions about people are instances of a concept for “Happiness,” having to do with feeling connected to friends. Your brain simultaneously constructs many instances of this concept, based on past experiences in similar situations when you have unexpectedly bumped into friends. Each instance has some probability of being correct at that moment. Let's give our focus to one of those instances, your prediction that you see your beloved Uncle Kevin unexpectedly in a shopping mall. Your brain issues this prediction because, at some time in the past, you saw Uncle Kevin in a similar situation and experienced sensations that you categorized as happiness. How well will this prediction match your incoming sensory inputs right now? If it matches better than all the other predictions, then you will experience this instance of “Happiness.” If not, then your brain will adjust the prediction, and you might experience an instance of “Disappointment.” Or if need be, your brain will make the prediction match the sensory input, and you will mistakenly perceive someone else to be your Uncle Kevin, as Sophia did in the shopping mall that day. So there you are, standing in the mall, and your brain must determine whether its prediction of Uncle Kevin ultimately becomes your perception and directs your action, or whether a course correction is required. To determine the details, the brain unpacks the summary of all the sensory input into a gigantic cascade of more detailed predictions, like uncompressing a YouTube video for viewing, or adding water to dehydrated food to make it edible. This process, shown in figure 6-1, is the same one that builds up a concept from details, but in reverse. For example, when the prediction of “Happiness” reaches the upper portions of the visual system, the prediction might unpack into details of Uncle Kevin's appearance, say, whether he is facing toward you or away from you, and what clothing he is wearing. These details are themselves predictions based on probabilities (e.g., Uncle Kevin never wears plaid), so your brain can compare the simulation to actual sensory input and compute and resolve any prediction error. This resolution does not happen in a single step but in millions of bits and pieces (as the prediction loops discussed in chapter 4). Each visual detail is unpacked into even more detailed predictions in turn, for (say) colors, shirt texture, and so on, each of which involves more prediction loops and cascading and unpacking. The cascade ends in the brain's primary visual cortex, which represents your lowest-level visual concepts in a tornado of ever-changing lines and edges. Figure 6-1: The concept cascade. When you develop a concept (right to left), sensory input is compressed into efficient, multisensory summaries. When you construct an instance of a concept by prediction (left to right), those efficient summaries unpack into ever more detailed predictions, which are checked against actual sensory input at each stage. Cascades begin-of all places-within our old friend the interoceptive network.* That's where multisensory summaries are constructed in your brain. Cascades end in your primary sensory regions, where the tiniest details of your experience are represented, not just for vision as in our example but also for sound, touch, interoception, and the rest of your senses. If one cascade of predictions accounts for the incoming sensory input- Uncle Kevin is indeed in front of you, his hair pulled back in a particular way, wearing a particular shirt, his voice sounding a particular way, your body in a particular state, and so on-then you have constructed an instance of “Happiness” having to do with feeling connected to friends. That is, the entire cascade is that instance of the concept “Happiness” as you glimpse your uncle. You are feeling happy. The concept cascade reveals the neural reasons for several of the claims I've made earlier in the book. First, your cascade of predictions explains why an experience like happiness feels triggered rather than constructed. You're simulating an instance of “Happiness” even before categorization is complete. Your brain is preparing to execute movements in your face and body before you feel any sense of agency for moving, and is predicting your sensory input before it arrives. So emotions seem to be “happening to” you, when in fact your brain is actively constructing the experience, held in check by the state of the world and your body. Second, the cascade explains a statement I made in chapter 4, that every thought, memory, emotion, or perception that you construct in your life includes something about the state of your body. Your interoceptive network, which regulates your body budget, is launching these cascades. Every prediction you make, and every categorization your brain completes, is always in relation to the activity of your heart and lungs, your metabolism, your immune function, and the other systems that contribute to your body budget. Third, the cascade also highlights the neural advantages of high emotional granularity, the phenomenon (described in chapter 1) of constructing more precise emotional experiences. When your brain constructs multiple instances of “Happiness” at seeing Uncle Kevin, it must sort out which one best resembles your current sensory input, to become the winning instance. This is a big job for your brain with some metabolic cost. But imagine if the English language had a more specific word than “happiness” for feeling attachment to a close friend, such as the Korean word jeong (정). Your brain would require less effort to construct with this more precise concept. Even better, if you had a special word for “happiness at feeling close to my Uncle Kevin,” your brain could be even more efficient at determining the winning instance. On the other hand, if you were constructing with the very broad concept “Pleasant Feeling” rather than “Happiness,” your brain's job would be harder. Preciseness leads to efficiency; this is a biological payoff of higher emotional granularity. Finally, we're seeing population thinking in action in the brain, because multiple predictions make up a concept in the moment. You do not construct just one instance of “Happiness” and experience it. You construct a large population of predictions, each of which has its own cascade. That population is a concept. It doesn't represent the sum total of everything you know about happiness, just summaries that fit your goal-bumping into a friend-in a similar situation. In a different, happiness-related situation, like receiving a gift or hearing your favorite song, your interoceptive network would launch very different summaries (and cascades) representing “Happiness” in that moment. These dynamic constructions are another example of efficiency in the brain. Scientists have known for some time that knowledge from the past, wired into brain connections, creates simulated experiences of the future, such as imagination. Other scientists focus on how this knowledge creates experiences of the present moment. The Nobel laureate and neuroscientist Gerald M. Edelman called your experiences “the remembered present.” Today, thanks to advances in neuroscience, we can see that Edelman was correct. An instance of a concept, as an entire brain state, is an anticipatory guess about how you should act in the present moment and what your sensations mean. My description of the concept cascade is just a sketch of a much larger parallel process. In real life, your brain never categorizes 100 percent with one concept and 0 percent with others. Predictions are more probabilistic than that. Your brain launches thousands of predictions simultaneously in every moment, in a storm of probabilities, and never lingers on a single winning instance. When you construct one hundred varied, simultaneous predictions of Uncle Kevin in a moment, each one is a cascade. (If you're interested in more details about the neuroscience, see appendix D.)13 Each time you categorize with concepts, your brain creates many competing predictions while being bombarded by sensory input. Which predictions should be the winners? Which sensory input is important, and which is just noise? Your brain has a network to help resolve these uncertainties, known as your control network. This is the same network that transforms an infant's “lantern” of attention into the adult “spotlight” you have now. The famous optical illusion in figure 6-2 illustrates your control network in action. Depending on the context, whether you read horizontally or vertically, you'll perceive the central symbol as a “B” or a “13.” Your control net work helps select the winning concept-letter or number?-in each moment. Figure 6-2: The control network helps the brain select among potential categorizations: in this case, “B” versus “13.” Your control network also helps construct instances of emotion. Suppose you've recently argued with your significant other, and now you're having chest pain. Is it a heart attack, indigestion, an experience of anxiety, or a perception that your partner's being unreasonable? Your interoceptive network will launch hundreds of competing instances of different concepts, each a brain-wide cascade, to resolve this quandary. Your control network assists in efficiently constructing and selecting among the candidate instances so your brain can pick a winner. It helps neurons to participate in certain constructions rather than others, and keeps some concept instances alive while suppressing others. The result is akin to natural selection, in which the instances most suitable to the current environment survive to shape your perception and action. The name “control network” is unfortunate because it implies a central position of authority, as if the network were making decisions and conducting the process. This is not the case. Your control network is more of an optimizer. It constantly tinkers with the information flow among neurons, ramping up the firing rate of some neurons and slowing down others, which moves sensory input in and out of your attentional spotlight, making some predictions fit while others become irrelevant. It's like a car-racing team that constantly optimizes the engine and body to make a car slightly faster and safer. This tinkering ultimately helps your brain simultaneously to regulate your body budget, produce a stable perception, and launch an action. Your control network helps select between emotion and non-emotion concepts (is this anxiety or indigestion?), between different emotion concepts (is this excitement or fear?), between different goals for an emotion concept (in fear, should I escape or attack?), and between different instances (when running to escape, should I scream or not?). When you're watching a movie, your control network might favor your visual and auditory systems, transporting you into the story. At other times it might background the traditional five senses in favor of more intense affect, resulting in an experience of emotion. Much of this tinkering happens outside your awareness. Some scientists refer to the control network as an “emotion regulation” network. They assume that emotion regulation is a cognitive process that exists separately from emotion itself, say, when you're pissed off at your boss but refrain from punching him. From the brain's perspective, however, regulation is just categorization. When you have an experience that feels like your so-called rational side is tempering your emotional side-a mythical arrangement that you've learned is not respected by brain wiring-you are constructing an instance of the concept “Emotion Regulation.”19 Your control network and interoceptive network, as you've now seen, are critical for constructing emotion. Moreover, these two core networks together contain most of the major hubs for communication throughout the entire brain. Think about the world's largest airports that serve multiple airlines. A traveler in JFK International Airport in New York can switch between American Airlines and British Airways because the two airlines overlap there. Likewise, information can pass efficiently between different networks in your brain via the major hubs in the interoceptive and control networks. These major hubs help to synchronize so much of your brain's information flow that they might even be a prerequisite for consciousness. If any of these hubs become damaged, your brain is in big trouble: depression, panic disorder, schizophrenia, autism, dyslexia, chronic pain, dementia, Parkinson's disease, and attention deficit hyperactivity disorder are all associated with hub damage. The major hubs in your interoceptive and control networks make possible what I describe in chapter 4, that your everyday decisions are driven by your body-budgeting regions-your inner, loudmouthed, mostly deaf scientist who views the world through affect-colored glasses. You see, your brain's body- budgeting regions are major hubs. Through their massive connections, they broadcast predictions that alter what you see, hear, and otherwise perceive and do. That's why, at the level of brain circuitry, no decision can be free of affect. I've said several times that the brain acts like a scientist. It forms hypotheses through prediction and tests them against the “data” of sensory input. It corrects its predictions by way of prediction error, like a scientist adjusts his or her hypotheses in the face of contrary evidence. When the brain's predictions match the sensory input, this constitutes a model of the world in that instant, just like a scientist judges that a correct hypothesis is the path to scientific certainty. Several years ago, my family was eating dinner in our kitchen in Boston when suddenly, simultaneously, all of us had a sensation that was entirely new. Our chairs tipped backward for a moment, then righted themselves, but in a curvy sort of way like cresting an ocean wave. This completely novel experience left us in a state of experiential blindness, so we started forming hypotheses. Did we all simply lose our balance momentarily? No, that wasn't likely to happen to three people at once. Did a car crash outside the house? No, we hadn't heard anything. Had a building exploded far away, out of audible range, making the ground tremble? Maybe, but the feeling wasn't so much a tremble as a swoop. What about an earthquake? Maybe, but we'd never been in an earthquake before, and ours had lasted only one second, much shorter than earthquakes we'd seen in disaster movies. However, the rising and falling shape, an almost sinusoidal motion, was consistent with our understanding of earthquakes. An earthquake was the best match to our knowledge, so we settled on that hypothesis. A few hours later, we learned that a magnitude 4. earthquake had struck in nearby Maine and rippled throughout New England. This same process of elimination that my family performed consciously, the brain does naturally, automatically, and extremely rapidly. Your brain has a mental model of the world as it will be in the next moment, developed from past experience. This is the phenomenon of making meaning from the world and the body using concepts. In every waking moment, your brain uses past experience, organized as concepts, to guide your actions and give your sensations meaning. I've been calling this process “categorization,” but it's known by many other names in science. Experience. Perception. Conceptualization. Pattern completion. Perceptual inference. Memory. Simulation. Attention. Morality. Mental Inference. In the folk psychology of daily life, these words mean different things, and scientists often study them as different phenomena, assuming each is produced by a distinct process in the brain. But really, they arise via the same neural processes. When I feel cheerful as my nephew Jacob exuberantly wraps his little arms around my neck for a big hug, this is conventionally called “an emotional experience.” When I see happiness in the big smile on his face as he is hugging me, I am no longer experiencing but “perceiving.” When I recollect the hug and how warm it made me feel, I am no longer perceiving but “remembering.” When I contemplate whether I was feeling happy or sentimental, I am no longer remembering but “categorizing.” My view is that these terms don't mark sharp distinctions, and they can all be accounted for with the same brain ingredients for making meaning. To make meaning is to go beyond the information given. A fast-beating heart has a physical function, such as getting enough oxygen to your limbs so you can run, but categorization allows it to become an emotional experience such as happiness or fear, giving it additional meaning and functions understood within your culture. When you experience affect with unpleasant valence and high arousal, you make meaning from it depending on how you categorize: Is it an emotional instance of fear? A physical instance of too much caffeine? A perception that the guy talking to you is a jerk? Categorization bestows new functions on biological signals, not by virtue of their physical nature but by virtue of your knowledge and the context around you in the world. If you categorize the sensations as fear, you are making meaning that says, “Fear is what caused these physical changes in my body.” When the concepts involved are emotion concepts, your brain constructs instances of emotion. When you perceived the blobby picture in chapter 2 as a bee, you made meaning from the visual sensations. Your brain accomplished this feat by predicting a bee and simulating lines to connect the blobs. Prior experience- seeing the real bee photograph-encouraged your brain to leave the prediction uncorrected. As a result, you perceived a bee in the blobs. Your prior experiences shape the meaning of momentary sensations. This same miraculous process makes emotion. Emotions are meaning. They explain your interoceptive changes and corresponding affective feelings, in relation to the situation. They are a prescription for action. The brain systems that implement concepts, such as the interoceptive network and the control network, are the biology of meaning-making. So, now you know how emotions are made in the brain. We predict and categorize. We regulate our body budgets, as any animal does, but wrap this regulation in purely mental concepts like “Happiness” and “Fear,” that we construct in the moment. We share these purely mental concepts with other adults, and we teach them to our children. We make a new kind of reality and live in it every day, mostly unaware that we are doing so. That's the topic of the next chapter."
  },
  {
    "index": 12,
    "level": 1,
    "start_page": 131,
    "end_page": 152,
    "title": "Emotions as Social Reality",
    "content": "Emotions as Social Reality. If a tree falls in the forest and no one is present to hear it, does it make a sound? This clichéd question has been asked to death by philosophers and grade-school teachers, but it also reveals something critical about human experience and, in particular, how we experience and perceive emotion. The common-sense answer to this riddle is yes, of course a falling tree makes a sound. If you and I were walking in the forest at the time, we would clearly hear the cracking of the wood, the rustling of the leaves, and the monstrous thud as the trunk slammed into the forest floor. It seems obvious that this sound would be present even if you and I were not. The scientific answer to the riddle, however, is no. A falling tree itself makes no sound. Its descent merely creates vibrations in the air and the ground. These vibrations become sound only if something special is present to receive and translate them: say, an ear connected to a brain. Any mammalian ear will do nicely. The outer ear gathers changes in air pressure and focuses them on the eardrum, producing vibrations in the middle ear. These vibrations move fluid in the inner ear over little hairs that translate the pressure changes into electrical signals that are received by the brain. Without this special machinery, there is no sound, only air movement. Even after the brain receives these electrical signals, its task is not complete. This wave must still be interpreted as the sound of a toppling tree. For this, the brain needs the concept of “Tree” and what trees can do, such as fall in a forest. This concept can come from prior experience with trees, or from learning about trees in a book, or from another person's description. Without the concept, there is no crashing timber, only the meaningless noise of experiential blindness. A sound, therefore, is not an event that is detected in the world. It is an experience constructed when the world interacts with a body that detects changes in air pressure, and a brain that can make those changes meaningful. Without a perceiver there is no sound, only physical reality. In this chapter, we explore another kind of reality that we humans construct, which exists only for those who are equipped to perceive it. Within this effortless ability lies an answer to the question, “What is an emotion?” It also explains how emotions are passed down through the generations without biological fingerprints. Next, consider another question: “Is an apple red?” This is also a riddle, but less obviously so than the one about the falling tree. Again, the common- sense answer is yes, the apple is red (or yellow or green if you prefer). The scientific answer, however, is no. “Red” is not a color contained in an object. It is an experience involving reflected light, a human eye, and a human brain. We experience red only when light of a certain wavelength (say, 600 nanometers) reflects from an object (in the midst of other reflections at other wavelengths), and only while a receiver translates this contrasting array of light into visual sensations. Our receiver is the human retina, which uses its three types of photoreceptors, called cones, to convert the reflected light into electrical signals made meaningful by a brain. In a retina that's missing a medium or long cone, light at 600 nanometers is experienced as gray. And in the absence of a brain, there is no experience of color at all, only reflected light in the world. Even with the right equipment in place (the eye and the brain), the experience of a red apple is not a done deal. For the brain to convert a visual sensation into the experience of red, it must possess the concept “Red.” This concept can come from prior experience with apples, roses, and other objects you perceive as red, or from learning about red from other people. (Even people who are blind since birth have a concept of “Red” that they learn from conversations and books.) Without this concept, the apple would be experienced differently. For instance, to the Berinmo people of Papua New Guinea, apples reflecting light at 600 nanometers are experienced as brownish, because Berinmo concepts for color divide up the continuous spectrum differently. These riddles about apples and trees invite us, as perceivers, to wrestle with two conflicting points of view. On one hand, common sense tells us that sounds and colors exist in the world beyond our skin, and we detect them with eyes and ears that carry the information to the brain. On the other hand, as we learned in chapters 4-6, we humans are architects of our own experiences. We do not passively detect physical changes in the world. We actively participate in constructing our experiences even though we are mostly unaware of that fact. An object might seem to transmit information about its color into your brain, but the information required for you to experience color comes mainly from your predictions, corrected by the light that your brain takes in from the world. With prediction, you can “see” color in your mind's eye on demand. Try right now to see the green colors of a verdant forest. The colors might not be as vivid as usual and the experience may be fleeting, but you can probably do it. And as you do, neurons in your visual cortex change their firing. You are simulating green. You can also imagine a crashing tree and hear the sound in your mind. Try it, and neurons in your auditory cortex will change their firing. Changes in air pressure and wavelengths of light exist in the world, but to us, they are sounds and colors. We perceive them by going beyond the information given to us, making meaning from them using knowledge from past experience, that is, concepts. Every perception is constructed by a perceiver, usually with sensory inputs from the world as one ingredient. Only certain changes in air pressure are heard as trees falling. Only some of the wavelengths of light striking our retinas are transformed into the experience of red or green. To believe otherwise is naive realism, as if perceptions were synonymous with reality. A third and final riddle is, “Are emotions real?” You might think this question is ridiculous, a classic example of academic indulgence. Of course emotions are real. Think about the last time you were thrilled or sad or furious. These were clearly real feelings. But in fact, this third riddle is like the falling tree and the red apple: a dilemma about what exists in the world versus in the human brain. The riddle forces us to confront our assumptions about the nature of reality and our role in creating it. But here, the answer is a bit more complex, because it depends on what we mean by “real.” If you talk to a chemist, “real” is a molecule, an atom, a proton. To a physicist, “real” is a quark, a Higgs boson, or maybe a collection of little strings vibrating in eleven dimensions. They are supposed to exist in the natural world whether or not humans are present-that is, they are thought to be perceiver-independent categories. If all human life left this planet tomorrow, subatomic particles would still be here. But evolution has provided the human mind with the ability to create another kind of real, one that is completely dependent on human observers. From changes in air pressure, we construct sounds. From wavelengths of light, we construct colors. From baked goods, we construct cupcakes and muffins that are indistinguishable except by name (chapter 2). Just get a couple of people to agree that something is real and give it a name, and they create reality. All humans with a normally functioning brain have the potential for this little bit of magic, and we use it all the time. Figure 7-1: Queen Anne's lace If you doubt your power as a conjurer of reality, look at figure 7-1. This plant is daucus carota, better known as Queen Anne's lace. Usually the outer blooms are white, but in rare cases they are pink (i.e., they reflect light at a wavelength that people in my culture experience as pink). My friend Kevin (“Uncle Kevin” from the previous chapter) once went to extraordinary lengths to purchase a pink Queen Anne's lace, which he planted proudly at the center of his garden. One day, he and I were having tea in his yard when another friend stopped by. Kevin and I popped inside to get some tea for her. We returned just in time to watch the friend shake her head, stoop, and with deftness born from decades of experience, rip the Queen Anne's lace out of the ground. Nothing in the natural world indicates whether a plant is definitively a flower or a weed. Queen Anne's lace is a flower to Kevin but a weed to his friend. The distinction depends on the perceiver. A rose is usually considered a flower, but it becomes a weed if you discover it in a field of vegetables. A dandelion is often considered a weed, but it transforms into a flower when placed in a bouquet of wildflowers or if it's a gift from your two-year-old child. Plants exist objectively in nature, but flowers and weeds require a perceiver in order to exist. They are perceiver-dependent categories. Albert Einstein illustrated this point nicely when he wrote, “Physical concepts are free creations of the human mind, and are not, however it may seem, uniquely determined by the external world.”5 Common sense leads us to believe that emotions are real in nature and exist independent of any observer, in the same manner as Higgs bosons and plants. Emotions seem to be present in wiggling eyebrows and wrinkled noses, in sagging shoulders and sweaty palms, in racing hearts and squirts of cortisol, and in silence, screams, and sighs. Science, however, tells us that emotions require a perceiver, just as colors and sounds do. When you experience or perceive emotion, sensory input is transformed into patterns of firing neurons. At the time, if you focus your attention on your body, you experience emotions as if they are happening in your body, just like you experience red color in the apple and sound in the world. If you're instead focusing attention on the world, you experience faces and voices and bodies as if they express emotion for you to decode. But as we learned in chapter 5, your brain categorizes using emotion concepts to make these sensations meaningful. The result is that you construct instances of happiness, fear, anger, or other emotion categories. Emotions are real, but real in the same manner of the sound of a tree falling, the experience of red, and the distinctions between flowers and weeds. They are all constructed in the brain of a perceiver. You move your facial muscles all the time. Your eyebrows scrunch. Your lips curl. Your nose wrinkles. These actions are perceiver-independent and they help you sample the sensory world. Widening your eyes enhances your peripheral vision, so you can more easily detect objects surrounding you. Narrowing your eyes improves your visual acuity for objects right in front of you. Wrinkling your nose helps to block noxious chemicals. But these movements are not intrinsically emotional. Inside your body, your heartbeat, blood pressure, breathing, temperature, and cortisol level fluctuate throughout the day. These changes have physical functions to regulate your body in the world; they are perceiver-independent. They also are not intrinsically emotional. Your muscle movements and bodily changes become functional as instances of emotion only when you categorize them that way, giving them new functions as experiences and perceptions. Without emotion concepts, these new functions don't exist. There are only moving faces, beating hearts, circulating hormones, and so on, just as without color concepts, “red” and the sound of a falling tree would not exist. There'd be only light and vibrations. Historically, scientists have debated whether emotion categories like fear and anger are real in nature or illusory. We learned in chapter 1 that those who adhere to the classical view believe that emotion categories are carved in nature, with every instance of (say) “Fear” sharing a common biological fingerprint. Emotion concepts in your head, they say, exist separately from those natural categories. Critics usually counter that anger, fear, and so on, are mere words from folk psychology and should be discarded for scientific endeavors. Early in my journey, I took this latter view, but I now think there's another possibility that's more realistic. The distinction between “real in nature” versus “illusory” is a false dichotomy. Fear and anger are real to a group of people who agree that certain changes in the body, on the face, and so on, are meaningful as emotions. In other words, emotion concepts have social reality. They exist in your human mind that is conjured in your human brain, which is part of nature. The biological processes of categorization, which are rooted in physical reality and are observable in the brain and body, create socially real categories. Folk concepts like “fear” and “anger” are not mere words to be discarded from scientific thought but play a critical role in the story of how the brain creates emotion. Social reality is not just about trivial-sounding examples like flowers, weeds, and red apples. Human civilization is literally built with social reality. Most things in your life are socially constructed: your job, your street address, your government and laws, your social status. Wars are waged and neighbor slaughters neighbor, all for the sake of social reality. When Benazir Bhutto, the late prime minister of Pakistan, said that “You can kill a man, but not an idea,” she was proclaiming the power of social reality to reshape the world. Money is a classic example of social reality. Given a rectangle of paper with a dead leader's face printed on it, or a metal disk or a shell or some barley, a group of people categorized that object as money, and it became money. We exchange billions of dollars every day based on social reality called a stock market. We study economies scientifically with complicated mathematical equations. The disastrous effects of the financial crisis of 2008 were a product of social reality. In a matter of moments, a collection of mortgages-themselves constructs of social reality-went from valuable to worthless, hurling people into economic ruin. Nothing objective in biology or physics caused this to happen. It was just one collective and devastating change of imagination. And consider this: what is the difference between two hundred one-dollar bills and a silk-screened painting of two hundred one- dollar bills? The answer is, “about $43. million.” That's the price paid in 2013 for Andy Warhol's painting “200 One Dollar Bills.” The painting is exactly what its title sounds like, scarcely different from the currency it depicts. The colossal difference in value is entirely social reality. The price also fluctuates-the work sold for a mere $300,000 in the 1990s, a relative bargain-which also reflects social reality. If $43. million seems like a high price to you, then you're a participant in this social reality. Make something up, give it a name, and you've created a concept. Teach your concept to others, and as long as they agree, you've created something real. How do we work this magic of creation? We categorize. We take things that exist in nature and impose new functions on them that go beyond their physical properties. Then we transmit these concepts to each other, wiring each other's brains for the social world. This is the core of social reality. Emotions are social reality. We construct instances of emotion in exactly the same manner as colors, falling trees, and money: using a conceptual system that is realized within the brain's wiring. We transform sensory inputs from the body and the world, which are perceiver-independent, into an instance of (say) happiness in the context of a concept, “Happiness,” found in many human minds. The concept imposes new functions on these sensations, creating reality where there was none before: an experience or perception of emotion. Instead of asking, “Are emotions real?” the better question is, “How do emotions become real?” Ideally, the answer lies in building a bridge from the perceiver-independent biology of the brain and body, like interoception, to the everyday folk concepts that we live our lives around, like “Fear” and “Happiness.” Emotions become real to us through two human capabilities that are prerequisites for social reality. First, you need a group of people to agree that a concept exists, such as “Flower” or “Cash” or “Happiness.” This shared knowledge is called collective intentionality. Most people barely think about collective intentionality, but it nevertheless is a foundation of every society. Even your own name is made real through collective intentionality. Emotion categories, in my view, are made real through collective intentionality. To communicate to someone else that you feel angry, both of you need a shared understanding of “Anger.” If people agree that a particular constellation of facial actions and cardiovascular changes is anger in a given context, then it is so. You needn't be explicitly aware of this agreement. You don't even have to agree whether a particular instance is anger or not. You just have to agree in principle that anger exists with certain functions. At that point, people can transmit information about that concept among themselves so efficiently that anger seems inborn. If you and I agree that a furrowed brow indicates anger in a given context, and I furrow my brow, I am efficiently sharing information with you. My movement itself does not carry anger to you, any more than vibrations in the air carry sound. By virtue of the fact that we share a concept, my movement initiates a prediction in your brain . . a uniquely human brand of magic. It is categorization as a cooperative act. Collective intentionality is necessary for social reality but not sufficient. Certain non-human animals are capable of a rudimentary form of collective intentionality without social reality. Ants work together toward a common activity, as do bees. Flocks of birds and schools of fish move in synchrony. Certain troupes of chimpanzees use tools, such as sticks for retrieving and eating termites, and rocks for cracking nuts, whose uses are passed down to offspring. Chimps even appear to learn a concept of “Tool” by realizing that different-looking objects can be used for a common purpose-for instance, obtaining food with some sort of object that is held in the hands, like a wooden stick or a screw driver. Humans are unique, however, because our collective intentionality involves mental concepts. We can look at a hammer, a chainsaw, and an ice pick and categorize them all as “Tools,” then change our minds and categorize them all as “Murder Weapons.” We can impose functions that would not otherwise exist, thereby inventing reality. We can work this magic because we have the second prerequisite for social reality: language. No other animals have collective intentionality combined with words. A few other animal species do have symbolic communication of a sort. Elephants appear to communicate through low-frequency vocal rumblings that can travel over a mile. Certain great apes appear to use sign language in a limited way, on the order of a two-year-old human, usually linked in some way to securing a reward. But only human animals have both language and collective intentionality. The two abilities build on one another in complex ways, allowing a human infant to bootstrap a conceptual system into her brain, changing its wiring in the process. The combination also allows people to categorize cooperatively, which is the basis of communication and social influence. Words invite us to form concepts, as we learned in chapter 5, by grouping together physically dissimilar things for some purpose. A trumpet, a timpani, a violin, and a military cannon look nothing alike, but the phrase “musical instrument” allows us to treat them as similar to meet a goal, such as performing Pyotr Tchaikovsky's 1812 Overture. The word “fear” groups together diverse instances that have greatly varied movements, interoceptive sensations, and events in the world. Even prelinguistic infants use words to form concepts about balls and noisemakers, as long as the words are spoken intentionally by live humans. Words are also the most efficient shorthand we know for communicating concepts that are shared by a group. When I order a pizza, I never have a conversation like this one: ME : Hello, I'd like to place an order, please. VOICE ON TELEPHONE. : Sure, what would you like? ME : I'd like a lump of dough that's been rolled flat and shaped into a circle or sometimes a rectangle with tomato sauce and cheese on top of it that's been baked in a very hot oven long enough for the cheese to melt and the crust to brown. For eating. VOICE. : That'll be $9.99. It'll be ready when the big hand is on the twelve and the little hand is on the seven. The word “pizza” would shorten this telephone call considerably because we have shared experience, and therefore shared knowledge, concerning pizza in our culture. I would describe the individual properties of a pizza only to someone who had never encountered pizza before, someone who would likewise labor to understand a pizza, feature by feature. Words also have power. They let us place ideas directly into another person's head. If I seat you in a chair, perfectly motionless, and say the word “pizza” to you, neurons in your brain will change their firing pattern automatically, making predictions. You might even salivate as you simulate the taste of mushrooms and pepperoni. Words give us our own special form of telepathy. Words also encourage mental inference: figuring out the intentions, goals, and beliefs of others. Human infants learn critical information resides in the minds of other people, as we discussed in chapter 5, and words are a vehicle for inferring this information. Words are not the only way to communicate a concept, of course. If I am married and want to indicate this to the world, I don't have to walk around repeating, “I'm married, I'm married, I'm married.” I can just wear a ring, preferably with some very large diamonds in it. Or in northern India, I can wear a bindi (red dot) on my forehead. Likewise, if I'm happy, I don't need words to communicate this. I can simply smile, and others around me understand through collective intentionality, as a torrent of predictions are unleashed in their brains. When my daughter was a preschooler, I only had to widen my eyes to warn her away from mischief. No words were required. Nevertheless, you need a word to teach a concept efficiently. Collective intentionality requires that everyone in a group shares a similar concept, be it “Flower” or “Weed” or “Fear.” The instances of each of these concepts vary widely with few statistical regularities in their physical features, but all group members must learn the concepts somehow. For all practical purposes, this learning requires a word. Which comes first, a concept or a word? This is an ongoing scientific and philosophical debate that we won't solve here; however, it's clear that people form certain concepts before knowing the word. Within a few days after birth, infants rapidly learn the perceptual concept of a face without knowing the word “face,” as we noted in chapter 5, because faces have statistical regularity: two eyes, a nose, and a mouth. Similarly, we distinguish the concepts “Plant” and “Human Being” without requiring words for them: plants photosynthesize and people do not. The difference is perceiver- independent, regardless of how the two concepts are named. On the other hand, certain concepts require words. Consider the category of “Pretend Telephones.” We've all seen children hold an object to their ear and converse into it, emulating their parents' phone behavior. The choice of object varies broadly: it might be a banana, a hand, a cup, even a security blanket. These instances have no significant statistical regularities, and yet a father can hand a banana to his young son and say, “Ring, ring, ring, it's for you,” and this shorthand is sufficient for a shared understanding of what to do next. On the other hand, if you did not know the concept “Pretend Telephone,” and you saw a two-year-old pressing a toy car against her ear and speaking, you would see only a talking child holding a toy to the side of her head. Similarly, emotion concepts are most easily learned with emotion words. You've learned that emotion categories have no consistent fingerprint in the face, body, or brain. That means instances of a single emotion concept, like “Surprise,” need no physical similarity for your brain to group them together. And any two emotion concepts, like “Surprise” and “Fear,” need no consistent fingerprints to reliably distinguish them. So we, as a culture, introduce mental similarity using words. From childhood we hear people say “fear” and “surprise” in particular contexts. The sound of each word (or, later in life, the written form of each word) creates enough statistical regularity within each category, and statistical differences between them, to get us started. The words quickly prompt us to infer the goals to anchor each concept. Without the words “fear” and “surprise,” these two concepts would likely not spread from person to person. Nobody knows whether the concepts form before the words or vice versa, but it's clear that words are vitally linked to the way we develop and transmit purely mental concepts. Classical view theorists debate endlessly about how many emotions there are. Is love an emotion? How about awe? Curiosity? Hunger? Do synonyms like happy, cheerful, and delighted refer to different emotions? What about lust, desire, and passion: are they distinct? Are they emotions at all? From the standpoint of social reality, these debates are nonissues. Love (or curiosity, hunger, etc.) is an emotion as long as people agree that its instances serve the functions of an emotion. We've characterized some of these functions in previous chapters. The first stems from the fact that emotion concepts, like all concepts, make meaning. Suppose you find yourself breathing rapidly and sweating. Are you are excited? Afraid? Physically exhausted? Different categorizations represent different meanings: that is, different likely explanations for your physical state in this situation, based on your past experience. Once you've made an instance of emotion, by categorizing with an emotion concept, your sensations and actions are explained. The second function of emotions stems from the fact that concepts prescribe action: If you're breathing rapidly and sweating, what should you do? Should you grin broadly in excitement, run away in fear, or lie down for a nap? An instance of emotion, constructed from a prediction, tailors your action to meet a particular goal in a particular situation, using past experience as a guide. The third function is related to a concept's ability to regulate your body budget. Depending how you categorize your sweating, panting state, your body budget may be affected differently. A categorization of excitement might lead to a moderate release of cortisol (say, to raise your arms); a categorization of fear might lead to a greater release of cortisol (as you prepare to run away); whereas napping requires no additional cortisol. Categorization literally gets under your skin. Every instance of emotion involves some body budgeting for the immediate future. These three functions have something in common: they're about you alone. You don't need any other people involved in the experience in order to make meaning, to act, or to regulate your body budget. But emotion concepts have two other functions that draw other individuals into your circle of social reality. One function is emotion communication, in which two people categorize with concepts in synchrony. If you see a man taking quick breaths and sweating, it communicates one thing if he's wearing a jogging suit and something else entirely if he's wearing a groom's tuxedo. Categorization here communicates meaning and explains why the man acts as he does. The other function is social influence. Concepts like “Excitement,” “Fear,” and “Exhaustion” are tools for you to regulate other people's body budgets, not just your own. If you can get someone else to perceive your panting, sweaty state as fear, you influence their actions in a way that mere quick breaths and damp brows cannot achieve on their own. You can be an architect of other people's experiences. These latter two functions require that other people-the ones you are communicating with or influencing-agree that certain body states or physical actions serve particular functions in certain contexts. Without this collective intentionality, one person's actions, no matter how meaningful they are to him, will be perceived by others as meaningless noise. Suppose you and a friend are walking together when you see a man stamping his foot forcefully on the pavement. You categorize the man as angry. Your friend categorizes the man as dejected. The man himself believes he is just clomping some caked mud off his shoe. Does that mean you and your friend are wrong? Could the man be unaware of his own emotion in the moment? Who is correct in this case? If this were a question of physical reality, you could settle the matter definitively. If I say that my shirt is made of silk and you say no, it's made of polyester, we can perform a chemical test to discover the answer. With social reality, however, there is no such thing as accuracy. If I say my shirt is a thing of beauty and you say it's hideous, neither of us is objectively correct. The same is true for perceiving emotion in the stamping man. Emotions have no fingerprints, so there can be no accuracy. The best you can do is find consensus. We can ask other people if they agree with you or with me about the shirt or the stamping man, or we can compare our categorizations to the norms of our culture. You, your friend, and the stamping man each construct a perception by prediction. The stamping man himself might be feeling unpleasant arousal, and he may categorize his interoceptive sensations, together with those he predicted from the outside world, as an instance of “Removing Mud from My Shoe.” You may construct a perception of anger and your friend a perception of dejection. Each construction is real, so questions of accuracy are unanswerable in a strictly objective sense. This is not a limitation of science: it is just the wrong question to be asking in the first place. There are no observer-independent measurements that can reliably and specifically adjudicate the matter. When you can't find an objective criterion to compute accuracy and are left with consensus, this is a clue that you are dealing with social, not physical, reality. This point is easily and frequently misunderstood, so let me be clear. I am not saying emotions are illusions. They are real, but socially real in the manner of flowers and weeds. I'm not saying that everything is relative. If that were true, civilization would fall apart. I am also not saying that emotions are “just in your head.” That phrase trivializes the power of social reality. Money, reputation, laws, government, friendship, and all of our most fervent beliefs are also “just” in human minds, but people live and die for them. They are real because people agree that they're real. But they, and emotions, exist only in the presence of human perceivers. Imagine the feeling of reaching into a bag of potato chips and discovering that the previous chip you ate was the last one. You feel disappointed that the bag is empty, relieved that you won't be ingesting any more calories, slightly guilty that you ate the entire bag, and yet hungry for another chip. I have just invented an emotion concept, and there is surely no word for it in the English language. And yet, as you read my prolonged description of this complex feeling, you most likely simulated the whole thing, right down to the crinkle of the bag and the cheerless little crumbs at the bottom. You experienced this emotion without a word for it. Your brain accomplished this feat by combining instances of concepts you already know, such as “Bag,” “Chips,” “Disappointment,” “Relief,” “Guilt,” and “Hunger.” This powerful ability of your brain's conceptual system, which we called conceptual combination in chapter 5, creates your very first instance of this new chip-related category of emotion, ready for simulation. Now if I name my new creation “Chiplessness” and teach it to our fellow citizens, it becomes every bit as real an emotion concept as “Happiness” and “Sadness.” People can predict with it, categorize with it, regulate their body budgets with it, and construct diverse instances of “Chiplessness” in different situations. This brings us to one of the most challenging ideas in this book: you need an emotion concept in order to experience or perceive the associated emotion. It's a requirement. Without a concept for “Fear,” you cannot experience fear. Without a concept for “Sadness,” you cannot perceive sadness in another person. You could learn the necessary concept, or you could construct it in the moment through conceptual combination, but your brain must be able to make that concept and predict with it. Otherwise, you will be experientially blind to that emotion. I realize this idea might sound counterintuitive, so let's start with a few examples. You are probably unfamiliar with an emotion called liget. It's a feeling of exuberant aggression experienced by a headhunting tribe from the Philippines, the Ilongot. Liget involves intense focus, passion, and energy while pursuing a hazardous challenge with a group of people who are competing against another group. The danger and energy instill a sense of togetherness and belonging. Liget is not just a mental state but a complex situation with social rules about which activities bring it on, when it is appropriate to feel, and how other people should treat you during an episode. To a member of the Ilongot tribe, liget is every bit as real an emotion as happiness and sadness are to you. Westerners surely do experience pleasant aggression. Athletes feel it in the heat of competition. Videogame players cultivate it during first-person shooter games. But these people are not experiencing liget with all its meaning, prescribed actions, body-budget changes, communication, and social influence unless they can construct “Liget” using conceptual combination. Liget is the whole conceptual package, and if your brain cannot make this concept, then you cannot experience liget, although you can experience parts of it: the pleasant, high arousal affect; the aggression; the thrill of pursuing a risky challenge; or the feeling of brother- or sisterhood that comes from being part of a group. Next, consider an emotion concept that's more recently adopted by U.S. culture. In a recent meeting with my lab members, I learned that an acquaintance (call him Robert) failed in his bid to win a Nobel prize. Robert had treated me poorly in the past (which is polite scientist-speak for “he acted like an ass”), so when I heard the news, I have to admit that I had a complex emotional experience: I felt some empathy for Robert, plus a small measure of gratification about his misfortune, plus a large wave of guilt at my pettiness, as well as embarrassment that someone might discover my uncharitable feeling. Imagine if I'd described my conceptual combination to my lab members: “Robert probably feels horrible about his failure, and I am pleased about that.” My words would have been highly inappropriate. No one else in my lab knew my history with Robert, nor my simultaneous guilt and embarrassment, so they wouldn't have understood my perspective and might have viewed me as an ass myself. So instead, I said, “I am feeling a bit of schadenfreude,” and everybody in the room smiled and nodded with recognition. One word efficiently communicated my emotional experience and made it socially acceptable, because everyone else in the lab had the concept and could construct a perception of schadenfreude. We couldn't have done that with mere pleasantly valenced affect at someone else's misfortune. The situation is exactly the same for a more familiar Western emotion like sadness. Any healthy human can experience low-arousal, unpleasant affect. But you cannot experience sadness with all of its cultural meaning, appropriate actions, and other functions of emotion unless you have the concept “Sadness.” Some scientists argue that without an emotion concept, the emotion still exists but the affected person doesn't realize it, implying a state of emotion outside of consciousness. I suppose this is a possibility, but I doubt it. If you had no concept of “Flower” and someone showed you a rose, you'd experience only a plant, not a flower. No scientist would claim that you're seeing a flower but just “don't realize it.” Similarly, the blobby image in chapter 2 does not have a hidden bee in it. You perceived the bee only because of conceptual knowledge. The same reasoning applies to emotions; without the concept “Liget” or “Sadness” or “Chiplessness” to categorize with, there is no emotion, only a pattern of sensory signals. Think of how useful the concept of “Liget” could be in Western culture. When military cadets train in the art of war, a small percentage of them reportedly develop a feeling of pleasure in killing. They do not seek to kill to feel pleasure; they are not psychopaths. But when they do kill, they experience pleasure. Their stories of combat often depict intense feelings of pleasure from the thrill of the hunt, or from a job well-done with comrades-in- arms. In Western culture, however, killing with pleasure is considered terrible and shameful; it is difficult to empathize with or muster compassion for those who have experienced this feeling. So consider this: what if we taught the concept and the word liget to cadets, including a set of social rules for when liget is appropriate to feel? We could embed this emotion concept in our broader cultural context of values and norms, just like we did with schadenfreude. The concept might even allow servicepeople to flexibly cultivate the experience of liget when needed for their military duties. New emotion concepts like liget could broaden their emotional granularity, improving their unit's cohesion and their job performance, all the while protecting mental health for these members of our armed forces, both in battle and when they come home from deployment. I realize I'm saying something provocative: that each of us needs an emotion concept before we can experience or perceive that emotion. This definitely doesn't match common sense or everyday experience; emotions feel so built-in. But if emotions are constructed by prediction, and you can predict only with the concepts you possess, well . . there you have it. The emotions that you experience so effortlessly, and which feel built-in, most likely were also known in your parents' generation, and their parents' as well. The classical view explains this progression by proposing that emotions -separate from emotion concepts-are built into the nervous system through evolution. I have an evolutionary story to tell as well, but it's about social reality, and it doesn't require emotion fingerprints in the nervous system. Emotion concepts like “Fear,” “Anger,” and “Happiness” are passed down from one generation to the next. This occurs not merely because we propagate our genes but because those genes allow each generation to wire the brains of the next one. Infants grow minds full of concepts as they learn the mores and values of their culture. This process goes by many names: Brain development. Language development. Socialization. One of humanity's major adaptive advantages-why we've flourished as a species-is that we live in social groups. This arrangement has allowed us to expand across the globe, creating livable habitats by feeding, clothing, and learning from each other in otherwise inhospitable physical conditions. We can therefore amass information across generations-stories, recipes, traditions, anything that we can describe-that helps each generation to shape the brain wiring of the next. This trove of intergenerational knowledge lets us actively shape the physical environment, rather than just adapt to it, and to create civilizations. Living in groups has some drawbacks, of course, particularly a major dilemma that every human must face: getting along versus getting ahead. Everyday concepts like “Anger” and “Gratitude” are critical tools for dealing with these two competing concerns. They are instruments of culture. They prescribe situation-specific actions, allow you to communicate, and influence the behaviors of others, all in the service of managing your body budget. Just because fear appears generation after generation in your culture does not prove that fear is coded into the human genome, nor that it was sculpted by natural selection in our hominin ancestors millions of years ago on the African savanna. These single-cause explanations discount the enormous power of collective intentionality (not to mention copious evidence from modern neuroscience). Evolution surely allowed humans to create culture, and part of that culture is a system of goal-based concepts to manage ourselves and each other. Our biology allows us to create goal-based concepts, but exactly which concepts may be a matter of cultural evolution. The human brain is a cultural artifact. We don't load culture into a virgin brain like software loading into a computer; rather, culture helps to wire the brain. Brains then become carriers of culture, helping to create and perpetuate it. All humans who live in groups must solve common problems, so it's not surprising to find some concepts that are similar across cultures. Most human societies, for example, have myths about supernatural beings: nymphs from ancient Greece, fairies from Celtic legends, leprechauns from Ireland, little people from Native American tales, Menehune from Native Hawaiian folklore, trolls from Scandinavia, the Aziza from Africa, the Agloolik from Inuit culture, the Mimis from Aboriginal Australia, the Shin from China, the Kami from Japan, and countless others. Tales of these magical creatures are an important part of human history and literature. They do not, however, mean that magical creatures actually exist or have ever existed in nature (no matter how much we wish we could attend Hogwarts). The category “Magical Creature” is constructed by human minds, and since it exists in so many different cultures, it probably serves some important function. In the same manner, “Fear” exists in many cultures (but not all, such as the !Kung people of the Kalahari Desert) by virtue of having important functions. As far as I know, no emotion concept is universal, but even if one were, universality itself does not automatically imply a perceiver-independent reality. Social reality is a driving force behind human culture. It's perfectly plausible for emotion concepts, as elements of social reality, to be learned from others during infancy, or even much later when someone moves from one culture to another (more on this shortly). Social reality is therefore one conduit for transmitting behaviors, preferences, and meanings from ancestors to descendants via natural selection. Concepts are not merely a social veneer on top of biology. They are a biological reality that is wired into your brain by culture. People who live in cultures with certain concepts, or more diverse concepts, may be more fit to reproduce. In chapter 5, we looked at the illusory stripes that we carve into a rainbow, as we categorize the wavelengths of light with our concepts for colors. If you visit the Russian Google (images.google.ru) and search for the Russian word for rainbow, радуга, you'll see that Russian drawings contain seven colors, not six: the Western blue stripe has been subdivided into light blue and dark blue, as in figure 7-2:23 Figure 7-2: Rainbow drawings are culture-specific These pictures demonstrate that concepts of color are influenced by culture. In Russian culture, the colors синий (blue) and Голубой (sky blue to a Westerner) are different categories, as distinct as blue and green are to an American. This distinction is not due to inborn, structural differences in the visual system of Russians versus Americans, but to culture-specific, learned concepts of color. People raised in Russia are simply taught that light and dark blue are distinct colors with different names. These color concepts become wired into their brains, and so they perceive seven stripes. Words represent concepts, and concepts are tools of culture. We pass them down from parent to child, from one generation to the next, just like your great-great-grandmother's candlesticks from the Old Country. “Rainbows have six stripes.” “Money is traded for goods.” “Cupcakes are a dessert and muffins are a breakfast food.” Emotion concepts are also cultural tools. They come with a rich set of rules, all in the service of regulating your body budget or influencing someone else's. These rules can be specific to a culture, stipulating when it's acceptable to construct a given emotion in a given situation. In the United States, it's appropriate to feel fear when you're on a rollercoaster, or about to hear the results of a cancer screening, or if someone points a gun at you. In the United States, it's not appropriate to feel fear each time you walk out of your house in a safe neighborhood: that feeling would be considered pathological, an anxiety disorder called agoraphobia. My friend Carmen, who was born in Bolivia, was surprised when I told her that emotion concepts vary widely from culture to culture. “I thought everybody in the world has the same emotions,” she explained to me in Spanish. “Well, Bolivians do have stronger emotions than Americans. Más fuerte.” Most people have lived with one set of emotion concepts their whole lives, so like Carmen, they find this cultural relativity surprising. Yet, scientists have documented numerous emotion concepts around the world that don't exist in English. Norwegians have a concept for an intense joy of falling in love, calling it “Forelsket.” The Danes have the concept “Hygge” for a certain feeling of close friendship. The Russian “Tocka” is a spiritual anguish, and the Portuguese “Saudade” is a strong, spiritual longing. After a little research, I located a Spanish emotion concept that has no direct equivalent in English, called “Pena Ajena.” Carmen described it to me as “sadness over another person's loss,” but I've also seen it characterized as discomfort or embarrassment on someone else's behalf. Here are a few more I find compelling:25 Gigil (Filipino): The urge to hug or squeeze something that is unbearably adorable. Voorpret (Dutch): Pleasure felt about an event before the event takes place. Age-otori (Japanese): The feeling of looking worse after a haircut. Some emotion concepts from other cultures are incredibly complicated, perhaps impossible to translate into English, yet natives experience them as a matter of course. The concept of “Fago” in Ifaluk (Micronesian) culture can mean love, empathy, pity, sadness, or compassion, depending on context. In Czech culture, the concept of “Litost” is said to be untranslatable but roughly “torment over one's own misery combined with the desire for revenge.” The Japanese emotion concept “Arigata-meiwaku” is felt when someone has done you a favor that you didn't want from them, and which may have caused difficulty for you, but you're required to be grateful anyway. When I speak to audiences in the United States about emotion concepts as variable and culture-specific, and then suggest that our own English-language concepts are similarly local to our culture, some people are very surprised, as my friend Carmen was. “But happiness and sadness are real emotions,” they insist, as if the emotions of other cultures are not as real as our own. To this I usually say: you are exactly right. Fago, litost, and the rest are not emotions . . to you. That's because you don't know these emotion concepts; the associated situations and goals are not important in middle-class American culture. Your brain cannot issue predictions based on “Fago,” so the concept doesn't feel automatic the way that happiness and sadness do to you. To understand fago, you have to combine other concepts that you do know, performing conceptual combination and expending mental effort. But the Ifaluk do have this emotion concept. Their brains automatically predict with it. When they experience fago, it feels just as automatic and real as happiness or sadness does to you, as if fago just happens to them. Yes, fago, litost, and the rest are just words made up by people, but so are “happy,” “sad,” “fearful,” “angry,” “disgusted,” and “surprised.” Invented words are the very definition of social reality. Would you say that your local currency is real money and the currencies of other cultures are just made up? To someone who has never traveled, it might seem that way, lacking the concept for another currency. But experienced travelers have the concept “Currency from Another Culture.” I'm asking you to learn the concept of “Emotion from Another Culture,” so you understand that its instances are just as real to others as your own emotions are to you. If you've found these ideas challenging, try this one: some cherished Western emotion concepts are completely absent in other cultures. Utka Eskimos have no concept of “Anger.” The Tahitians have no concept of “Sadness.” This last item is very difficult for Westerners to accept . . life without sadness? Really? When Tahitians are in a situation that a Westerner would describe as sad, they feel ill, troubled, fatigued, or unenthusiastic, all of which are covered by their broader term pe'ape'a. Someone who believes in the classical view of emotion would explain away this variability, saying that a frowning Tahitian really is in a biological state of sadness, whether he knows it or not. A constructionist does not have the luxury of such certainty, because people frown for many reasons such as while thinking, exerting effort, in humor, when censoring a thought, or when feeling pe'ape'a. Beyond individual emotion concepts, different cultures don't even agree on what “emotion” is. Westerners think of emotion as an experience inside an individual, in the body. Many other cultures, however, characterize emotions as interpersonal events that require two or more people. This includes the Ifaluk of Micronesia, the Balinese, the Fula, the Ilongot of the Philippines, the Kaluli of Papua New Guinea, the Minangkabau of Indonesia, the Pintupi Aborigines of Australia, and the Samoans. More intriguingly, some cultures don't even have a unified concept of “Emotion” for the experiences that Westerners lump together as emotional. The Tahitians, the Gidjingali Aborigines of Australia, the Fante and Dagbani of Ghana, the Chewong of Malaysia, and our friends the Himba from chapter 3 are a few well-studied examples. Most scientific research on emotion is conducted in English, using American concepts and American emotion words (and their translations). According to noted linguist Anna Wierzbicka, English has been a conceptual prison for the science of emotion. “English terms of emotion constitute a folk taxonomy, not an objective, culture-free analytic framework, so obviously we cannot assume that English words such as disgust, fear, or shame are clues to universal human concepts, or to basic psychological realities.” To make matters even more imperialistic, these emotion words are from twentieth- century English, and there's evidence that some are fairly modern. The concept of “Emotion” itself is an invention of the seventeenth century. Before that, scholars wrote about passions, sentiments, and other concepts that had somewhat different meanings. Different languages describe diverse human experience in different ways- emotions and other mental events, colors, body parts, direction, time, spatial relations, and causality. The diversity from language to language is astonishing. The experiences of my friend Batja Mesquita, the cultural psychologist whom you met in chapter 5, provide an example. She was born and raised in the Netherlands and immigrated to America for her postdoctoral training. Over the next fifteen years, she married, raised a family, and was a professor at Wake Forest University in North Carolina. When living in the Netherlands, Batja felt that her emotions were, for lack of a better word, natural. After moving to the United States, however, she soon noticed her emotions were not a good fit for American culture. Americans struck her as unnaturally happy. We constantly spoke in an upbeat tone of voice. We smiled a tremendous amount. When Batja asked how people were doing, we would always answer positively (“I'm doing great!”). Batja's own emotional responses seemed inadequate in the U.S. cultural context. When asked how she was feeling, she did not respond with sufficient enthusiasm or say she was “fabulous” or “wonderful.” I once heard her give a talk on her experiences, and I nodded through the entire thing, clapped vigorously at the end, and then walked up to her, gave her a hug, and said “excellent job!” It took me a moment to realize I had just confirmed every one of her observations. Batja's experience is not unique. Our colleague Yulia Chentsova Dutton from Russia says that her cheeks ached for an entire year after moving to the United States because she had never smiled so much. My neighbor Paul Harris, a transplanted emotion researcher from England, has observed how American academics are always excited by scientific puzzles-a high arousal, pleasant feeling-but never merely curious, perplexed, or confused, which are low arousal and fairly neutral experiences that are more familiar to him. In general, Americans prefer high arousal, pleasant states. We smile a lot. We praise, compliment, and encourage each other. We give each other awards for all levels of accomplishment, even “Certificates of Participation.” It seems like every other week there is an awards show on television. I have lost count of how many books on happiness have been published in the United States in the last ten years. We are a culture of positivity. We like to be happy and to celebrate how great we are. The more time that Batja spent in America, the more her emotions became attuned to the American context. Her pleasant emotion concepts expanded and became more variable. She became more granular, experiencing the American style of happiness as distinct from satisfaction and contentment. Her brain bootstrapped new concepts for American norms and customs. This process is called emotion acculturation. From a new culture, you acquire new concepts, which translate into new predictions. Using those predictions, you become able to experience and perceive the emotions of your newly adopted home. The scientist who discovered emotion acculturation is, in fact, Batja herself. She found that people's emotion concepts not only vary from culture to culture but also transform. For example, situations that bring about anger in Belgium, like having your goals blocked by a coworker, in Turkey will also include feelings of (what Americans experience as) guilt, shame, and respect. But for Turkish immigrants in Belgium, their emotional experiences come to look more “Belgian” the longer they live there. A brain that is bathed in the situations of a new culture is probably somewhat like an infant's brain: driven more by prediction error than prediction. Lacking the emotion concepts of the new culture, the immigrant brain soaks up sensory input and builds new concepts. The new emotional patterns don't replace the old ones, though they may cause interference, as was the case for my research associate Alexandra from Greece whom you met in chapter 5. You can't predict efficiently when you don't know the local concepts. You must get by with conceptual combination, which can be effortful and yields only an approximate meaning. Or you will be awash in prediction error much of the time. The process of acculturation therefore taxes your body budget. In fact, people who are less emotionally acculturated report more physical illness. Once again, categorization gets under your skin. In this book, I am trying to acculturate you into a new way of thinking about emotion. Whether you realize it or not, you have a set of concepts about emotions: what they are, where they come from, and what they mean. Perhaps you began this book with classical view concepts such as “Emotional Reaction” and “Facial Expression” and “Emotion Circuit in the Brain.” If so, I've been slowly replacing them with a new set, including “Interoception,” “Prediction,” “Body Budget,” and “Social Reality.” In a sense, I am attempting to draw you into a new culture called the theory of constructed emotion. A new culture's norms may seem odd, or even wrong, until you've lived there for a while and come to understand them . . and I hope you already do, or you will. Ultimately, if I and other like-minded scientists are successful in substituting the new concepts for the old, well, that's a scientific revolution. The theory of constructed emotion explains how you experience and perceive emotion in the absence of any consistent, biological fingerprints in the face, body, or brain. Your brain continually predicts and simulates all the sensory inputs from inside and outside your body, so it understands what they mean and what to do about them. These predictions travel through your cortex, cascading from the body-budgeting circuitry in your interoceptive network to your primary sensory cortices, to create distributed, brain-wide simulations, each of which is an instance of a concept. The simulation that's closest to your actual situation is the winner that becomes your experience, and if it's an instance of an emotion concept, then you experience emotion. This whole process occurs, with the help of your control network, in the service of regulating your body budget to keep you alive and healthy. In the process, you impact the body budgets of those around you, to help you survive to propagate your genes into the next generation. This is how brains and bodies create social reality. This is also how emotions become real. Yes, that's a mouthful. And some details are still reasoned speculation, like the exact mechanisms of the concept cascade. But we can say confidently that the theory of constructed emotion is a viable way to think about how emotions are made. The theory accounts for all of the phenomena of the classical view, plus its anomalies such as the huge variability in emotional experiences, in emotion concepts, and in physical changes during emotion. It dissolves useless nature/nurture debates (e.g., what is hardwired versus what is learned) by using a single framework to understand both physical reality and social reality, moving us one step closer to a scientific bridge between the social and natural worlds. And this bridge, like all bridges, will lead us to a new place, as you'll see in the next chapter: a modern origin story of what it means to be human."
  },
  {
    "index": 13,
    "level": 1,
    "start_page": 153,
    "end_page": 172,
    "title": "A New View of Human Nature",
    "content": "A New View of Human Nature. The theory of constructed emotion is not just a modern explanation of how emotions are made. It's also an ambassador for a radically different view of what it means to be a human being. This view is consistent with the latest research in neuroscience. It also gives you more control over your feelings and behavior than the classical view does, and it has deep implications for how to live your life. You are not a reactive animal, wired to respond to events in the world. When it comes to your experiences and perceptions, you are much more in the driver's seat than you might think. You predict, construct, and act. You are an architect of your experience. Another compelling view of human nature comes from the classical view of emotion. It's been around for thousands of years and is still embedded in law, medicine, and other critical elements of society. The two views have in fact been at war with each other throughout recorded history. In previous battles, the classical view of human nature has consistently come out on top for reasons we'll see. But now, as we're in the midst of a revolution of mind and brain, modern neuroscience has given us the tools to settle the conflict, and based on overwhelming evidence, the classical view has lost. In this chapter, I lay out the distinctive new view of human nature represented by the theory of constructed emotion and compare it to the traditional ideas espoused by the classical view. I also introduce you to a shadowy culprit that has kept the classical view so prominent for so long, entrenched in science and culture, despite a steady stream of contrary evidence. Most of us think of the outside world as physically separate from ourselves. Events happen “out there” in the world, and you react to them “in here” in your brain. In the theory of constructed emotion, however, the dividing line between brain and world is permeable, perhaps nonexistent. Your brain's core systems combine in various ways to construct your perceptions, memories, thoughts, feelings, and other mental states. You experienced this with the blobby bee picture, when you saw shapes that didn't physically exist, demonstrating that your brain models your world through simulation. Your brain issues a storm of predictions, simulates their consequences as if they were present, and checks and corrects those predictions against actual sensory input. Along the way, your interoceptive predictions produce your feelings of affect, influence every action that you perform, and determine which parts of the world you care about in the moment (your affective niche). Without interoception, you wouldn't notice or care about your physical surroundings or anything else, and you'd be unlikely to survive for long. Interoception enables your brain to construct the environment in which you live. At the same time that your brain is modeling your world, the outside world helps to wire your brain. When you're an infant, awash in sensory input, the outside world seeds your earliest concepts, as your brain hardwires itself to the realities of the physical world around you. That's how babies' brains become wired to recognize human faces. As your brain develops and you begin learning words, your brain hardwires itself to the social world, and you begin creating purely mental concepts like “Things That Can Protect You from Stinging Insects” and “Sadness.” These concepts from your culture appear to be in the outside world, but they are constructions of your conceptual system. In this view, culture is not some gauzy, amorphous vapor that surrounds you. It helped to wire your brain, and you behave in certain ways that wire the brains of the next generation. For example, if a culture dictates that people with certain skin colors are less worthwhile, this social reality has a physical effect on the group: they have lower salaries and their children have poorer nutrition and living conditions. These factors change the structure of their children's brains for the worse, making school harder and increasing the odds that the children will earn lower salaries in the future. Your constructions aren't arbitrary-your brain (and the mind it creates) must keep in touch with the bits of reality that count in order to keep your body alive and healthy. Construction cannot make a solid wall unsolid (unless you have mutant superpowers), but you can redraw countries, redefine marriage, and decide who's worthwhile and who isn't. Your genes gave you a brain that can wire itself to its physical and social environment, and other members of your culture construct that environment with you. It takes more than one brain to create a mind. The theory of constructed emotion also leads to a whole new way of thinking about personal responsibility. Suppose you're angry with your boss and lash out impulsively, slamming your fist on his desk and calling him an idiot. Where the classical view might attribute some blame to a hypothetical anger circuit, partially absolving you of responsibility, construction extends the notion of responsibility beyond the moment of harm. Your brain is predictive, not reactive. Its core systems are constantly trying to guess what's coming next so you can survive. Therefore your actions, and the predictions that launched those actions, are shaped by all your past experiences (as concepts) that led up to that moment. You slam that desk because your brain predicted an instance of anger, using your concept of “Anger,” and your past experience (whether direct, or from movies or books, etc.) includes an action of slamming the desk in a similar situation. Your control network, you may recall, constantly shapes the course of your predictions and prediction error to help select among multiple actions, whether you experience yourself as in control or not. This network can only work with the concepts that you've got. So the question of responsibility becomes, Are you responsible for your concepts? Not all of them, certainly. When you're a baby, you can't choose the concepts that other people put into your head. But as an adult, you absolutely do have choices about what you expose yourself to and therefore what you learn, which creates the concepts that ultimately drive your actions, whether they feel willful or not. So “responsibility” means making deliberate choices to change your concepts. As a real-world example, pick any extended conflict in the world: Israelis versus Palestinians, Hutus versus Tutsis, Bosnians versus Serbs, Sunni versus Shia. Climbing out on a limb here, I'd like to suggest that no living member of these groups is at fault for the anger that they feel toward each other, since the conflicts in question began many generations ago. But each individual today does bear some responsibility for continuing the conflict, because it's possible for each person to change their concepts and therefore their behavior. No particular conflict is predetermined by evolution. Conflicts persist due to social circumstances that wire the brains of the individuals who participate. Someone must take responsibility to change these circumstances and concepts. Who's going to do it, if not the people themselves? To make this point, a scientific study provides some preliminary hope. Researchers trained a group of Israelis to think about various negative events, such as Palestinians' launching rockets and the kidnapping of an Israeli soldier, and recategorize them as less negative. The trainees were not only less angry afterward but they showed greater support for policies leading to more peaceful and conciliatory resolutions, such as providing aid to Palestinians, as well as less support for aggressive tactics toward Palestinians living in the Gaza Strip. Surrounding the recent Palestinian bid for membership in the United Nations, this training in recategorization led people to support giving up security control over neighborhoods in East Jerusalem in exchange for full peace, and to show less support for restrictive policies like prohibiting Palestinians from using the Israeli medical system. These latter changes persisted for five months after training. If you grow up in a society full of anger or hate, you can't be blamed for having the associated concepts, but as an adult, you can choose to educate yourself and learn additional concepts. It's certainly not an easy task, but it is doable. This is another basis for my frequent claim, “You are an architect of your experience.” You are indeed partly responsible for your actions, even so- called emotional reactions that you experience as out of your control. It is your responsibility to learn concepts that, through prediction, steer you away from harmful actions. You also bear some responsibility for others, because your actions shape other people's concepts and behaviors, creating the environment that turns genes on and off to wire their brains, including the brains of the next generation. Social reality implies that we are all partly responsible for one another's behavior, not in a fluffy, let's-all-blame-society sort of way, but a very real brain-wiring way. When I was a therapist, I worked with college-aged women who, as little girls, had suffered abuse at the hands of parents. I used to help my clients understand that they've been victimized twice: once in the moment and again because they've been left with emotional suffering that only they can resolve. Due to their trauma, their brains continue to model a hostile world, even after they've escaped to a better one. It was not their fault that their brains are wired for a specific, toxic environment. But each woman is the only one who can transform her conceptual system to make things better. That's the form of responsibility that I mean. Sometimes, responsibility means that you're the only one who can change things. And now, we come to the question of human origin. We are accustomed to thinking about ourselves as the final destination of a long evolutionary journey. The theory of constructed emotion takes a more balanced perspective. Natural selection did not aim itself toward us. We are just another species with particular adaptations that help pass our genes to the next generation. Other animals have evolved plenty of powers that we don't have, like leaping great distances and scaling walls, which is why we're so fascinated by superheroes like Spider-Man. Humans are clearly the most talented at building rockets that reach other planets, and inventing and enforcing laws that exist in our minds and dictate how we treat each other. Something in the human brain gives us our unique abilities, but that “something” needn't be separate, dedicated brain circuitry for rocketry and law enforcement-or, for that matter, emotions-passed down from our non- human ancestors. One of your most notable adaptations is that you needn't carry all the genetic material to create all the wiring in your brain. That would be tremendously expensive, biologically speaking. Instead, you have genes that let your brain develop in the context of the other brains around you, through culture. Just as an individual brain takes advantage of redundancy, compressing information into similarities and differences, multiple brains take advantage of one another's redundancies (that we're in the same culture and learned the same concepts) and wire each other. In effect, evolution improves its efficiency via human culture, and we pass culture to our offspring by wiring their brains. The human brain, from the macro level to the micro level, is organized for variation and degeneracy. In its interacting networks, clusters of neurons are partly independent and share a lot of information efficiently. This arrangement allows ever-changing populations of neurons to form and dissolve in milliseconds, so that single neurons participate in different constructions in different situations, modeling a variable and only partly predictable world. Neural fingerprints have no place in such a dynamic environment. It would be highly inefficient for all of humanity to have one inherited set of mental modules, given that we live in such diverse geographic and social environments around the world. The human brain evolved to create different kinds of human minds, adapted to different environments. We don't need one universal brain creating one universal mind to claim that we are all one species. On the whole, the theory of constructed emotion is a biologically informed, psychological explanation of who you are as a human being. It takes into account both evolution and culture. You are born with some brain wiring as determined by your genes, but the environment can turn some genes on and off, allowing your brain to wire itself to your experiences. Your brain is shaped by the realities of the world that you find yourself in, including the social world made by agreement among people. Your mind is a grand collaboration that you have no awareness of. Through construction, you perceive the world not in any objectively accurate sense but through the lens of your own needs, goals, and prior experience (as you did with the blobby bee). And you are not the pinnacle of evolution, just a very interesting sort of animal with some unique abilities. The theory of constructed emotion provides a very different outlook on human nature than the classical view does. Classical ideas about our evolutionary origins, our personal responsibility, and our relationship with the outside world have been dominant in Western culture for thousands of years. To understand this older view of human nature and why it's been so entrenched for so long, it's convenient to begin-as so many scientific stories do-with Charles Darwin. In 1872, Darwin published The Expression of the Emotions in Man and Animals, where he wrote that emotions were passed down to us, unchanging through the ages, from an early animal ancestor. Emotions in modern humans are therefore caused by ancient parts of our nervous system, according to Darwin, and each emotion has a specific, consistent fingerprint. To borrow a term from philosophy, Darwin was saying that each emotion has an essence. If instances of sadness occur with a pout and a slowed heart rate, then a fingerprint of “pout and slowed heart rate” may be the essence of sadness. Alternatively, the essence might be an underlying cause that makes all the instances of sadness the emotion they are, such as a set of neurons. (I'll use the word “essence” to refer to both possibilities.)6 The belief in essences is called essentialism. It presupposes that certain categories-sadness and fear, dogs and cats, African and European Americans, men and women, good and evil-each have a true reality or nature. Within each category, the members are thought to share a deep, underlying property (an essence) that causes them to be similar, even if they have some superficial differences. There are many varieties of dog with differences in size, shape, color, gait, temperament, and so on, but these differences are considered superficial with regard to some essence that all dogs share. A dog is never a cat. Likewise, all varieties of the classical view consider emotions like sadness and fear to have distinct essences. The neuroscientist Jaak Panksepp, for example, writes that an emotion's essence is a circuit in the subcortical regions of your brain. The evolutionary psychologist Steven Pinker writes that emotions are like mental organs, analogous to body organs for specialized functions, and that an emotion's essence is a set of genes. The evolutionary psychologist Leda Cosmides and the psychologist Paul Ekman assume that each emotion has an innate, unobservable essence, which they refer to as a metaphorical “program.” Ekman's version of the classical view, called basic emotion theory, assumes that essences for happiness, sadness, fear, surprise, anger, and disgust are triggered automatically by objects and events in the world. Another version, called classical appraisal theory, inserts an additional step in between you and the world, saying that your brain first judges (“appraises”) the situation and decides whether to trigger an emotion. All versions of the classical view agree that each emotion category has a distinct fingerprint; they just disagree on the nature of the essences. Essentialism is the culprit that has made the classical view supremely difficult to set aside. It encourages people to believe that their senses reveal objective boundaries in nature. Happiness and sadness look and feel different, the argument goes, so they must have different essences in the brain. People are almost always unaware that they essentialize; they fail to see their own hands in motion as they carve dividing lines in the natural world. Darwin's belief in emotion essences, as revealed in Expression, helped to launch the modern classical view of emotion to prominence. That same belief also made Darwin unwittingly look like a hypocrite. It is no small task to criticize-let alone contradict-the ideas of one of the greatest scientists in history. But let's have a go, shall we? Darwin's most famous book, On the Origin of Species, triggered a paradigm shift that transformed biology into a modern science. His greatest scientific achievement, so nicely summed up by the evolutionary biologist Ernst Mayr, was freeing biology from “the paralyzing grip of essentialism.” Regarding emotion, however, Darwin made an inexplicable about-face thirteen years later by writing Expression, a book riddled with essentialism. In doing so, he abandoned his remarkable innovations and returned to essentialism's paralyzing grip, at least where emotions are concerned. You see, before Darwin's theory from Origin became popular in the nineteenth century, essentialism ruled the animal kingdom. Each species was assumed to have an ideal form, created by God, with defining properties (essences) that distinguished it from all other species (each with their own essences). Deviations from the ideal were said to be due to error or accident. Think of this as the “dog show” version of biology. A dog show, in case you've never seen one, is a contest to identify the “best” dog in a field of competitors. The dogs do not directly compete with one another but are compared by judges to a hypothetical ideal dog to see who's the closest. When rating Golden Retrievers, for example, the judges compare each competitor to the ideal image of a Golden Retriever. Is the dog the right height? Are its limbs symmetrical? Is the muzzle straight, blending smoothly with the skull? Is the coat a rich, dense, lustrous gold? Any differences from the ideal dog are regarded as error, and the dog with the smallest amount of error wins. In the same manner, influential thinkers of the early nineteenth century saw the world of living creatures as one big dog show. If you looked at a Golden Retriever and observed that its stride was longer than average, then its stride was too long compared to the ideal, or even wrong. Then along came Darwin, who argued that variations within a species, such as length of stride, are not errors. Instead, variations are expected and are meaningfully related to the species' environment. Any population of Golden Retrievers has a variety of stride lengths, some of which provide a functional advantage for running, climbing, or hunting. The individuals with strides that best fit their environment will live longer and produce more offspring. This is Darwin's theory of evolution from Origin in action, known as natural selection and sometimes called “survival of the fittest.” To Darwin, each species was a conceptual category-a population of unique individuals who vary from one another, with no essence at their core. The ideal dog doesn't exist: it's a statistical summary of many diverse dogs. No features are necessary, sufficient, or even typical of every individual in the population. This observation, known as population thinking, is central to Darwin's theory of evolution. Population thinking is based on variation, whereas essentialism is based on sameness. The two ideas are fundamentally incompatible. Origin is therefore a profoundly anti-essentialist book. So it is baffling that where emotion is concerned, Darwin reversed his greatest achievement by writing Expression. It is equally baffling, not to mention ironic, that the classical view of emotion is based on the very essentialism that Darwin is famous for vanquishing in biology. The classical view explicitly labels itself as “evolutionary” and assumes that emotions and their expressions are products of natural selection, yet natural selection is completely absent from Darwin's thinking on emotion. Any essentialist view that wraps itself in the cloak of Darwin is demonstrating a profound misunderstanding of Darwin's central ideas about evolution. The compelling power of essentialism led Darwin to some beautifully ridiculous ideas about emotion. “Even insects,” he wrote in Expression, “express anger, terror, jealousy, and love” when they rub their body parts together to make sounds. Think about that the next time you're chasing a fly in your kitchen. Darwin also wrote that emotional imbalance could cause frizzy hair. Essentialism is not only powerful but also infectious. Darwin's perplexing belief in unvarying emotion essences lived on after his death and distorted the legacy of other famous scientists. In the process, the classical view of emotion gained momentum. The most important example is that of William James, considered by many to be the father of American psychology. James might not be the household name that Darwin is, but he was, quite simply, an intellectual giant. His 1,200-page tome Principles of Psychology contains most of Western psychology's most important ideas and remains, after more than a century, the foundation of the field. His name graces the highest honor that can be bestowed on a scientist from the Association of Psychological Science, the William James Prize, and Harvard's psychology building is named William James Hall. James is widely cited for saying that each type of emotion-happiness, fear, and so on-has a distinct fingerprint in the body. This essentialist idea is a key fact of the classical view, and generations of James-influenced researchers have searched for those fingerprints in heartbeats, respiration, blood pressure, and other bodily markers (and have written some bestselling books on emotion). James's statement has a catch, however: he never said it. The widely believed claim that he did comes from a hundred-year-old misinterpretation of his words through the lens of essentialism. James actually wrote that each instance of emotion, not each category of emotion, comes from a unique bodily state. This is a wildly different statement. It means you can tremble in fear, jump in fear, freeze in fear, scream in fear, gasp in fear, hide in fear, attack in fear, and even laugh in the face of fear. Each occurrence of fear is associated with a different set of internal changes and sensations. The classical misinterpretation of James represents a 180-degree inversion of his meaning, as if he were claiming the existence of emotion essences, when ironically he was arguing against them. In James's words, “ 'Fear' of getting wet is not the same fear as fear of a bear.”13 How did this widespread misunderstanding of James arise? I discovered that one of James's contemporaries sowed the confusion, a philosopher named John Dewey. He came up with his own theory of emotion by grafting Darwin's essentialist views from Expression onto James's anti-essentialist ideas, even though they are fundamentally incompatible. The result was a Frankenstein's monster of a theory that inverted James's meaning by assigning an essence to each emotion category. For the finishing touch, Dewey named his concoction after James, calling it “the James-Lange theory of emotion.”* Today, Dewey's role in this jumble is forgotten, and countless publications attribute his theory to James. A prominent example is the writings of neurologist Antonio Damasio, author of Descartes' Error and other popular books on emotion. To Damasio, an emotion's unique physical fingerprint, which he calls a somatic marker, is a source of information used by the brain to make good decisions. These markers are like little bits of wisdom. Emotional experience, according to Damasio, occurs when somatic markers are transformed into conscious feelings. Damasio's hypothesis is actually a child of the James-Lange merger, not of James's actual views on emotion. Dewey's misinterpretation of James is one of the great mistakes in modern psychology, forged by essentialism in the name of Darwin. It is ironic, not to mention absurdly tragic, when Darwin's name is invoked to lend authority to essentialist scientific views, when his greatest scientific achievement was to vanquish essentialism in biology. So why is essentialism so powerful that it can twist the words of great scientists and misdirect the path of scientific discovery? The simplest reason is that essentialism is intuitive. We experience our own emotions as automatic reactions, so it's easy to believe that they spring forth from ancient, dedicated parts of the brain. We also see emotions in blinks, furrowed brows, and other muscle twitches, and we hear emotions in the pitch and lilt of voices, without any sense of effort or agency. Therefore, it's also easy to believe that we've been engineered by nature to recognize emotional displays and programmed to act on them. That's a dubious conclusion, however. Millions of people around the world can instantly, effortlessly recognize Kermit the Frog, but that doesn't mean the human brain is wired for Muppet recognition. Essentialism promises simple, single-cause explanations that reflect common sense, when in fact we live in a complex world. Essentialism is also remarkably difficult to disprove. Since an essence can be an unobservable property, people are free to believe in essences even when they cannot be found. It's easy to come up with reasons why an experiment did not detect an essence: “we haven't looked everywhere yet,” or “it's inside this complicated biological structure we can't see into yet,” or “our tools today aren't sufficiently powerful to find the essence, but one day they will be.” These hopeful thoughts are heartfelt but logically impossible to prove false. Essentialism inoculates itself against counterevidence. It also changes the way science is practiced. If scientists believe in a world of essences that are waiting to be discovered, then they devote themselves to finding those essences, a potentially endless quest. Essentialism also appears to be an inherent part of our psychological makeup. Humans create categories by inventing purely mental similarities, as you learned in chapter 5, and we name those categories with words. That's why a word like “pet” or “sadness” applies to a multitude of diverse instances. Words are an incredible achievement, but they are also a Faustian bargain for the human brain. On one hand, a word like “sadness,” when applied to a collection of varied perceptions, invites you to search for (or invent) some underlying sameness that transcends their noticeable differences. That is, the word “sadness” guides you to create an emotion concept, which is a good thing. But the word also invites you to believe in a reason for that sameness: some deep, unobservable, or even unknowable quality that is responsible for their equivalence, giving them their true identity. That is, words invite you to believe in an essence, and that process is conceivably the psychological origin of essentialism. William James made a similar observation over a century ago when he wrote, “Whenever we have made a word . . to denote a certain group of phenomena, we are prone to suppose a substantive entity existing beyond the phenomena, of which the word shall be the name.” The very words that help us to learn concepts can also trick us into believing that their categories reflect firm boundaries in nature. Research with children illustrates how the human brain constructs a belief in essences. A scientist shows a child a red cylinder, calling it a nonsense name like “blicket,” and demonstrates that it has a special function of lighting up a machine. Next, the child is shown two more objects, a blue square that the scientist also calls a “blicket,” and a second red cylinder that is not called a “blicket.” The child will expect only the blue square to light up the machine, despite its visual differences from the original red “blicket.” Children infer that each “blicket” contains an unseen causal force that lights the machine. This phenomenon, which scientists call induction, is an extremely efficient way for the brain to extend concepts by ignoring variation. However, induction also encourages essentialism. As a child, when you saw a friend slumped on the ground, crying at the loss of a toy, and were told that the kid felt sad, your brain inferred that there was an unseen causal force inside the child causing the feeling of sadness, the slumped body posture, and the crying. You extended your belief in this essence to other instances of children who were pouting, throwing tantrums, gritting their teeth, and engaging in other behaviors, because adults labeled them for you as sad. Emotion words reinforce the fiction that the equivalences we create are objectively real in the world, waiting to be discovered. Essentialism may also be a natural consequence of how your brain is wired. The same circuitry that allows you to form concepts and predict with them also makes essentializing easy. Your cortex learns concepts by separating similarities from differences, as you saw in chapter 6. It integrates information across vision, hearing, interoception, and the other sensory domains, compressing them into efficient summaries. Each summary is like a little imaginary essence, invented by your brain to represent that a bunch of instances from your past are similar. So, essentialism is intuitive, logically impossible to disprove, part of our psychological and neural makeup, and a self-perpetuating scourge in science. It is also the basis for the classical view's most fundamental idea, that emotions have universal fingerprints. No wonder the classical view has such stamina-it's powered by a virtually unkillable belief. When you embed essentialism in a theory of emotion, you get something more than just a doctrine on how and why you have feelings. You get-yes- a compelling story of what it means to be a human being. A classical theory of human nature. The classical story begins with your evolutionary origins. You are said to be an animal at the core. You allegedly inherited various mental essences from your non-human ancestors, including emotion essences buried deep within your subcortex. To quote Darwin, “Man, with all his noble qualities . . with his god-like intellect . . with all these exalted powers . . still bears in his bodily frame the indelible stamp of his lowly origin.” Nevertheless, the classical view considers you special because your animalistic essences come gift-wrapped in rational thought. A uniquely human essence of reason supposedly lets you regulate your emotions by rational means, placing you at the pinnacle of the animal kingdom. The classical view of human nature also speaks to personal responsibility. It says that your behavior is governed by internal forces beyond your control: you are buffeted by the world and respond emotionally on impulse, like an erupting volcano or a boiling pot. According to this view, sometimes your emotion essences and cognitive essences vie for control of your behavior, and other times the two sets of essences work together to make you wise. Either way, if you're at the mercy of strong emotions that can hijack you, the argument goes, then you might be less culpable for your actions. This assumption now sits at the foundation of Western legal systems, where so- called crimes of passion are given special treatment. Additionally, if you are completely devoid of emotion, then you are seen as more capable of inhuman acts. A serial killer who feels no remorse, some believe, is somehow less human than a murderer who deeply regrets his actions. If this is the case, then morality would be rooted in your ability to feel certain emotions. The classical view also draws hard boundaries between you and the outside world. As you look around, you see objects like trees, rocks, houses, snakes, and other people. These objects exist outside your anatomical body. In this view, falling trees make a sound whether you're present or not. Your emotions, thoughts, and perceptions, on the other hand, are said to exist inside your anatomical body, each with its own essence. So, by implication, your mind would be completely inside you and the world completely outside you. In a sense, the classical view wrenched human nature away from religion and placed it into the hands of evolution. You are no longer an immortal soul but a collection of specialized, distinct, inner forces. You come into the world preformed, not in God's image but by your genes. You perceive the world accurately, not because God designed you this way but because the survival of your genes to the next generation depends on it. And your mind is a battleground, not of good and evil, righteousness and sin, but of rationality and emotionality, cortex over subcortex, inner versus outer forces, the thoughts in your brain versus the emotions in your body. You, with your animal brain wrapped in rational cortex, are distinct from other animals in nature, not because you have a soul but because you are the pinnacle of evolution, endowed with insight and reason. Darwin embodied this essentialist view of human nature. Even though he vanquished essentialism from our understanding of the natural world, when it came to humans' place in that world, essentialism got the better of him. Expression covered all three parts of the classical view of human nature: that animals and humans share universal essences of emotion, that emotions seek expression in the face and body outside of our control, and that they are triggered by the outside world. In the years that followed, however, Darwin's own essentialism came back to bite him in the behind. As Darwin's intellectual descendants adopted his views, shaping the classical view, they ironically misinterpreted (or twisted?) his own words to conform more fully to essentialism. Darwin indeed stated in Expression that humans display universal facial expressions that evolved from a common ancestor: With mankind some expressions, such as the bristling of the hair under the influence of extreme terror, or the uncovering of the teeth under that of furious rage, can hardly be understood, except on the belief that man once existed in a much lower and animal-like condition. The community of certain expressions in distinct though allied species, as in the movements of the same facial muscles during laughter by man and by various monkeys, is rendered somewhat more intelligible, if we believe in their descent from a common progenitor. On first glance, you might think Darwin is saying that facial expressions are a useful and functional product of evolution, and, in fact, the classical view was founded on this idea. However, Darwin actually said the opposite. He wrote that smiles, frowns, eye-widening, and other expressions were useless, vestigial movements-products of evolution that no longer serve a function, like the human tailbone and appendix and the wings of the ostrich. He made this statement over a dozen times in Expression. Emotional expressions were primarily a compelling example for his broader arguments about evolution. If these expressions are useless in humans but shared with other animals, according to Darwin, they must exist because they were functional in a long-gone, common ancestor. Vestigial expressions would provide strong evidence that humans were animals, justifying his earlier views about natural selection from On the Origin of Species in 1859, which he then applied to human evolution in his next book, The Descent of Man, and Selection in Relation to Sex, in 1871. If Darwin didn't claim that emotional expressions evolved to serve a survival function, then why do so many scientists fervently believe that he claimed this? I discovered the answer in the manuscripts of an early- twentieth-century American psychologist, Floyd Allport, who wrote extensively on Darwin's ideas. In 1924, Allport made a sweeping inference from Darwin's writing that significantly changed the original meaning. Allport wrote that expressions begin as vestigial in newborns but quickly assume function: “Instead of the biologically useful reaction being present in the ancestor and the expressive vestige in the descendant, we regard both these functions as present in the descendant, the former serving as a basis from which the latter develops.”23 Allport's modification obtained a certain authenticity and validity, despite being inaccurate, because it supported the classical view of human nature. It was eagerly adopted by like-minded scientists who could now claim to be the heirs of the unassailable Charles Darwin. In reality, they are merely the heirs of Darwin-hacking Floyd Allport. As you can see, Darwin's name sometimes functions like a magical cloak that wards off the evil spirits of scientific criticism. It allowed Floyd Allport and John Dewey to transmute the words of William James and Darwin himself into their diametric opposites and shore up the classical view of emotion. The cloak is protective, for if you disagree with a Darwinian idea, you must be denying evolution. (Heck, you're probably a closet creationist.) Darwin's magical cloak also helped to propagate the mistaken idea that the brain evolved as a bunch of blobs with distinct, dedicated functions. This key belief of the classical view led many scientists down the fruitless path of searching for emotion blobs in the brain. The path was paved by a Darwin- swaddled physician from the mid-nineteenth century, Paul Broca, who claimed to have discovered the brain blob for human language. He observed that patients with damage to a region of the left frontal lobe were rendered unable to speak fluently, a condition called nonfluent or expressive aphasia. When a person with Broca's aphasia tries to say something meaningful, the words come out jumbled: “Thursday, er, er, er, no, er, Friday . . Bar-ba-ra . . wife . . and, oh, car . . drive . . purnpike [sic] . . you know . . rest and . . TV.” Broca inferred that he'd found the essence of language in the brain, much like classical view scientists point to amygdala lesions as proof of fear circuitry. The region has been known as Broca's area ever since. The thing is, Broca had scant evidence for his claims, and other scientists had plenty of evidence that he was wrong. They pointed out, for example, that other patients with nonfluent aphasia had a perfectly healthy Broca's area. But Broca's idea prevailed anyway because it was protected by Darwin's magical cloak reinforced by a healthy dose of essentialism. Thanks to Broca, scientists now had an evolutionary story for the origin of language-that it's located in “rational” cortex-countering the prevailing belief that language was given by God. Today's textbooks in psychology and neurology still hold up Broca's area as the clearest example of localized brain function, even as neuroscience has shown that the region is neither necessary nor sufficient for language.* Broca's area is actually a failure to localize a psychological function to a brain blob. Nevertheless, history was rewritten in Broca's favor, lending strength to essentialist views of the mind. Broca and his Darwinian cloak went on to reinforce the classical fiction that emotion and reason evolved as layers in the brain, which you encountered in chapter 4 as the “triune brain.” Broca was inspired by Darwin's claims in The Descent of Man that the human mind, like the human body, was sculpted by evolution. Darwin wrote that “animals are excited by the same emotions as ourselves,” surmising that human brains, like the rest of the human body, reflect our “lowly origin.” So Broca and other neurologists and physiologists launched a grand search for animalistic emotion circuits-our inner beast. They focused on what they believed to be ancient parts of the brain, whose circuits were allegedly regulated by the more evolutionarily advanced cortex. Broca localized the “inner beast” in what he believed to be an ancient “lobe” deep within the human brain. He named it le grand lobe limbique, or “the limbic lobe.” Broca did not brand his supposed lobe as the seat of emotion (actually, he thought it housed the sense of smell and other primitive survival circuitry), but he did treat limbic tissue as a single, unified entity, laying the first stone on a path toward essentializing it as the home of emotion. Over the next century, Broca's limbic lobe morphed into a unified “limbic system” for emotion, guided by other believers in the classical view. This so-called system was said to be evolutionarily old; to be virtually unchanged from its origin in non-human mammals; and to control the heart, lungs, and other internal organs of the body. It allegedly lay between ancient “reptilian” circuits in the brainstem for hunger, thirst, and so on, and the newer, uniquely human layers of cortex that regulate mankind's animalistic emotions. This illusory hierarchy embodied Darwin's ideas about human evolution-base appetites having evolved first, followed by wild emotional passions, with rationality as our crowning glory. Scientists inspired by the classical view have claimed to localize many different emotions to limbic brain regions, such as the amygdala, that are (allegedly) under the control of the cortex and cognition. Modern neuroscience, however, has shown that the so-called limbic system is a fiction, and experts in brain evolution no longer take it seriously, let alone consider it a system. Accordingly, it's not the home of emotion in the brain, which is unsurprising because no single brain area is dedicated to emotion. The word “limbic” still has meaning (when referring to brain anatomy), but the limbic system concept was just another example of applying an essentialist, Darwin-flavored ideology to the structure of the human body and brain. Long before Broca fashioned his first brain blob, the classical and construction views of human nature were at war. In Ancient Greece, Plato divided the human mind into three types of essences: rational thoughts, passions (which today we would call emotions), and appetites like hunger and sex drive. Rational thought was in charge, controlling the passions and appetites, an arrangement that Plato described as a charioteer wrangling two winged horses. A hundred years earlier, however, his countryman Heraclitus (chapter 2) was arguing that the human mind constructs perception in the moment, like constructing a river from countless drops of water. In Ancient Eastern philosophy, traditional Buddhism enumerated more than fifty discrete mental essences, called dharmas, some of which bear a striking resemblance to the so-called basic emotions of the classical view. Centuries later, a radical revision of Buddhism recast the dharmas as human constructions dependent on concepts. From those initial skirmishes, the war has continued throughout recorded history. The eleventh-century scientist Ibn al-Haytham, who made seminal contributions to developing the scientific method, held the constructionist view that we perceive the world through judgment and inference. Medieval Christian theologians were essentialists, associating different cavities in the brain with distinct essences of memory, imagination, and intelligence. Philosophers in the seventeenth century, such as René Descartes and Baruch Spinoza, believed in emotion essences and catalogued them, while eighteenth- century philosophers like David Hume and Immanuel Kant argued more for construction and perception-based explanations for human experience. The neuroanatomist Franz Joseph Gall in the nineteenth century founded phrenology, perhaps the ultimate essentialist view of the brain, to detect and measure mental essences as bumps on the skull (!!). Shortly thereafter, William James and Wilhelm Wundt espoused constructionist theories of the mind; as James wrote, “A science of the relations of mind and brain must show how the elementary ingredients of the former correspond to the elementary functions of the latter.” James and Darwin were also casualties within this war over human nature, as their views of emotion were, shall we say, “adjusted,” and the spoils went to scientists such as Broca who claimed a victory for evolution . . or at least an essentialist sort of evolution. Plato's essences of the mind are still around today, though their names have changed (and we've dispensed with the horses). Nowadays we call them perception, emotion, and cognition. Freud called them the id, the ego, and the superego. The psychologist and Nobel laureate Daniel Kahneman metaphorically calls them System 1 and System 2. (Kahneman is very careful to say it's a metaphor, but many people seem to be ignoring him and essentializing Systems 1 and 2 as blobs in the brain.) The “triune brain” names them the reptilian brain, the limbic system, and the neocortex. Most recently, the neuroscientist Joshua Greene has used the intuitive analogy of a camera, which can operate quickly and effortlessly using its automatic settings, or more flexibly and deliberately in manual mode. On the other side of the fence, construction views of the mind are plentiful today. Psychologist and bestselling author Daniel L. Schacter has a construction theory of memory. And you can easily find construction theories for perception, the self, concept development, brain development (neuroconstruction), and of course the theory of constructed emotion. The battles today are all the more intense because it's easy for each side to view the other in caricature. The classical view often dismisses construction as saying everything is relative, as if the mind were merely a blank slate and biology can be disregarded. Construction blasts the classical view for ignoring the powerful effects of culture and justifying the status quo. In caricature, the classical view says “nature” and construction says “nurture,” and the result has been a wrestling match between straw men. Modern neuroscience, however, has burned down both caricatures. We are not blank slates, and our children are not “Silly Putty” to be shaped this way and that, but neither is biology destiny. When we peer into the workings of a functioning brain, we don't see mental modules. We see core systems that interact continuously in complex ways to produce many sorts of minds, depending on culture. The human brain is itself a cultural artifact because it is wired by experience. We have genes that are turned on and off by the environment, and other genes that regulate how sensitive to the environment we are. I'm not the first person to make these points. But I am perhaps the first one to point out how brain evolution, brain development, and its resulting anatomy point in a clear direction for the science of emotion and our view of human nature. Ironically, the millennia-long war over human nature has itself been tainted by essentialism. Both sides have assumed that a single, superior force must be shaping the brain and designing the mind. In the classical view, this force has been nature, God, and then evolution. In construction, it has been the environment and then culture. But neither biology nor culture is responsible alone. Others have made this point before me, but it's time to take it seriously. We don't know every detail about how the mind and brain work, but we know enough to say definitively that neither biological determinism nor cultural determinism is correct. The boundary of the skin is artificial and porous. As Steven Pinker so nicely writes, “It is now simply misguided to ask whether humans are flexible or programmed, whether behavior is universal or varies across cultures, whether acts are learned or innate.” The devil is in the details, and the details give us the theory of constructed emotion. Now that the final nails are being driven into the classical view's coffin in this era of neuroscience, I would like to believe that this time, we'll actually push aside essentialism and begin to understand the mind and brain without ideology. That's a nice thought, but history is against it. The last time that construction had the upper hand, it lost the battle anyway and its practitioners vanished into obscurity. To paraphrase a favorite sci-fi TV show, Battlestar Galactica, “All this has happened before and could happen again.” And since the last occurrence, the cost to society has been billions of dollars, countless person-hours of wasted effort, and real lives lost. My cautionary tale begins in the early twentieth century, when scientists inspired by Darwin and the mutant James-Lange theory were searching in vain for the essences of anger, sadness, fear, and so on. Their repeated failures eventually led them to a creative solution. If we cannot measure emotions in the body and brain, they said, we'll measure only what happens before and after: the events that bring on an emotion and the physical reactions that result. Never mind what's happening inside that skull thing in the middle. Thus began the most notorious historical period in psychology, called behaviorism. Emotions were redefined as mere behaviors for survival: fighting, fleeing, feeding, and mating, collectively known as the “four F's.” To a behaviorist, “happiness” equaled smiling, “sadness” was crying, and “fear” was the act of freezing in place. And so, the nagging problem of finding the fingerprints of emotional feelings was, with the flick of a pen, defined out of existence. Psychologists often recount stories of behaviorism in the same chilling tones as a ghost story around a campfire. It declared that thoughts, feelings, and the rest of the mind were unimportant to behavior or might not even exist. During this “dark ages” of emotion research, which lasted for several decades, nothing worthwhile was discovered on human emotion (supposedly). Ultimately, most scientists rejected behaviorism because it ignores a basic fact: that each of us has a mind, and in every waking moment of life, we have thoughts and feelings and perceptions. These experiences, and their relation to behavior, must be explained in scientific terms. Psychology emerged from the darkness in the 1960s, according to the official history, as a cognitive revolution reinstated the mind as a topic of scientific inquiry, likening emotion essences to modules or organs in a mind that was thought to function like a computer. With this transformation, the final pieces of the modern classical view fell into place, and the two main flavors of the classical view- basic emotion theory and classical appraisal theories-were officially anointed. That's what the history books say . . but history books are written by the victors. The official history of emotion research, from Darwin to James to behaviorism to salvation, is a byproduct of the classical view. In reality, the alleged dark ages included an outpouring of research demonstrating that emotion essences don't exist. Yes, the same kind of counterevidence that we saw in chapter 1 was discovered seventy years earlier . . and then forgotten. As a result, massive amounts of time and money are being wasted today in a redundant search for fingerprints of emotion. I discovered this quite by chance in 2006 while cleaning my office, when I stumbled across a couple of old papers from the 1930s when emotion research was allegedly dead. These papers did not embrace behaviorism. They said that emotions do not have biological essences. Following a trail of references, I discovered a treasure trove of over a hundred publications, written across a span of fifty years, that most of my scientific colleagues had never heard of. The writers were nascent constructionists, though they did not use that term. They were running experiments to find physical fingerprints for distinct emotions, failing to do so, concluding that the classical view was unjustified, and speculating about constructionist ideas. I call this band of scientists the Lost Chorus because their work, published in prestigious journals, has been largely overlooked, ignored, or misunderstood since the supposed dark ages ended. Why did the Lost Chorus flourish for half a century and then vanish? My best guess is that these scientists did not offer a fully formed, alternative theory of emotion to compete with the compelling classical view. They presented solid counterevidence to be sure, but criticism alone was not enough to remain relevant. As philosopher Thomas Kuhn wrote about the structure of scientific revolutions: “To reject one paradigm without simultaneously substituting another is to reject science itself.” So when the classical view reasserted itself in the 1960s, half a century of anti-essentialist research was swept into history's dustbin. And we are all the poorer for it, considering how much time and money are being wasted today in pursuit of illusory emotion essences. At press time, Microsoft is analyzing facial photographs in an attempt to recognize emotion. Apple has recently purchased Emotient, a startup company using artificial intelligence techniques in an effort to detect emotion in facial expressions. Companies are programming Google Glass ostensibly to detect emotion in facial expressions in an effort to help autistic children. Politicians in Spain and Mexico are engaging in so-called neuropolitics to discern voter preferences from their facial expressions. Some of the most pressing questions about emotion remain unanswered, and important questions remain obscured, because many businesses and scientists continue practicing essentialism while the rest of us are figuring out how emotions are made. It's hard to give up the classical view when it represents deeply held beliefs about what it means to be human. Nevertheless, the facts remain that no one has found even a single reliable, broadly replicable, objectively measurable essence of emotion. When mountains of contrary data don't force people to give up their ideas, then they are no longer following the scientific method. They are following an ideology. And as an ideology, the classical view has wasted billions of research dollars and misdirected the course of scientific inquiry for over a hundred years. If people had followed evidence instead of ideology seventy years ago, when the Lost Chorus pretty solidly did away with emotion essences, who knows where we'd be today regarding treatments for mental illness or best practices for rearing our children. Every scientific journey is a story. Sometimes it's a story of gradual discovery: “Once upon a time, people didn't know very much, but we learned more and more over the years, and today we know lots of stuff.” Other times, it's a tale of radical change: “Everyone used to believe something that seemed correct, but boy were we wrong! Now the fascinating truth is here.” Our journey is more of a story within a story. The inner story is how emotions are made, wrapped in an outer story of what it means to be human. “For two thousand years, people believed something about emotions, despite abundant counterevidence all around us. The human brain, you see, is wired to mistake its perceptions for reality. Today, powerful tools have yielded a more evidence-based explanation that's almost impossible to ignore . . yet some people still manage.” The good news is that we're in a golden age of mind and brain research. Many scientists are now on a path forged by the data, rather than ideology, to understand emotion and ourselves. This new, data-driven understanding leads to innovative ideas about how to live a fulfilling and healthful life. If your brain operates by prediction and construction and rewires itself through experience, then it's no overstatement to say that if you change your current experiences today, you can change who you become tomorrow. The next few chapters delve into these implications in the areas of emotional intelligence, health, law, and our relationships with other animals."
  },
  {
    "index": 14,
    "level": 1,
    "start_page": 173,
    "end_page": 194,
    "title": "Mastering Your Emotions",
    "content": "Mastering Your Emotions. Every time you bite into a juicy peach or munch a bag of crunchy potato chips, you're not simply replenishing your energy. You're having an experience that is pleasant, unpleasant, or something in between. You bathe not only to stave off disease but also to enjoy warm water against your skin. You seek out other people not to stand in a herd for protection from predators but to feel the glow of friendship or to unload when you're feeling burdened. And sex is clearly for more than propagating your genes. These examples show that you have a special link between the physical and the mental. Each time you perform a physical act for your body budget, you're also doing something mental with concepts. Every mental activity has a physical effect as well. You can put this connection to work for you, to master your emotions, enhance your resilience, become a better friend or parent or lover, and even change your conception of who you are. Change is not easy. Ask any therapist or Buddhist monk; they've trained for years to become aware of their experiences and control them. Even so, you can take small steps right now based on the theory of constructed emotion and the new view of human nature it implies. Some of the suggestions I propose in this chapter will sound familiar, like getting enough sleep, but with new scientific justification to motivate you. Other advice will probably be entirely new, like learning words from a foreign language, which you've probably never associated with emotional health. Not every suggestion will be right for you; some will fit your lifestyle better than others. But the effort can lead to greater well-being and success. Students with a richer emotion vocabulary do better in school. People with a balanced body budget are less likely to develop serious illnesses like diabetes and heart disease, and as they age, their mental abilities will stay sharper for longer. And life may become more meaningful and fulfilling. Can you snap your fingers and change your feelings at will, like changing your clothes? Not really. Even though you construct your emotional experiences, they can still bowl you over in the moment. However, you can take steps now to influence your future emotional experiences, to sculpt who you will be tomorrow. I don't mean that in some vague, pseudo-spiritual, let's-illuminate-your-cosmic-soul kind of way, but in a very real, predicting- brain way. Everything you've read so far about interoception, affect, body budgets, prediction, prediction error, concepts, and social reality has broad and deep practical implications for who you are and how you live your life. That's our theme as we enter the final part of this book, which begins here with emotional well-being and then continues to health (chapter 10), the law (chapter 11), and non-human animals (chapter 12). For the remainder of the book, we'll apply our new view of human nature, especially the porous boundary between the physical and the social, to architect a recipe for living. The major ingredients in that recipe are your body budget and your concepts. If you maintain a balanced body budget, you'll feel better in general, so that's where we'll start. And if you develop a rich set of concepts, you'll have a toolbox for a meaningful life. Typical self-help books focus on your mind. If you think differently, they say, you will feel differently. You can regulate your emotions if you try hard enough. These books, however, don't give much consideration to your body. If there's one thing that (I hope) you've learned from the past five chapters, it's that your body and your mind are deeply interconnected. Interoception drives your actions. Your culture wires your brain. The most basic thing you can do to master your emotions, in fact, is to keep your body budget in good shape. Remember, your interoceptive network labors day and night, issuing predictions to maintain a healthy budget, and this process is the origin of your affective feelings (pleasantness, unpleasantness, arousal, and calmness). If you want to feel good, then your brain's predictions about your heart rate, breathing, blood pressure, temperature, hormones, metabolism, and so on, must be calibrated to your body's actual needs. If they aren't, and your body budget gets out of whack, then you're going to feel crappy no matter what self-help tips you follow. It's just a matter of which flavor of crap. Modern culture, unfortunately, is engineered to screw up your body budget. Many of the products sold in supermarkets and chain restaurants are pseudo- food loaded with budget-warping refined sugar and bad fats. Schools and jobs require you to wake early and go to sleep late, leaving over 40 percent of Americans between the ages of thirteen and sixty-four regularly sleep- deprived, a condition that can lead to chronic misbudgeting and possibly depression and other mental illnesses. Advertisers play on your insecurities, suggesting you'll be judged badly by your friends unless you buy the right clothing or car, and social rejection is toxic for your body budget. Social media offers new opportunities for social rejection and adds ambiguity, which is even worse for your body budget. Friends and employers expect you to be surgically attached to your cell phone at all hours, which means you never truly relax, and late-night screen time disrupts your sleeping patterns. Your culture's expectations for work, rest, and socializing determine how easily you can manage that internal budget. Social reality transmutes into physical reality. Your body budget, you may remember, is regulated by predictive circuitry in your interoceptive network. If those predictions become chronically out of sync with your body's actual needs, it's hard to bring them back into balance. Your body-budgeting circuitry, the loudmouth of your brain, doesn't respond quickly to counterevidence (prediction error) from your body. Once the predictions have been off-base for long enough, you will feel chronically miserable. When people feel crappy on a regular basis, quite a few of them self- medicate. Thirty percent of all medications consumed in the United States are taken to manage some form of distress. For these sufferers, their predictions are regularly not calibrated to their bodies' actual expenditures, likely because their brain is misestimating the cost. So they feel miserable and take medication, or they turn to alcohol or certain street drugs like opiates. That's the bad news. What can you do, practically speaking, to keep your predictions calibrated and body budget balanced? I apologize if I suddenly sound like your mother, but the road begins with eating healthfully, exercising, and getting enough sleep. I know, I know, it sounds mundane or even trite, but sadly there is no substitute, biologically speaking. A body budget, like a financial budget, is easier to maintain when you have a solid foundation. When you were a baby, your caretakers entirely managed your body budget. As you grew, they gradually transferred more and more responsibility for maintaining your budget to you. Today your friends and family might pitch in a little, but its nourishment is pretty much up to you. So to whatever extent you can, eat your greens, go easy on the refined sugars and bad fats and caffeine, work out vigorously and regularly, and get plenty of sleep. This advice might seem impossible without significant changes in the structure and habits of your life. For some people, the difficulty comes in resisting junk food and excessive TV time and other temptations of mainstream culture. Other people who struggle to make ends meet, who have to choose between eating and paying the bills, might not have the luxury of making lifestyle changes. But please do what you can. The science is crystal clear on healthful food, regular exercise, and sleep as prerequisites for a balanced body budget and a healthy emotional life. A chronically taxed body budget increases your chances of developing a host of different illnesses, as we'll see in the next chapter. A next line of attack is to modify your physical comfort if you can. Try a massage from a lover, a close friend, or a paid massage therapist (if you can afford it). Human touch is good for your health-it improves your body budget by way of your interoceptive network. Massage is especially helpful after vigorous exercise. It limits inflammation and promotes faster healing of the tiny tears in muscle tissue that result from exercise, which you might otherwise experience as unpleasant. Yet another budget-balancing activity is yoga. People who practice yoga long-term are able to calm down more quickly and effectively, probably due to some combination of physical activity and the slow-paced breathing. Yoga also reduces levels of certain proteins, called proinflammatory cytokines, that over the long term promote harmful inflammation in your body. (We'll learn more about these proteins in the next chapter.) Regular exercise also increases the levels of other proteins, called anti-inflammatory cytokines, that reduce your chances of developing heart disease, depression, and other illnesses. Your physical surroundings also affect your body budget, so if possible, try to spend time in spaces with less noise and crowding, and more greenery and natural light. Not many of us can afford to sculpt our environment by moving into a new house or redecorating, but it is amazing what a simple houseplant will do. Environmental factors like these are so important to your body budget that they even appear to help psychiatric patients recover more quickly. Diving into a compelling novel is also healthful for your body budget. This is more than mere escapism; when you get involved in someone else's story, you aren't as involved in your own. Such mental excursions engage part of your interoceptive network, known as the default mode network, and keep you from ruminating (which would be bad for the budget). If you are not a reader, see a compelling film. If the story is sad, have a good cry, which is also beneficial to the budget. Here's another simple budget-booster: set up regular lunch dates with a friend and take turns treating each other. Research shows that giving and gratitude have mutual benefits for the body budgets involved, so when you take turns, you reap the benefits. (And over the long run, it costs the same as splitting the checks.)9 There are many more things you can try that I haven't mentioned yet. Adopt a pet, which gives you touch and unconditional adoration at the same time. Take walks in a public garden or park. Look online for research on your favorite hobbies, to see if they're beneficial for stress, or just try things out and see what works. Knitting works, apparently; for me, it's counted cross- stitch. Changing your habits to suit your body budget is never easy, and sometimes it's impossible, but try these techniques wherever you can. They will lift your mood and you'll feel less stressed more of the time. After attending to your body budget, the next best thing you can do for emotional health is to beef up your concepts, otherwise known as “becoming more emotionally intelligent.” People with a classical view mindset think about emotional intelligence as “detecting” other people's emotions “accurately,” or experiencing happiness and avoiding sadness “at the right time.” With our new understanding of emotions, however, we can think about emotional intelligence in a new way. “Happiness” and “Sadness” are each populations of diverse instances. Therefore, emotional intelligence (EI) is about getting your brain to construct the most useful instance of the most useful emotion concept in a given situation. (And also when not to construct emotions but instances of some other concept.) Daniel Goleman, bestselling author of Emotional Intelligence, argues that higher EI leads to greater success in academics, business, and social relationships. “For star performance in all jobs, in every field,” he writes, “emotional competence is twice as important as purely cognitive abilities.” So you might be surprised to hear that science still has no generally accepted definition or measure of EI. Goleman's books offer a lot of reasonable, practical advice, but they don't properly explain why his advice works. Their scientific justification is heavily influenced by the outdated “triune brain” model-if you regulate your alleged emotional inner beast effectively, then you're emotionally intelligent. Emotional intelligence is better characterized in terms of concepts. Suppose you knew only two emotion concepts, “Feeling Awesome” and “Feeling Crappy.” Whenever you experienced emotion or perceived someone else as emotional, you could categorize only with this broad brush. Such a person cannot be very emotionally intelligent. In contrast, if you could distinguish finer meanings within “Awesome” (happy, content, thrilled, relaxed, joyful, hopeful, inspired, prideful, adoring, grateful, blissful . .), and fifty shades of “Crappy” (angry, aggravated, alarmed, spiteful, grumpy, remorseful, gloomy, mortified, uneasy, dread-ridden, resentful, afraid, envious, woeful, melancholy . .), your brain would have many more options for predicting, categorizing, and perceiving emotion, providing you with the tools for more flexible and functional responses. You could predict and categorize your sensations more efficiently, and better tailor your actions to your environment. What I'm describing is emotional granularity, the phenomenon (described in chapter 1) that some people construct finer-grained emotional experiences than others do. People who make highly granular experiences are emotion experts: they issue predictions and construct instances of emotion that are finely tailored to fit each specific situation. At the other end of the spectrum, there are young children who haven't yet developed adult-like emotion concepts, and who use “sad” and “mad” interchangeably to mean feeling unpleasant (as we discussed in chapter 5). My lab has shown that adults run the whole range from low to high emotional granularity. So, a key to EI is to gain new emotion concepts and hone your existing ones. There are many ways to gain new concepts: taking trips (even just a walk in the woods), reading books, watching movies, trying unfamiliar foods. Be a collector of experiences. Try on new perspectives the way you try on new clothing. These kinds of activities will provoke your brain to combine concepts to form new ones, changing your conceptual system proactively so you'll predict and behave differently later. For example, in our household, my husband, Dan, is in charge of recycling because I am forever placing inappropriate items into the bin, like cellophane or wood, because by God, they should be recyclable. Instead of getting frustrated by the extra work I make for him, Dan applied a concept from his childhood, when he collected superhero comic books. My fruitless attempts at bucking reality became a “Superpower” that he calls wishful recycling. An irritating habit was thus transformed into an amusing foible. Perhaps the easiest way to gain concepts is to learn new words. You've probably never thought about learning words as a path to greater emotional health, but it follows directly from the neuroscience of construction. Words seed your concepts, concepts drive your predictions, predictions regulate your body budget, and your body budget determines how you feel. Therefore, the more finely grained your vocabulary, the more precisely your predicting brain can calibrate your budget to your body's needs. In fact, people who exhibit higher emotional granularity go to the doctor less frequently, use medication less frequently, and spend fewer days hospitalized for illness. This is not magic; it's what happens when you leverage the porous boundary between the social and the physical. So, learn as many new words as possible. Read books that are outside of your comfort zone, or listen to thought-provoking audio content like National Public Radio. Don't be satisfied with “happy”: seek out and use more specific words like “ecstatic,” “blissful,” and “inspired.” Learn the difference between “discouraged” or “dejected” versus generically “sad.” As you build up the associated concepts, you'll become able to construct your experiences more finely. And don't limit yourself to words in your native language. Pick another language and seek out its concepts for which your language has no words, like the Dutch emotion of togetherness, gezellig, and the Greek feeling of major guilt, enohi. Each word is another invitation to construct your experiences in new ways. Try also to invent your own emotion concepts, using your powers of social reality and conceptual combination. The author Jeffrey Eugenides presents a collection of amusing ones in his novel Middlesex, including “the hatred of mirrors that begins in middle age,” “the disappointment of sleeping with one's fantasy,” and “the excitement of getting a room with a minibar,” though he does not assign them words. You can do the same thing yourself. Close your eyes and imagine yourself in a car, driving away from your hometown, knowing that you will never, ever return. Can you characterize that feeling by combining emotion concepts? If you can employ this technique day to day, you'll be better calibrated to cope with varied circumstances, and potentially more empathic to others, with improved skill to negotiate conflict and get along. You can even name your creations, like my word “chiplessness” in chapter 7, and teach them to your family and friends. Once you've shared your creations, they are just as real as any other emotion concept and bring the same benefits to your body budget. An emotionally intelligent person not only has lots of concepts but also knows which ones to use and when. Just like painters learn to see fine distinctions in colors, and wine lovers develop their palettes to experience tastes that non-experts cannot, you can practice categorizing like any other skill. Suppose you see your teenage son heading out to school looking like he just rolled out of bed: hair unkempt, clothing wrinkled, and remnants of last night's dinner dotting his shirt. You could berate him and send him back to his room to change, but instead, ask yourself what you are feeling. Are you concerned that his teachers won't take him seriously? Disgusted by his greasy hair? Nervous that his attire will reflect badly on you as a parent? Irritated that you spend money on clothing he never wears? Or perhaps you're sad that your little boy has grown up and you miss the exuberance of his childhood. If all this introspection sounds implausible, realize that people pay good money to therapists and life coaches for exactly this purpose: to help them reframe situations, that is, find the most useful categorization in the service of action. You can do it yourself and become an expert categorizer of emotion with enough practice, and it gets easier with repetition. Fine-grained categorizations have been shown to beat two other popular approaches for “regulating” emotions, in a study about fear of spiders. The first approach, called cognitive reappraisal, taught subjects to describe the spider in a nonthreatening way: “Sitting in front of me is a little spider, and it's safe.” The second approach was distraction, having the subjects pay attention to something unrelated instead of the spider. The third was to categorize sensations with greater granularity, such as: “In front of me is an ugly spider and it is disgusting, nerve-wracking, and yet, intriguing.” The third approach was the most effective in helping people with arachnophobia to be less anxious when observing a spider and to actually approach spiders. The effects lasted a week beyond the experiment, too. Higher emotional granularity has other benefits for a satisfying life. In a collection of scientific studies, people who could distinguish finely among their unpleasant feelings-those “fifty shades of feeling crappy”-were 30 percent more flexible when regulating their emotions, less likely to drink excessively when stressed, and less likely to retaliate aggressively against someone who has hurt them. For people who suffer from schizophrenia, those who exhibit higher emotional granularity report better relationships with family and friends, compared to those who exhibit lower granularity, and are better able to choose the correct action in social situations. In contrast, lower emotional granularity is associated with all sorts of afflictions. People who have major depressive disorder, social anxiety disorder, eating disorders, autism spectrum disorders, borderline personality disorder, or who just experience more anxiety and depressed feelings all tend to exhibit lower granularity for negative emotion. People who are diagnosed with schizophrenia exhibit low granularity for distinguishing positive from negative emotions. To be clear, nobody is claiming that low granularity causes these disorders, but it conceivably plays some role. After improving your emotional granularity, another way to hone your concepts, which is popular with therapists and self-help books, is to keep track of your positive experiences each day. Can you find anything that can make you smile, even briefly? Each time you attend to positive things, you tweak your conceptual system, reinforcing concepts about those positive events and making them salient in your mental model of the world. It's even better if you write about your experiences because, again, words lead to concept development, which will help you predict new moments to cultivate positivity. In contrast, when you ruminate about something unpleasant, you cause fluctuations in your body budget. Rumination is a vicious cycle: each time you dwell on (say) a recent breakup of a relationship, you add another instance to predict with, which expands your opportunity to ruminate. Certain concepts about your breakup, such as your final shouting match, or the look on your lover's face as he or she walked away for the last time, become entrenched in your model of the world. These concepts, as patterns of neural activity, get easier and easier for your brain to re-create, like well-trodden walking paths that grow deeper with each passerby's footsteps. You don't want them to become paved roads. Every experience you construct is an investment, so invest wisely. Cultivate the experiences you want to construct again in the future. Sometimes it's helpful to construct instances of unpleasant emotion on purpose. Think about football players who cultivate anger before a big game. They shout and jump and pump their fists in the air to get themselves in the right frame of mind for crushing the competition. By elevating their heart rates, breathing more deeply, and generally influencing their body budgets, they create a familiar physical state and categorize it in the context of the sports stadium, based on their knowledge of past situations where a particular emotion helped with performance. Their aggression also strengthens bonds with their teammates and tells their opponents to beware. This is EI at work in a somewhat unlikely place. If you are a parent, you can help your children develop the skills to become emotionally intelligent. Speak to them about emotions and other mental states as early as you can, even if you think they are too young to understand. Remember that infants develop concepts well before you realize it is happening. So look children straight in the eye, widen your eyes to grab their attention, and speak about bodily sensations and movements in terms of emotions and other mental states. “See that little boy? He is crying. He is feeling pain from falling down and scraping his knee. He is sad and probably wants a hug from his parents.” Elaborate on the feelings of storybook characters, on your children's own emotions, and on your emotions. Use a wide variety of emotion words. Talk about what causes emotions and what are their consequences to others. In general, think of yourself as your children's tour guide through the mysterious world of humans and their movements and sounds. Your detailed explanations help your children build a well-developed conceptual system for emotion. When you teach emotion concepts to children, you are doing more than communicating. You are creating reality for these kids-social reality. You're handing them tools to regulate their body budget, to make meaning of their sensations and act on them, to communicate how they feel, and to influence others more effectively. They will use these skills their whole lives. As you teach your children about emotion, try not to limit yourself to essentialist stereotypes: smiling when happy, scowling when angry, and so on. (This may be difficult, as you're competing with TV cartoons that stick to Western stereotypes of emotion.*) Help them understand the variety of the real world, that a smile may mean happiness, embarrassment, anger, or even sadness depending on context. Try also to admit when you aren't sure how you feel, when you're guessing how someone else feels, or when you guess badly. Carry on full conversations with your young child, taking turns, even when she is a baby who cannot respond verbally yet. By the time a child is a toddler, the conversational pattern matters as much as the words themselves for building emotion concepts. My husband and I never used “baby talk” with our daughter but spoke to her in fully formed, adult sentences from the time she was born, pausing afterward to let her “respond” in whatever way she could. People around us in the supermarket thought we were crazy, but we did wind up with an emotionally intelligent teenager who actually talks to adults. (And she can torture me with three-decimal precision. I'm so proud.)21 Do your children have screaming fits or throw tantrums? You can help them master their emotions and calm down by using social reality to your advantage. When my daughter, Sophia, was two and in her tantrum phase, telling her to calm down had no effect, of course. So we invented a concept called the “Cranky Fairy.” Whenever Sophia launched into a tantrum (or if we were lucky, slightly beforehand), we'd explain to her, “Oh no, the Cranky Fairy is visiting. She's making you feel cranky. Let's try to make the Cranky Fairy go away.” Then we directed her to a particular chair-a fuzzy red one with a picture of Elmo from Sesame Street-as her special place for calming down. (No, it didn't have little fuzzy red manacles.) At first we carried her to the chair, and sometimes she'd pitch a fit and kick the chair over, but eventually she would walk to it unasked and sit until her unpleasant feelings subsided. Sometimes she'd even announce that the Cranky Fairy was on her way. These practices might sound silly, but they have tangible effects. By inventing and sharing the concepts “Cranky Fairy” and “Elmo Chair” with Sophia, we created tools to help her calm herself. To her, these concepts were as real as money, art, power, and other constructions of social reality are to us. In general, children with richer conceptual systems for emotion are poised for greater academic success. In one study conducted by the Yale Center for Emotional Intelligence, schoolchildren were taught to broaden their knowledge and use of emotion words for twenty to thirty minutes per week. The results were improved social behavior and academic performance. Classrooms that employed this educational model were also better organized and were rated by blind observers as having better instructional support for students. In contrast, if you don't talk to a child about his sensations in emotional terms, you can actually hamper his developing conceptual system. After four years of life, children in higher-income homes have seen or heard four million more words than their low-income counterparts, and they have better vocabulary and reading comprehension. Children with the fewest material advantages therefore lag in the social world. A simple intervention, like advising lower-income parents to communicate with their children more, improves the children's school performance. In the same manner, using more emotion words should improve children's EI. The same principles apply when you give your children feedback about their behavior. Studies show that children in low-income homes hear 125,000 more words of discouragement than praise, while their higher-income counterparts hear 560,000 more words of praise than discouragement, all by age four. That means children from lower-income homes have a more taxed body budget but fewer resources to deal with it. We all criticize our kids now and then, but try to make your feedback specific. If your daughter is whining incessantly, instead of yelling “Knock it off,” try something like, “Your whining is irritating me, so stop it. If you are having a problem, use your words.” When your son suddenly smacks your daughter in the head, don't call him “a bad boy.” (That's not a concept you want him to develop.) Be specific: “Stop hitting your sister; it hurts her and makes her feel sad. Tell her you are sorry.” The same rule holds for praise: don't call your daughter “a good girl.” Praise her actions: “You made a good choice not hitting your brother back.” This wording helps children to build more useful concepts. Your tone of voice matters too, since it easily communicates your affect and directly impacts the child's nervous system. By regulating your children's body budgets effectively, you guide them not only to a richer conceptual system for emotion but also better overall language development, which prepares them for better academic performance in school. Okay, now you've done your best to revamp your lifestyle for a balanced budget, and you've beefed up your conceptual system to transform yourself into an emotion expert. You're still going to have ups and downs. You'll still have to deal with the compromises demanded by love, the ambiguities of your social life, the insincerity of the workplace, the fickleness of friendships, and your body slowly failing you as you age. What can you do to master your feelings in the moment? The simplest approach, believe it or not, is to move your body. All animals use motion to regulate their body budgets; if their brain serves up more glucose than their body needs, a quick scamper up a tree will bring their energy level back into balance. Humans are unique in that we can regulate the budget without moving, using purely mental concepts. But when this skill fails you, remember that you too are an animal. Get up and move around, even if you don't feel like it. Turn on some music and dance around your home. Take a walk in a park. Why does this work? Moving your body can change your predictions and therefore your experience. Your movements may also help your control network to bring other, less bothersome concepts into the foreground. Another approach to mastering your emotions in the moment is to change your location or situation, which in turn can change your predictions. During the Vietnam War, for example, 15 percent of U.S. soldiers were addicted to heroin. When they came home as veterans, 95 percent of them stayed off the drug in their first year back-an astounding figure compared to the general population, where only 10 percent of users avoid relapse. The shift in location changed their predictions, which lessened their craving for the drug. (I sometimes wonder if midlife crisis is a drastic attempt to change one's predictions by changing the context.*)27 When changes in movement and context fail to help you master your emotions, the next big thing to try is recategorizing how you feel. This will require some explanation. Anytime you feel miserable, it's because you are experiencing unpleasant affect due to interoceptive sensations. Your brain will dutifully predict causes for those sensations. Perhaps they are a message from your body, like “I have a stomachache.” Or perhaps they're saying, “Something is seriously wrong with my life.” This is the distinction between discomfort and suffering. Discomfort is purely physical. Suffering is personal. Imagine what your body looks like to an invading virus. You are just a big bag of DNA, proteins, water, and whatever other biological stuff it must steal to replicate itself. An influenza virus doesn't care about your beliefs, qualities, or values when it infects your cells. It does not make moral judgments on your character, like “Oooh, she's a snob with a bad haircut . . let's infect her!” No, a virus is egalitarian toward its victims. It brings discomfort, but it's nothing personal. All humans who haven't slept enough, with a nice wet set of lungs, can apply for the job of host. Affect, on the other hand, transforms interoceptive sensation into something about you, with your particular strengths and faults. Now the sensations are personal-they reside inside your affective niche. When you feel wretched, the world seems like an awful place. People are judging you. Wars are raging. The polar ice caps are melting. You are suffering. Most of us devote a lot of time to relieving suffering. We often eat for pleasure or to soothe ourselves, rather than for the nutrients. I think drug addiction is often a misguided attempt to relieve the suffering from a body budget that's chronically out of whack. It's tricky to distinguish discomfort and suffering in the moment. Are you feeling irritated or just having caffeine withdrawal? If you are a woman, you probably have ambiguous physical symptoms related to your menstrual cycle or during menopause, and you may categorize the sensations as having emotional meaning when they do not. I remember in 2010 when my whole lab was moving from one university to another, including twenty researchers and hundreds of thousands of dollars of equipment. Everything seemed to be going wrong, plus I was about to leave for a two-week trip. Somehow I was holding myself together, extinguishing each fire as it ignited . . and then my laptop died. I sank to the floor in the middle of my kitchen and started sobbing. At just that moment, my husband walked in, noticed my state, and asked innocently, “Are you premenstrual?” Oh. My. God. I lashed out at him, the goddamn sexist pig and how dare he be so smug when I'm barely holding my life together?? My fury shocked us both. And three days later, I discovered that he was right. With practice, you can learn to deconstruct an affective feeling into its mere physical sensations, rather than letting those sensations be a filter through which you view the world. You can dissolve anxiety into a fast- beating heart. Once you can deconstruct into physical sensations, then you can recategorize them in some other way, using your rich set of concepts. Perhaps that pounding in your chest is not anxiety but anticipation, or even excitement. Look around right now and find an object to focus on. Try recategorizing it not as a three-dimensional visual object but as the individual pieces of differently colored light that your perception is constructed from. Tough, isn't it? Nevertheless, you can train yourself to do it. Pick the shiniest part of the object and try tracing its outlines with your eye. With a lot of practice, you can learn how to deconstruct objects like this. Great artists like Rembrandt could do it and realistically render objects in paint on a canvas. In a similar manner, you can deconstruct your emotions. Recategorization is a tool of the emotion expert. The more concepts that you know and the more instances that you can construct, the more effectively you can recategorize in this manner to master your emotions and regulate your behavior. For instance, if you're about to take a test and feel affectively worked up, you might categorize your feeling as harmful anxiety (“Oh no, I'm doomed!”) or as helpful anticipation (“I'm energized and ready to go!”). The head of my daughter's karate school, Grandmaster Joe Esposito, advises his nervous students before their black belt test: “Make your butterflies fly in formation.” He is saying yes, you feel worked up right now, but don't perceive it as nervousness: construct an instance of “Determination.” Recategorization of this kind can bring tangible benefits to your life. Numerous studies have looked at performance on math tests such as the GRE and found that students achieve higher scores when they recategorize anxiety as merely a sign that the body is coping. People who recategorize anxiety as excitement show similar effects, with better performance and fewer classic symptoms of anxiety when speaking in public and even when singing karaoke. Their sympathetic nervous system still creates those jittery butterflies, but with fewer of the proinflammatory cytokines that lower performance and generally make people feel crappy, so they perform better. Studies have shown that remedial math students at community colleges can improve their exam grades and their final course grade through effective recategorization. This significant development can change the trajectory of a person's life, given that a college degree can be the difference between financial success and a lifelong struggle to make ends meet. If you can categorize your discomfort as helpful, say, when you're exercising hard, you can cultivate greater stamina. The U.S. Marine Corps has a motto that embodies this principle: “Pain is weakness leaving the body.” Whenever you exercise just until you feel unpleasant and then stop, you're categorizing your physical sensations as exhaustion. You'll always exercise below your threshold, despite the health benefits of continuing. Through recategorization, however, you can continue exercising and feel even better later, as you reap the benefits of a stronger, healthier body. The more you do it, the more you tune your conceptual system toward longer exercise in the future. Lower back pain, sports injuries, soreness from arduous medical treatments, and other ailments offer similar opportunities to distinguish between physical discomfort and affective distress. People who live with chronic pain, for example, commonly have catastrophic thoughts that appear to impact their lives even more than the intensity of the pain does. When they learn to separate their physical sensations from their unpleasant affect, they may use fewer opiate drugs and crave them less. This is a significant finding considering that nearly 6 percent of Americans use prescription medication for chronic pain each year, mostly addictive opiates that are now known to enhance pain symptoms with long-term use. According to Deborah Barrett, author of Paintracking (and my sister-in-law), when you can categorize pain as physical, the pain need not be a personal catastrophe. The notion of recategorizing suffering as discomfort, or deconstructing the mental into the physical, has ancient origins. In Buddhism, some forms of meditation help to recategorize sensations as physical symptoms to reduce suffering, a practice Buddhists call deconstructing the self. Your “self” is your identity-a collection of characteristics that somehow define you, like your assorted memories, beliefs, likes, dislikes, hopes, life choices, morals, and values. You can also define yourself by your genes, your physical characteristics (weight, eye color), your ethnicity, your personality (funny, trustworthy), the relationships you have with other people (friend, parent, child, lover), the roles you hold (student, scientist, salesperson, factory worker, physician), your geographic or ideological community (American, New Yorker, Christian, Democrat), even the car that you drive. A common core runs through all these views: the self is your sense of who you are, and it's continuous through time, as if it were the essence of you. Buddhism considers the self to be a fiction and the primary cause of human suffering. Whenever you crave material things like expensive cars and clothes, or desire compliments to enhance your reputation, or seek positions of status and power to benefit your life, Buddhism says you are treating your fictional self as real (reifying the self). These material concerns may bring immediate gratification and pleasure but they also entrap you, like golden handcuffs, and cause persistent suffering, which we would call prolonged unpleasant affect. To a Buddhist, a self is worse than a passing physical illness. It is an enduring affliction. My scientific definition of the self is inspired by the workings of the brain yet is sympathetic to the Buddhist view. The self is part of social reality. It's not exactly a fiction, but neither is it objectively real in nature like a neutron. It depends on other people. In scientific terms, your predictions in the moment, and your actions that derive from them, depend to some extent on the way that others treat you. You can't be a self by yourself. We can understand why Tom Hanks's character in the movie Cast Away, who was marooned alone on a desert island for four years, needed to create a companion named Wilson out of a volleyball. Certain behaviors and preferences are consistent with your self and some are not. There are foods you enjoy and others you'd prefer not to eat. You might call yourself a “dog person” or a “cat person.” These behaviors and preferences vary quite a bit: your favorite food might be French fries, but not at every meal. The most enthusiastic dog lovers know a couple of dogs that they can't stand and are secretly fond of a few cats. Overall, your self is like a collection of dos and don'ts that summarizes your likes, dislikes, and habits in the moment. We've seen something like this before. These dos and don'ts are like the features of a concept. So in my view, the self is a plain, ordinary concept just like “Tree,” “Things That Protect You from Stinging Insects,” and “Fear.” I am quite sure you don't go around thinking of yourself as a concept, but just go with me for a bit on this. If the self is a concept, then you construct instances of your self by simulation. Each instance fits your goals in the moment. Sometimes you categorize yourself by your career. Sometimes you're a parent, or a child, or a lover. Sometimes you're just a body. Social psychologists say that we have multiple selves, but you can think of this repertoire as instances of a single, goal-based concept called “The Self” in which the goal shifts based on context. How does your brain keep track of all the varied instances of your “Self” as an infant, a young child, an adolescent, a middle-aged adult, and an older adult? Because one part of you has remained constant: you've always had a body. Every concept you have ever learned includes the state of your body (as interoceptive predictions) at the time of learning. Some concepts involve a lot of interoception, such as “Sadness,” and others have less, such as “Plastic Wrap,” but they're always in relation to the same body. So every categorization you construct-about objects in the world, other people, purely mental concepts like “Justice,” and so on-contains a little bit of you. This is the rudimentary mental basis of your sense of self. The fiction of the self, paralleling the Buddhist idea, is that you have some enduring essence that makes you who you are. You do not. I speculate that your self is constructed anew in every moment by the same predictive, core systems that construct emotions, including our familiar pair of networks (interoceptive and control), among others, as they categorize the continuous stream of sensation from your body and the world. As a matter of fact, a portion of the interoceptive network, called the default mode network, has been called the “self system.” It consistently increases in activity during self- reflection. If you have atrophy in your default mode network, as happens in Alzheimer's disease, you eventually lose your sense of self. Deconstructing the self offers a new inspiration for how to become the master of your emotions. By tweaking your conceptual system and changing your predictions, you not only change your future experiences; you can actually change your “Self.” Suppose you are feeling bad-worried because you are struggling with your finances, angry that you did not receive the promotion you deserved, dejected because your teacher believes you are not as intelligent as other students, or heartbroken because your lover abandoned you. A Buddhist mindset would describe these feelings as the suffering that results from clinging to material wealth, reputation, power, and security in an effort to reify the self. In the language of the theory of constructed emotion, wealth, reputation, and the rest are firmly within your affective niche, impacting your body budget, which ultimately leads you to construct instances of unpleasant emotions. Deconstructing the self for a moment allows you to reduce the size of your affective niche so concepts like “Reputation,” “Power,” and “Wealth” become unnecessary. Western culture has some common wisdom associated with these ideas. Don't be materialistic. What doesn't kill us makes us stronger. Sticks and stones. But I am asking you to take this one step further. When you are suffering from some ill or insult that has befallen you, ask yourself: Are you really in jeopardy here? Or is this so-called injury merely threatening the social reality of your self ? The answer will help you recategorize your pounding heartbeat, the knot in the pit of your stomach, and your sweaty brow as purely physical sensations, leaving your worry, anger, and dejection to dissolve like an antacid tablet in water. I'm not saying this kind of recategorization is easy, but with practice it's possible, and it's also healthful. When you categorize something as “Not About Me,” it exits your affective niche and has less impact on your body budget. Similarly, when you are successful and feel proud, honored, or gratified, take a step back and remember that these pleasant emotions are entirely the result of social reality, reinforcing your fictional self. Celebrate your achievements but don't let them become golden handcuffs. A little composure goes a long way. If you are interested in taking this strategy further, try meditation. Mindfulness meditation, just one type of many, teaches you to stay alert and present in the moment but to observe sensations as they come and go, non- judgmentally.* This state (which requires tremendous practice) reminds me of the quiet, alert state of newborn babies when they observe the world, their brains comfortably awash in prediction error, with no anxiety in sight. They experience sensations and release them. Meditation achieves something similar. This state may take years of practice to achieve, so the next best thing is to recategorize your thoughts, feelings, and perceptions as physical sensations, which are easier to let go of. You can use meditation, at least at first, to prioritize categorizations that focus on the physical, and deprioritize those that add more psychological meaning about you or your place in the world. Meditation has a potent effect on brain structure and function, though scientists have not sorted out the exact details yet. Key regions in the interoceptive and control networks are larger for meditators, and connections between these regions are stronger. This matches what we might expect, since the interoceptive network is critical to constructing mental concepts and representing physical sensations from the body, and the control network is critical to regulating categorization. In some studies, we see stronger connections even after only a few hours of training. Other studies find that meditation reduces stress, improves the detection and processing of prediction error, facilitates recategorization (termed “emotion regulation”), and reduces unpleasant affect, although the findings are often inconsistent from one study to the next because not all the experiments have been well-controlled. Sometimes deconstructing the self is too challenging. You can achieve some of the same benefits more simply by cultivating and experiencing awe, the feeling of being in the presence of something vastly greater than yourself. It helps you get some distance from your self. I experienced these benefits firsthand when my family spent a few summer weeks at a beach house in Rhode Island. A symphony of crickets surrounded us each evening, resonating with an intensity I'd never heard before. I hadn't paid much attention to crickets before that, but now they entered my affective niche. I began to look forward to them every evening and to find their song comforting while falling asleep. When we returned from our vacation, I discovered that I could hear crickets through the thick walls of my home if I lay quietly enough. Now, whenever I wake in the middle of a summer night, feeling anxious after a stressful day in the lab, the crickets help me drift back to sleep. I developed an awe-inspired concept of being enveloped within nature and feeling like a tiny speck. This concept helps me change my body budget whenever I want. I can notice a tiny weed forcing its way through a crack in the sidewalk, proving yet again that nature cannot be tamed by civilization, and employ the same concept to take comfort in my insignificance. You can experience similar awe when hearing ocean waves crash against rocks on a beach, gazing at the stars, walking under storm clouds in the middle of the day, hiking deep into uncharted territory, or taking part in spiritual ceremonies. People who report feeling awe more frequently also have the lowest levels of those nasty cytokines that cause inflammation (though nobody has proved cause and effect). Whether you cultivate awe, meditate, or find other ways to deconstruct your experience into physical sensations, recategorization is a critical tool for mastering your emotions in the moment. When you feel bad, treat yourself like you have a virus, rather than assuming that your unpleasant feelings mean something personal. Your feelings might just be noise. You might just need some sleep. At this point you've seen how to work on becoming more emotionally intelligent about your experiences. Now let's turn to perceiving emotion intelligently in other people around you, and the subsequent benefits for your well-being. My husband, Dan, went through a brief, difficult time a few decades ago, before we knew each other, and was referred to a psychiatrist. About thirty seconds into the first session, Dan knitted his brow and scowled, as he often does when he is concentrating, and the psychiatrist, trusting his perceptions as accurate, pronounced that Dan was “filled with pent-up anger.” The thing is, Dan is one of the calmest people I know. When Dan assured the psychiatrist that he wasn't angry, the psychiatrist, confident in his ability to read his patients, insisted, “Yes, you are.” Well, Dan was out the door before the second hand had completed its first revolution. He may well hold the world record for the shortest therapy session. My point here isn't to knock the mental-health profession but to illustrate the false confidence that one's perceptions of other people's mental states are -or ever can be-“right.” It comes from the classical view, which proposes that Dan broadcasts anger with a distinct fingerprint and the therapist detects it, even if Dan is unaware. If you want to gain mastery at perceiving other people's emotional experiences, you must let go of this essentialist assumption. What happened during Dan's minute in therapy? He constructed an experience of concentration, and the therapist constructed a perception of anger. Both constructions were real, not in the objective sense but in the social sense. Perceptions of emotion are guesses, and they're “correct” only when they match the other person's experience; that is, both people agree on which concept to apply. Anytime you think you know how someone else feels, your confidence has nothing to do with actual knowledge. You're just having a moment of affective realism. To improve at emotion perception, we must all give up the fiction that we know how other people feel. When you and a friend disagree about feelings, don't assume that your friend is wrong like Dan's ex-therapist did. Instead think, “We have a disagreement,” and engage your curiosity to learn your friend's perspective. Being curious about your friend's experience is more important than being right. So, if our perceptions are just guesses, how do we ever communicate with each other? If you tell me that you're proud of your child's accomplishments in school, and “Pride” is a population of diverse instances with no consistent fingerprint, how can I know which “Pride” you mean? (This question doesn't arise in the classical view, where pride has a distinct essence; you simply broadcast pride and I recognize it.) You and I communicate emotion, in the face of huge variability, by way of the brain's predictive machinery. Your emotions are guided by your predictions. And as I observe you, the emotions I perceive are guided by my predictions. Emotional communication happens, therefore, when you and I predict and categorize in synchrony. Scientists and bartenders know that people synchronize in various ways when they communicate, especially if they like or trust each other. I nod, then you nod. You touch my arm and a moment later I touch yours. Our nonverbal behaviors coordinate. There's also biological synchrony; a mother's and child's heart rates will synchronize if they are securely bonded, and the same can happen to anyone during an engaging conversation. The mechanism is still a mystery. I suspect it's because their breathing synchronizes as they unconsciously observe each other's chests rising and falling. When I was a training therapist, I learned to intentionally synchronize my breathing with my clients' to prepare them for hypnosis. We likewise synchronize our concepts for emotion. My emotions are guided by my predictions. And as you observe me, the emotions you perceive are guided by your predictions. The sound of my voice and the motions of my body, as they are perceived by your brain, either confirm your predictions or become prediction error for you. Suppose you tell me, “My son got the lead in the school play. I'm so proud.” Your words and actions launch a population of predictions in my brain, helping to coordinate a shared concept of “Pride” between us in the moment. My brain computes probabilities based on past experience and winnows down its predictions to a winning instance, perhaps leading me to say, “Congratulations.” Then the process repeats in the other direction as you perceive me. We'll be more in sync if we share a cultural background or other past experiences, and if we agree that certain facial configurations, body movements, vocal acoustics, and other cues have certain meanings in certain contexts. Little by little, we co-construct an emotional experience that we both identify with the word “proud.” In this scenario, our concepts don't need to match exactly for me to understand how you feel; they just must have reasonably compatible goals. On the other hand, if I construct an instance of the unpleasant kind of pride, in which you're arrogant and dismissive, I might obtusely fail to comprehend what you are saying, because you've used a concept that does not match mine in that instance. Note that our mutual construction is a continuous process with both brains in constant activity, even though I'm portraying it here as a simple back-and-forth sequence of events. The co-construction of experience also allows us to regulate each other's body budgets; this is one of the great benefits that we get from living in groups. All members of a social species regulate each other's body budgets- even bees, ants, and cockroaches. But we are the only species who can do so by teaching each other purely mental concepts, and then using them in synchrony. Our words allow us to enter each other's affective niches, even at extremely long distances. You can regulate your friend's body budget (and he yours) even if you are an ocean apart-by phone or email or even just by thinking about one another. Your choice of words has a huge impact on this process, as those words shape other people's predictions. Parents who ask a child, “Are you upset?” instead of the more general question, “How are you feeling?” are influencing the answer, co-constructing emotion and honing the child's concepts toward being upset. Doctors who ask a patient, “Are you feeling depressed?” likewise make a positive response more likely than if they'd said, “Tell me how you've been.” These are leading questions, the same sort that attorneys utilize (and object to) with witnesses on the stand. In everyday life, as in the courtroom, you need to be mindful of influencing people's predictions by your words. Likewise, if you want someone else to know what you're feeling, you need to transmit clear cues for the other person to predict effectively and for synchrony to occur. In the classical view of emotion, the responsibility is all on the perceiver's end because emotions are supposedly displayed universally. In a construction mindset, you also bear the responsibility to be a good sender. Suppose you hadn't read this book, and someone said to you, “Pssst! Wanna be the master of your emotions? Then eat less junk food and learn lots of new words.” I admit, it sounds unintuitive. But healthful eating leads to a body budget that is easier to balance and to more calibrated interoceptive predictions, and new words seed new concepts that are a basis for constructing emotional experiences and perceptions. Many things that seem unrelated to emotion actually have a profound impact on how you feel, because of the porous boundary between the social and the physical. You are a remarkable animal who can create purely mental concepts that influence the state of your body. The social and the physical are intimately linked via your body and your brain, and your ability to move effectively between social and physical depends on a set of skills that you can learn. So grow your emotion concepts. Cultivate opportunities for your brain to wire itself to the realities of your social world. If you feel unpleasant in the moment, then deconstruct or recategorize your experiences. And realize that your perceptions of others are just guesses and not facts. Some of these new skills are supremely difficult to cultivate. It's one thing for a scientist like me to tell you, “That's how the brain works.” It's another thing entirely to up-end your whole lifestyle to take advantage of the science. Who has time to revamp their eating and sleeping habits and get more exercise, let alone learn new concepts, practice categorizing, and occasionally step back from the fiction of the self ? We all have jobs and schoolwork and time constraints and all sorts of personal and home situations. Also, some of these suggestions require an investment of time or money, which might be in short supply for the people who could benefit most. But . . everyone can find something they can try in this chapter, even if it's just taking walks or combining some emotion concepts before you go to sleep. Or giving up potato chips. (Okay, maybe not completely.) Emotion concepts and body budgeting can improve your health and well- being, as you've just seen, but they can also be a catalyst for illness. Emotions are said to influence a variety of debilitating medical disorders like depression, anxiety, and unexplained chronic pain, as well as metabolic dysfunctions that lead to type-2 diabetes, heart disease, and even cancer. At the same time, new discoveries about the nervous system are dissolving the sacred boundary between what we think of as physical and mental illness, in the same way that the theory of constructed emotion blurs the boundary between the physical and the social. That is the next topic we'll visit."
  },
  {
    "index": 15,
    "level": 1,
    "start_page": 195,
    "end_page": 213,
    "title": "Emotion and Illness",
    "content": "Emotion and Illness. Think about the last time you had a cold. You probably had a runny nose, cough, fever, and other diverse symptoms. Most people attribute colds to a single cause, namely, a cold virus. And yet, when scientists place a cold virus into the noses of one hundred people, only 25-40 percent get sick. So a cold virus cannot be the essence of a cold-something more complex must be going on. The virus is necessary but not sufficient. The diverse set of symptoms that you collectively call “a cold” involves not just your body but also your mind. For example, if you are an introverted or negative-minded person, you're more likely to develop a cold from a noseful of germs. Our new view of human nature, inspired by the theory of constructed emotion, dissolves the boundaries between the mental and physical, including where illness is concerned. Old, essentialist thinking, in contrast, keeps those dividing lines sharp. Having a problem with your brain? Then see a neurologist. If the problem is with your mind, well, you need a psychiatrist. A more modern view integrates mind and brain and offers guidance on how better to understand human illness. For example, if you look at the diverse symptoms found in illnesses like anxiety, depression, chronic pain, and chronic stress, they don't fit into a handful of neat compartments, like a silverware drawer. Each illness has tremendous variability, and all of their sets of symptoms have tremendous overlap. This situation should sound familiar. You've already learned that emotion categories like happiness and sadness have no essences; they're made by core systems in your body and brain, in the context of other bodies and brains. Now I'll suggest that some illnesses that seem distinct are likewise constructions: human-made ways of carving up the same highly variable biological pie. A construction approach to understanding illness can answer some perplexing questions that have never been resolved. Why do so many disorders share the same symptoms? Why are so many people both anxious and depressed? Is chronic fatigue syndrome a distinct illness, or merely depression in disguise? Are people who suffer from chronic pain with no identifiable tissue damage mentally ill? And why do so many people with heart disease develop depression? If differently named illnesses are related to the same set of core causes, muddying the dividing lines between those illnesses, then such questions cease to be mysteries. This is the most speculative chapter in the book, but it's informed by data, and I hope you'll find the ideas intriguing and provocative. In the pages that follow, I demonstrate that phenomena like pain and stress, and illnesses such as chronic pain, chronic stress, anxiety, and depression, are more intertwined than you might think, and they're constructed in the same manner as emotion. A key component of this viewpoint is a better understanding of the predictive brain and your body budget. Your body budget fluctuates normally throughout the day, as your brain anticipates your body's needs and shifts around your budgetary resources like oxygen, glucose, salt, and water. When you digest food, your stomach and intestines “borrow” resources from your muscles. When you run, your muscles borrow from your liver and kidneys. During these transfers, your budget remains solvent. Your body budget tilts out of balance when your brain estimates badly. This is a fairly normal occurrence. When something psychologically meaningful happens, like seeing your boss or coach or teacher walking toward you, your brain may predict unnecessarily that you need fuel, activating survival circuits that impact your budget. In general, these short- term imbalances are nothing to worry about, as long as you pay back your withdrawals by eating and sleeping. When a budget imbalance becomes prolonged, however, your internal dynamics change for the worse. Your brain mispredicts that your body needs energy over and over and over, driving your budget into the red. The effects of chronic misbudgeting can be devastating to your health and summon your body's “debt collectors,” which are part of your immune system. Usually, your immune system is one of the good guys in your body, since it protects you from invaders and injury. It helps you by causing inflammation, like the swelling you get from banging your finger by accident with a hammer, or from a bee sting or an infection. The inflammation comes from little proteins called proinflammatory cytokines, which I mentioned briefly in the previous chapter. When you have an injury or illness, your cells secrete cytokines that draw blood to the affected region, raising its temperature and causing swelling.* These cytokines can make you feel fatigued and generally sick while they go about their job of helping you heal. Proinflammatory cytokines can also become bad guys, however, given the right conditions for debt collection. This is particularly true when your body budget is chronically unbalanced, say, if you live in a dangerous neighborhood and hear gunfire every night. In such a harsh environment, your brain might regularly predict that you need more energy than your body requires. These predictions cause your body to release cortisol more often and in greater amounts than you need. Cortisol normally suppresses inflammation (that's why hydrocortisone cream relieves itching, and cortisone shots reduce swelling). When you have too much cortisol in your blood for a long time, inflammation flares up. You feel devoid of energy. You might run a fever. If someone placed a cold virus into your nose, you'd be one of the people who gets sick. Now a vicious cycle can ensue. When you feel fatigued due to inflammation, you don't move as much, in order to conserve (what your brain mistakenly believes to be) your limited energy resources. You start eating and sleeping poorly and neglect exercise, which throws your budget out of balance even more, and you start to feel seriously like crap. You might gain weight, which enhances your problems because certain fat cells actually produce the proinflammatory cytokines that make inflammation worse. You might also start avoiding other people, who then cannot help balance your body budget, and people with fewer social connections also have more proinflammatory cytokines and might even get sick more often. About ten years ago, scientists discovered-to their astonishment-that proinflammatory cytokines can cross from the body into the brain. We also now know that the brain has its own inflammatory system with cells that secrete these cytokines. These little proteins, with their capacity to induce feelings of such misery, reshape the brain. Inflammation in the brain causes changes in brain structure, particularly within your interoceptive network; it interferes with neural connections, and even kills neurons. Chronic inflammation can also make it harder for you to pay attention and remember things, lowering performance on IQ tests. So consider what happens if you're in a stressful social situation, like when a clique of coworkers suddenly stops inviting you to join them at lunch, or when friends read your text messages but don't answer. As per normal, your brain predicts you need fuel that your body doesn't require, temporarily impacting your budget. But what if the social situation doesn't resolve quickly? What if this social rejection is your life every day? Your body stays on alert, flush with cortisol and cytokines. Now your brain starts treating your body as if it were sick or damaged, and chronic inflammation sets in. Inflammation in your brain is very bad. It affects your predictions, in particular those that manage your body budget, sending your budget into overdraft. Remember that your body-budgeting circuitry is hard of hearing- it can be mostly deaf to corrections from your body. Inflammation moves the needle toward “completely deaf.” Your body-budgeting regions become insensitive to your situation, making it more likely that your budget will remain overdrawn. You can become consumed with fatigue and unpleasant feelings. The chronic misbudgeting depletes your resources, causes wear and tear on your body, and eventually builds up more proinflammatory cytokines. When that happens, you are really, truly in trouble. A chronically imbalanced body budget acts like fertilizer for disease. In the last twenty years, it has become clear that the immune system is an ingredient in far more illnesses than you might expect, including diabetes, obesity, heart disease, depression, insomnia, reduced memory, and other “cognitive” functions related to premature aging and dementia. For example, if you already have cancer, inflammation makes tumors grow faster. The cancer cells also become more likely to survive the perilous journey through the bloodstream to infect other sites in the body, a process called metastasis. Death from cancer comes sooner. Inflammation has been a game-changer for our understanding of mental illness. For many years, scientists and clinicians held a classical view of mental illnesses like chronic stress, chronic pain, anxiety, and depression. Each ailment was believed to have a biological fingerprint that distinguished it from all others. Researchers would ask essentialist questions that assume each disorder is distinct: “How does depression impact your body? How does emotion influence pain? Why do anxiety and depression frequently co- occur?”9 More recently, the dividing lines between these illnesses have been evaporating. People who are diagnosed with the same-named disorder may have greatly diverse symptoms-variation is the norm. At the same time, different disorders overlap: they share symptoms, they cause atrophy in the same brain regions, their sufferers exhibit low emotional granularity, and some of the same medications are prescribed as effective. As a result of these findings, researchers are moving away from a classical view of different illnesses with distinct essences. They instead focus on a set of common ingredients that leave people vulnerable to these various disorders, such as genetic factors, insomnia, and damage to the interoceptive network or key hubs in the brain (chapter 6). If these areas become damaged, the brain is in big trouble: depression, panic disorder, schizophrenia, autism, dyslexia, chronic pain, dementia, Parkinson's disease, and attention deficit hyperactivity disorder are all associated with hub damage. My view is that some major illnesses considered distinct and “mental” are all rooted in a chronically unbalanced body budget and unbridled inflammation. We categorize and name them as different disorders, based on context, much like we categorize and name the same bodily changes as different emotions. If I'm correct, then questions like, “Why do anxiety and depression frequently co-occur?” are no longer mysteries because, like emotions, these illnesses do not have firm boundaries in nature. I present more justification for this view as we discuss the details of stress, pain, depression, and anxiety. Let's begin with stress. You might think that stress is something that happens to you, like when you try to juggle five tasks at once, or your boss tells you that tomorrow's work was due yesterday, or you lose a loved one. But stress doesn't come from the outside world. You construct it. Some stress is positive, like the challenge of learning a new subject in school. Some is negative but tolerable, like having a fight with your best friend. And some is toxic, like the chronic stress of prolonged poverty, abuse, or loneliness. In other words, stress is a population of diverse instances. It is a concept, just like “Happiness” or “Fear,” that you apply to construct experiences from an imbalanced body budget. You construct instances of “Stress” via the same brain mechanisms that construct emotion. In each case, your brain issues predictions about your body budget in relation to the outside world and makes meaning. These predictions issue from your interoceptive network and descend along the same pathways from the brain to the body. In the opposite direction, the ascending pathways that carry sensory inputs from the body to the brain are also the same for stress and emotion. And the same pair of networks, interoceptive and control, play their same roles. (Emotion and stress researchers rarely recognize these similarities, and tend to ask how stress influences emotion and vice versa, as if stress and emotion are independent.) From the viewpoint of construction, what differs is the end result, whether your brain categorizes your sensations as stressful or emotional. Why does the predicting brain construct instances of stress or emotion in a given situation? No one knows. Maybe the longer your body budget is out of whack, the more likely you are to categorize with the concept “Stress,” but this is pure speculation. If your body budget is unbalanced for a long time, you may experience chronic stress. (Chronic misbudgeting is often diagnosed as stress, which is why people think stress causes illness.) Chronic stress is dangerous to your physical health. It literally eats away at your interoceptive and control networks, causing them to atrophy, as your chronically imbalanced body budget remodels the very brain circuitry that regulates the budget. So much for the classical division between mental and physical illness. Scientists are still figuring out the puzzle of immune system, stress, and emotion, but we do know a few things right now. Cumulative imbalance in the body budget-say, from growing up in adversity, where you don't feel safe or are deprived of basic necessities like nutritious food, quiet time to sleep, and so on-also changes the structure of your interoceptive network, rewiring your brain and reducing its ability to accurately regulate your body budget. All it takes are a couple of highly negative experiences for children to feel like they are living in a combat zone, reducing the size of their body- budgeting regions by the time they reach adulthood. Growing up in a family that is harsh or chaotic, with a lot of conflict or verbal criticism, increases inflammation in adolescent girls and places kids on a trajectory toward chronic disease; it's almost as bad for the development of these networks as childhood abuse or neglect. Ditto for suffering as the target of a bully. Kids who were bullied as children show low-grade inflammation that persists into adulthood, which predisposes them to a host of psychiatric and physical diseases. These are the myriad ways that an imbalanced body budget sculpts your brain, translating into a higher lifetime risk of heart disease, arthritis, diabetes, cancer, and other diseases. On the positive side, the link between emotion and stress suggests that you can reduce inflammation by applying techniques from the previous chapter. More emotionally intelligent people with cancer, for example, appear to have lower levels of proinflammatory cytokines. In studies, when patients said that they frequently categorize, label, and understand their emotions, they were less likely to have increased cytokines during recovery from prostate cancer, or after a stressful event, and the highest levels of circulating cytokines were found in men who expressed a lot of affect that they didn't label. Female breast cancer survivors who explicitly label and understand their emotions also have better health and fewer medical visits for cancer-related symptoms. This means that over time, people who effectively categorize their interoceptive sensations as emotion might be better protected against chronic inflammatory processes that lead to poor health. Pain, like stress and emotion, is a word that describes a population of diverse experiences-the ache of a twisted ankle, the steady pounding of a headache, the irritation of a mosquito bite, and, of course, the agony of pushing a thirty- five-centimeter head through a ten-centimeter cervix. You might think that when your body is harmed, information simply radiates from the afflicted area to your brain, leading you to swear loudly and reach for the ibuprofen and bandages. It's true that your nervous system sends sensory input to your brain when your muscles or joints are injured, or your body tissues are damaged by excessive heat or cold, or in response to a chemical irritation like a pinch of pepper in your eye. This process is called nociception. And in the past, scientists believed that your brain simply received and represented nociceptive sensations and, voilà, you experience pain. But the inner workings of pain are more complex in a predictive brain. Pain is an experience that occurs not only from physical damage but also when your brain predicts damage is imminent. If nociception works by prediction, as does every other sensory system in the brain, then you construct instances of pain out of more basic parts using your concept of “Pain.”16 The way I see it, pain is constructed in the same way that emotions are made. Suppose you're at your doctor's office receiving a tetanus shot. Your brain constructs an instance of “Pain” by issuing predictions about the needle piercing your skin, since you have prior experience with shots. You might feel the pain even before the needle touches your arm. Your predictions are then corrected by actual nociceptive input from the body-the injection occurs-and once any prediction errors are dealt with, you have categorized the nociception sensations and made them meaningful. The pain you experience as coming from the shot is really in your brain. My prediction-based explanation of pain is backed up by a couple of observations. When you are expecting pain, like the moment just before an injection, your brain regions that process nociception change their activity. That is, you simulate pain and therefore feel it. This phenomenon is called the nocebo effect. You're probably more familiar with its counterpart, the placebo effect, which relieves pain using a medically ineffective treatment like a sugar pill. If you believe you'll feel less pain, your beliefs influence your predictions and tune down your nociceptive input so you do feel less pain. Both placebos and nocebos involve chemical changes in the brain regions that process nociception. These chemicals include opioids that relieve pain and work similarly to morphine, codeine, heroin, and other opiate drugs. Opioids increase during placebo and turn down nociception, and likewise decrease during nocebo effects, earning them the moniker of “your internal medicine cabinet.”18 I watched my daughter experience the nocebo effect when she was a baby and had thirteen ear infections in nine months. The first time we visited the pediatrician's office for treatment, she wailed in discomfort as he peered into her ears (though he is a caring and careful physician). The second time, she cried in the waiting room. The third time, she began sobbing in the building lobby, and the fourth time, as we entered the parking garage. After that, she would whimper anytime we passed the street where the doctor's office was located. This is the predicting brain in action; little Sophia was likely simulating ear pain. It took many months, after Sophia was past the infections and well into toddlerhood, for her to stop asking, “Go to dottor? Kekk Sophie's ears?” whenever we were in the vicinity. Pain, like emotion and stress, appears to be a whole-brain construction. It involves our familiar pair of networks, the interoceptive and control networks. And the similarities don't stop here. The pathways sending nociceptive predictions down to the body, and those bringing nociceptive input up to the brain, are closely related to interoception. (It's even possible that nociception is a form of interoception.) Overall, the body sensations that are categorized as pain, stress, and emotions are fundamentally the same, even at the level of neurons in the brain and spinal cord.* Distinguishing between pain, stress, and emotion is a form of emotional granularity. It's easy to show that interoception and nociception are in bed with each other. If I made you feel unpleasant affect in my lab while applying painful heat to your arm, you'd report feeling more pain. This happens because your body-budgeting regions issue predictions that can dial pain up and down like a volume control. Those predictions can influence your brain's simulation of pain, and they also reach down to your body and can amplify or dampen its status reports to your brain. Your body-budgeting regions can therefore trick your brain into believing that there is tissue damage, regardless of what is happening in your body. So, when you're feeling unpleasant, your joints and muscles might hurt more, or you could develop a stomachache. When your body budget's not in shape, meaning your interoceptive predictions are miscalibrated, your back might hurt more, or your headache might pound harder-not because you have tissue damage but because your nerves are talking back and forth. This is not imaginary pain. It is real. When people experience ongoing pain without any damage to their body tissue, it's called chronic pain. A few well-known examples are fibromyalgia, migraine headaches, and chronic back pain. Over 1. billion people suffer from chronic pain, including 100 million in the United States who collectively pay $500 billion per year for treatment. When you include lost productivity in the price tag, pain costs the United States $635 billion each year. It is also frustratingly hard to treat, as the currently prescribed pain medications, analgesics, are ineffective more than half the time. This worldwide epidemic of chronic pain is one of today's great medical mysteries. How and why do so many people experience ongoing pain when their bodies appear to have no physical damage? To answer that question, think about what would happen if your brain issued unnecessary predictions of pain and then ignored prediction error to the contrary. You would genuinely experience pain for no discernable reason. This is much like your experience when the blobby picture in chapter 2 became a bee, as you genuinely perceived lines that didn't exist. Your brain ignored sensory input, maintaining that its predictions are reality. Apply this example to pain and the result is a plausible model of chronic pain: errant predictions without correction. Scientists now consider chronic pain to be a brain disease with its roots in inflammation. It's possible that the brain of a chronic pain sufferer received intense nociceptive input sometime in the past, and as the injury healed, the brain didn't get the memo. It keeps predicting and categorizing anyway, generating chronic pain. It's also possible that predictions about inner-body movements are turning up the volume for nociceptive input as it heads from the body to the brain. If you're unlucky enough to suffer from chronic pain, then you've probably faced skeptics who don't understand what you're going through. They try to explain away your pain by saying, “It's in your head,” by which they mean, “You have no tissue damage, so go see a psychiatrist.” I'm saying that you're not crazy. There is something wrong with you. Your predictive brain, which is indeed located “in your head,” is generating authentic pain that continues past the point when your body has already healed. It's similar to phantom limb syndrome, when an amputee can still feel his missing arm or leg because his brain keeps issuing predictions about it. We already have intriguing evidence that some types of chronic pain work by prediction. Animals who have stress or injury early in life become more likely to develop persistent pain. Human infants who have surgery are more likely to have heightened pain in later childhood. (Incredibly, infants prior to the 1980s were routinely not anesthetized during major surgery, on the belief that they couldn't feel pain!) There's also a medical condition called complex regional pain syndrome, in which pain from an injury spreads inexplicably to other areas of the body, which appears to be linked to bad nociceptive predictions. So “Pain,” like “Stress,” is another concept with which you make meaning of physical sensations. You could characterize pain and stress as emotions, or even emotion and stress as types of pain. I'm not saying that instances of emotion and pain are indistinguishable in the brain, but neither has a fingerprint. If I scan your brain while you're having a toothache and when you're angry, the scans will look somewhat different. But then, if I scan your brain during different instances of anger, they look somewhat different too. Different instances of dental pain likely vary as well. This is degeneracy; variation is the norm. Emotion, acute pain, chronic pain, and stress are constructed in the same networks, the same neural pathways to and from the body, and most likely the same primary sensory region of cortex, so it is completely plausible that we distinguish emotion and pain by concept-that is, via the concepts the brain applies to make sense of bodily sensations. Chronic pain is likely a misapplication of the concept “Pain” by your brain, as it constructs the experience of pain without injury or threat to your tissue. Chronic pain seems to be a tragic case of predicting poorly and receiving misleading data from your body. Keeping in mind what you've just learned about chronic stress and chronic pain, let's turn our attention to depression, which is another debilitating condition that can overwhelm a life. Also known as major depressive disorder, depression is far beyond the everyday distress that people feel when they groan, “I'm like sooo depressed.” Marvin the Paranoid Android, in Douglas Adams's The Hitchhiker's Guide to the Galaxy, was truly depressed. Sometimes he was so despondent about life that he shut himself down. A major depressive episode is similarly incapacitating. “The pain of severe depression is quite unimaginable to those who have not suffered it,” recalled the novelist William Styron in his memoir, “and it kills in many instances because its anguish can no longer be borne.”27 To many scientists and physicians, depression remains a disease of the mind. It's classified as a disorder of affect and often blamed on negative thinking: You're too hard on yourself, or have too many self-defeating, catastrophic thoughts. Or perhaps traumatic events trigger depression, particularly if your genes make you vulnerable. Or maybe you don't regulate your emotions well, making you too responsive to negative events and too unresponsive to positive ones. All of these explanations assume that thinking controls feeling-the old “triune brain” idea. Change your thoughts or regulate your emotions better, the logic goes, and depression will lift. The mantra seems to be: “Don't worry, be happy; and if that doesn't work, try antidepressants.”28 Twenty-seven million Americans take daily antidepressants, yet more than 70 percent continue to experience symptoms anyway, and psychotherapy is not effective for everyone either. Often the symptoms begin in adolescence to early adulthood and then recur throughout life. The World Health Organization projects that by 2030, depression will cause more premature deaths and years of disability than cancer, stroke, heart disease, war, or accidents. Those are pretty dreadful outcomes for a “mental” illness. A lot of research seeks to find the universal genetic or neural essence of depression. But most likely, depression is not just one thing. Depression is- you guessed it-a concept. It is a population of diverse instances, so there are many degenerate paths to depression, many of which begin with an imbalanced body budget. If depression is a disorder of affect, and affect is an integrated summary of how your body budget is doing (answer: pretty poorly), then depression may actually be a disorder of misbudgeting and prediction. We know that your brain continually predicts your body's energy needs based on past experience. Under normal circumstances, your brain also corrects its predictions based on actual sensory information from your body. But what if this correction wasn't working properly? Your momentary experience would be constructed from the past but not corrected by the present. In general terms, that's what I think is happening in depression. Your brain is continually mispredicting your metabolic needs. Your body and brain therefore act as if you were fighting off an infection or healing from a wound when none exists, as in chronic stress or pain. As a result, your affect is out of whack: you experience debilitating misery, fatigue, or other symptoms of depression. Simultaneously, your body is quickly metabolizing unnecessary glucose to meet those high yet nonexistent energy needs, leading to weight problems and leaving you at risk for other metabolic-related illnesses that co- occur with depression, including diabetes, heart disease, and cancer. The traditional view of depression is that negative thoughts cause negative feelings. I'm suggesting it's the other way around. Your feelings right now drive your next thought, as well as your perceptions, as predictions. So a depressed brain relentlessly keeps making withdrawals from the budget, basing its predictions on similar withdrawals from the past. This means constantly reliving difficult, unpleasant events. You wind up in a cycle of budgeting imbalances, unbroken by prediction error because it is ignored, gets tuned down, or doesn't make it to the brain. In effect, you're locked into a cycle of uncorrected predictions, trapped in an adverse past when your metabolic needs were high. A depressed brain is effectively locked into misery. It's like a brain in chronic pain, ignoring prediction error, but on a much larger scale that shuts you down. It puts your budget chronically in debt, so your brain tries to cut spending. What's the most efficient way to do that? Stop moving and don't pay attention to the world (prediction error). That is the unrelenting fatigue of depression. If depression is a disorder caused by chronic misbudgeting, then it's not, strictly speaking, exclusively a psychiatric disease. It's also a neurological, metabolic, and immunologic disease. Depression is an imbalance of many entwined parts of the nervous system that we can understand only by treating the whole person, not by treating one system in isolation like the parts of a machine. The tipping point into a major depressive episode can come from many different sources. You could suffer prolonged stress or abuse, particularly in childhood, leaving you carrying around a model of the world built from toxic past experiences. You could have physical conditions like chronic heart disease or insomnia that lead to bad interoceptive predictions. Your genes could leave you sensitive to your environment and every little problem. Also, if you're a woman of reproductive age, the connectivity within your interoceptive network changes throughout the month, leaving you more vulnerable, at certain points in your cycle, to unpleasant affect, rumination, and perhaps even increased risk of mood disorders such as depression and post-traumatic stress disorder. “Thinking positive thoughts” or taking antidepressants might not be enough to bring your body budget back into balance: other lifestyle changes or system adjustments might be necessary. The theory of constructed emotion suggests that we can treat depression by breaking the cycle of misbudgeting, that is, by changing interoceptive predictions to be more in line with what's going on around you. Scientists have found evidence that this is the case. As treatments like antidepressants and cognitive behavioral therapy start to work and you feel less depressed, your activity in a key body-budgeting region returns to normal levels, and connectivity in your interoceptive network is restored. These changes are consistent with the idea of reducing the excessive predictions. We might also treat depression by letting in more prediction error, say, by asking people to keep a diary of their positive experiences, which can ease the drain on the body budget. The problem, of course, is that no treatment works for everyone, and there are some people for whom no treatments work. One of the most promising avenues for treatment I've seen is the groundbreaking work of neurologist Helen S. Mayberg (chapter 4), who electrically stimulates the brains of unrelentingly depressed patients. Her technique instantly relieves the agony of depression, if only while the current is on, as the patient's brain shifts from all-consuming internal focus to the external world, so it can predict and process prediction error normally. Let's hope that these preliminary yet encouraging results will ultimately lead scientists to a more lasting treatment for depression. At the very least, these results should help spread the word that depression is a brain disease and not just a shortage of happy thoughts. Anxiety is a condition that seems very different from chronic pain and depression. When you're anxious, you feel worried or worked up, like you don't know what to do with yourself, and generally miserable. This is a stark contrast with depression, in which you feel sluggish, like you can't go on with life, and also generally miserable, and with chronic pain, which is, well, painful. So far, we've learned that emotion, chronic pain, chronic stress, and depression all involve the interoceptive and control networks. Those same networks are critical to anxiety as well. Anxiety is still a puzzle being unraveled,* but one thing seems certain: it is yet another disorder of prediction and prediction error across these two networks. The neural pathways studied in anxiety for prediction and prediction error are also the same ones as for emotion, pain, stress, and depression. Traditional research on anxiety disorders is founded on the old “triune brain” model, that cognition controls emotion. Your allegedly emotional amygdala is overactive, they say, and your so-called rational prefrontal cortex is failing to regulate it. This approach is still influential, even though the amygdala is not the home of any emotion, the prefrontal cortex does not house cognition, and emotion and cognition are whole-brain constructions that cannot regulate each other. So, how is anxiety made? We don't know all the details yet, but we have some tantalizing clues. I speculate that an anxious brain, in a sense, is the opposite of a depressed brain. In depression, prediction is dialed way up and prediction error way down, so you're locked into the past. In anxiety, the metaphorical dial is stuck on allowing too much prediction error from the world, and too many predictions are unsuccessful. With insufficient prediction, you don't know what's coming around the next corner, and life contains a lot of corners. That's classic anxiety. Anxiety sufferers, for whatever reason, have weakened connections between several key hubs in the interoceptive network, including the amygdala. Some of these hubs also happen to sit in the control network. These weakened connections likely translate into an anxious brain that is clumsy at crafting predictions to match the immediate circumstances, and that fails to learn effectively from experience. You might predict threats needlessly, or create uncertainty by predicting imprecisely or not at all. In addition, your interoceptive inputs become even more noisy than usual when your body budget has been in the red for a while; as a consequence, your brain ignores them. These situations leave you open to a lot of uncertainty and a lot of prediction error that you can't resolve. And uncertainty is more unpleasant and arousing than assured harm, because if the future is a mystery, you can't prepare for it. For example, when people are seriously ill but have an excellent chance of recovery, they are less satisfied with life than people who know their disease is permanent. Based on the evidence, it appears that anxiety, like depression, is a constructed category in the same fashion as emotion, pain, and stress. The misery you feel in anxiety and depression tells you that something is seriously wrong with your body budget. Either your brain is trying to secure a deposit, ramping up unpleasant affect, or it's attempting to reduce your need for the deposit by remaining still, resulting in fatigue. Your brain may categorize these sensations as anxiety, depression, or, for that matter, pain or stress or emotion. To be clear, I am not saying that major depressive disorder and anxiety disorders are interchangeable. I'm suggesting that every category of mental illness is a diverse population of instances, and certain collections of symptoms could reasonably be categorized equally well as an anxiety disorder or as depression. There's also the issue of severity-some of Helen Mayberg's severely depressed patients, such as those who are near-catatonic, would clearly not be diagnosed with an anxiety disorder. However, some of her other patients who are in agony might reasonably be diagnosed with anxiety, chronic stress, or even chronic pain. In general, moderately severe depression and anxiety can have overlapping symptom profiles with one another, and with chronic stress and chronic pain, and also with chronic fatigue syndrome. These observations provide a solution to the mystery that opened chapter 1: why did test subjects in my graduate school experiments seem unable to distinguish between anxious and depressed feelings? One reason we've covered already is emotional granularity: some of my subjects could probably construct more finely tailored emotions than others could. But now a second reason comes to light: that “Anxiety” and “Depression” are concepts for categorizing similar sensations. When my subjects were feeling unpleasant, I handed them rating scales to report their feeling, but only in terms of anxiety and depression. People will use whatever measure you give them to describe how they feel. If someone feels crappy and you give her only an anxiety scale, she'll report her feelings using words for anxiety. She might even come to feel anxious as the words prime her to simulate an instance of “Anxiety.” Alternatively if you hand her a depression scale, she'll report her feeling using words for depression and might likewise end up feeling depressed. This would explain my mysterious results. Concepts like “Anxiety” and “Depression” are highly variable and malleable. Words on questionnaires can influence people's categorizations, just like the basic emotion method influences perceptions with its list of emotion words. I encountered something similar in a physician's office not long ago. I'd been feeling fatigued for some time and had gained some weight, and the doctor asked, “Are you depressed?” I responded, “Well, I don't have sad feelings, but I do feel dead tired much of the time.” He countered with, “Maybe you're depressed and you don't know it.” My doctor did not realize that unpleasant affect can have a physical cause, which in my case was probably lack of sleep from running a lab of a hundred people, staying up late working on this book, and being a mother to my teenage daughter, plus a little thing called menopause. (I wound up explaining interoception and body budgets to him.) But here's the thing: If he had simply diagnosed me with depression, he could have actually cultivated a feeling of depression in me in that instant. Sure, I was fatigued, and I probably had some inflammation going on due to a bit of chronic stress. If I hadn't resisted, I could have come away with a prescription for antidepressants and a belief that something was seriously wrong with my life or myself for being unable to cope. This belief might have worsened my miscalibrated body budget, if I started to search for problems in my life . . and you can always find something if you look. Instead, my doctor and I uncovered a body-budgeting issue and looked for ways to repair it. My doctor didn't realize it, but he was co-constructing my experience. He wanted to construct one social reality, and I had another. When prediction error from the world dominates prediction, you can have anxiety. Suppose you couldn't predict at all, ever. What would happen? For starters, your body budget would be screwed up because you couldn't predict your metabolic needs. You'd have difficulty integrating sensory input from vision, hearing, smell, interoception, nociception, and your other sensory systems into a cohesive whole. You'd therefore have impaired statistical learning, making it difficult for you to learn basic concepts, even to recognize the same person from different angles. Many things would be outside your affective niche. If you were an infant in that situation, you'd most likely be disinterested in other humans; you'd stop looking at the faces of your caregivers, making it harder for them to regulate your highly disrupted body budget, breaking a crucial bond. You would also have trouble learning purely mental concepts of social reality because they're learned with words, but you're disinterested in humans so you probably have difficulty learning language. You'd never grow a proper conceptual system. In the end, you'd exist in a constant stream of ambiguous sensory input with few concepts to help you make sense of it. You'd be anxious all the time because sensations are unpredictable. In effect, you'd have a total breakdown of interoception, concepts, and social reality. In order to learn at all, you'd need your sensory input to be very consistent, even stereotyped, with as little variation as possible. I don't know about you, but to me, this collection of symptoms sounds just like autism. Clearly, autism is an incredibly complex condition and a gigantic area of research, and it can't be summed up in a handful of paragraphs. Autism is also hugely variable, a term applied to a wide spectrum of symptoms that probably have multiple, complex causes. All I'm saying is: the possibility is intriguing that autism is a disorder of prediction. People with autism who can describe their experiences say things consistent with the idea. Temple Grandin, one of the most famous and outspoken individuals with autism, writes clearly about her lack of prediction and her overwhelming prediction error. “Sudden loud noises hurt my ears like a dentist's drill hitting a nerve,” she writes in “An Inside View of Autism.” Grandin eloquently describes how she struggled to form concepts: “When I was a child, I categorized dogs from cats by sorting the animals by size. All the dogs in our neighborhood were large until our neighbors got a Dachshund. I remember looking at the small dog and trying to figure out why she was not a cat.” Naoki Higashida, a thirteen-year-old boy with autism who wrote The Reason I Jump, notes his efforts to categorize: “First, I scan my memory to find an experience closest to what's happening now. When I've found a good close match, my next step is to try to recall what I said the last time. If I'm lucky, I hit upon a usable experience and all is well.” In other words, lacking a properly functioning conceptual system, Higashida has to work hard to do what other brains do automatically. Other researchers too are now speculating that autism is a failure of prediction. Some believe that autism is primarily caused by a dysfunction of the control network, producing a model of the world that is too specific to each situation. Others see the problem as a deficit in the neurochemical called oxytocin, leading to problems in the interoceptive network. I suspect that there isn't just one network problem in autism but a menu of different possibilities, owing to degeneracy. In fact, autism is characterized as a neurodevelopmental disorder that is extremely variable in its genetics, neurobiology, and symptoms. I speculate that the problems begin with body- budgeting circuitry because it's present at birth, and all statistical learning is grounded in body-budget regulation (chapters 4 and 5). Alterations in the circuitry will change the trajectory of brain development. Without a fully loaded predictive brain, you'd be at the mercy of your environment. You'd have a brain driven by stimulus and response, when the nervous system is optimized for a more metabolically efficient brain organization. That might explain the experiences of people with autism. You've now seen that several notable and serious disorders may all be related to your immune system, which links your mental and physical health within your predicting brain. When bad predictions go unchecked, they may lead to a chronically unbalanced body budget, which contributes to inflammation in the brain and corrupts your interoceptive predictions even further in a vicious cycle. In this manner, the same systems that construct emotion also can contribute to illness. I'm not saying that body-budget debt is the single cause of all mental illness. Nor am I suggesting that rebalancing the budget is the golden cure. I'm just saying that, thanks to our new view of human nature, we can understand that a body budget is a common factor in diseases that are traditionally considered separable. When you have too much prediction and not enough correction, you feel bad, and the flavor of badness depends on the concepts you use. In small amounts, you might feel angry or shameful. In extreme amounts, you get chronic pain or depression. In contrast, too much sensory input and ineffective prediction yields anxiety, and in extreme amounts, you might develop an anxiety disorder. With no prediction at all, you'd have a condition comparable to autism. All of these disorders appear to be rooted in misbudgeting. Now imagine with me, for a moment, the myriad ways that a young person can develop a budget that's chronically in overdraft. There's overt abuse and neglect, of course, but also an avalanche of smaller events. The steady stream of violence they witness on TV and in movies, videos, and computer games. The degrading language they hear in popular music and casually mimic as they greet peers with “Hey, bitch.” (Is it a friendly hello, an insult, or a threat?) The rise of bullying as a form of joking because on television, people say horrible things to each other to the sound of a laugh track. Add to this the almost limitless opportunities for social rejection that texting and some forms of social media provide, combined with not enough sleep and exercise, plus too much pseudo-food of dubious nutritional quality, and you have a cultural recipe for a generation of adults with chronic body misbudgeting. Could the misery of chronic misbudgeting be one reason why the United States is in the midst of an opiate crisis? Your brain's natural opioids reduce pain because they regulate affect (not nociception), and opiate drugs mimic these effects-which might explain their widespread abuse. From 1997 to 2011, the number of U.S. adults who are addicted to prescription drugs increased by 900 percent. Many others have resorted to heroin, methamphetamines, and other street drugs that reduce distress. We also know that a significant portion of the population isn't sleeping enough, eating well, or exercising regularly. With opiate drugs, people are probably self- medicating the discomfort that stems from a chronically imbalanced body budget. They begin taking opiates for a variety of reasons, but they keep using and even abusing, I suspect, because they are regulating their out-of-whack affect to feel better. Their body budgets are too messed up for their brain's natural opioids to do their job. The wretchedness of chronic misbudgeting can also be temporarily reduced with food, which stimulates some of the same brain receptors that respond to opiate drugs. In experiments on rats, this stimulation leads the rats to binge on high-carbohydrate foods, even when they are not hungry. In people, eating sugar triggers the brain's opioids to increase production. So eating junk food or white bread actually feels good. No wonder I love a crusty French loaf. And sugar may actually act as a mild analgesic. So, when people talk about our society being addicted to sugar, they might not be far off. I wouldn't be surprised if people are employing high-carbohydrate food as a drug to manage their affect and feel better. Hello, obesity epidemic. A population of citizens with imbalanced body budgets doesn't just cost billions of dollars in health care. It costs people their well-being, their relationships, and even their lives. People who study these illnesses are beginning to set aside the essentialism that creates categories like “Anxiety” and “Depression” and “Chronic Pain,” and looking to common underlying factors instead. If we could add interoception, body-budget balancing, and emotion concepts to the list of those common factors, I suspect we'd make more progress against these debilitating disorders. In the meantime, your own knowledge of these common factors may help you avoid illness and communicate more effectively with your doctors. We all walk a tightrope between the world and the mind, and between the natural and the social. Many phenomena that were once considered purely mental-depression, anxiety, stress, and chronic pain-can, in fact, be explained in biological terms. Other phenomena that were believed to be purely physical, like pain, are also mental concepts. To be an effective architect of your experience, you need to distinguish physical reality from social reality, and never mistake one for the other, while still understanding that the two are irrevocably entwined."
  },
  {
    "index": 16,
    "level": 1,
    "start_page": 214,
    "end_page": 244,
    "title": "Emotion and the Law",
    "content": "Emotion and the Law. Every society has rules for which emotions are acceptable, when they are acceptable, and how to express them. In my American culture, it's appropriate to feel grief when someone dies, and inappropriate to chuckle as the casket is lowered into the ground. A surprise party is a time to feel surprised and then joyful, and if you know about your own party in advance, it's appropriate to feign surprise when you arrive. Members of the Ilongot tribe in the Philippines may feel the emotion liget when acting as a team to behead an enemy, in celebration of a job well done. If you violate your culture's rules of social reality, punishment may follow. Laughter at a funeral may get you shunned. Failure to be surprised at your own party may yield disappointed guests. And most cultures no longer prize decapitation. The ultimate rules for emotion in any society are set by its legal system.* That might seem like a surprising claim, but consider this. In the United States, if your accountant steals your life savings, or a banker sells you a bad mortgage, it's considered unacceptable to kill them; but if you murder your spouse in a fit of rage for cheating on you with a secret lover, the law might cut you some slack, especially if you're a man. It's unacceptable to make your neighbor feel fear that you will harm him bodily-that is considered a form of assault-but in some states it's okay for you to “stand your ground” and harm someone first, even if you kill the person. It's acceptable for you to profess romantic love, but not (at various times in U.S. history) toward people whose sex is the same as yours or whose skin color isn't. Violate these norms, and you might lose your money, your freedom, or your life. For centuries, laws in the United States have been shaped by the classical view of emotion, steeped in the essentialist view of human nature. Judges, for example, attempt to set emotion aside to render a decision by pure reason, a belief that assumes emotion and reason are distinct entities. Violent defendants plead that they were hijacked by their anger, assuming that anger is one single, unitary cauldron that, when unconstrained by clear thought, bubbles over to unleash a torrent of aggression. Juries look for remorse in a defendant, as if remorse had a single, detectable expression in the face and body. Expert witnesses testify that a defendant's bad behavior was caused by one errant brain blob, an example of baseless blob-ology. The law is a social contract that exists in a social world. Are you responsible for your actions? Yes, says the essentialist view of human nature, as long as you haven't been commandeered by your emotions. Are other people responsible for your actions? No, you are an individual with free will. How do you determine what a defendant is feeling? By detecting his or her emotions in expressions. How do you make a just, moral decision? By setting your emotions aside. What is the nature of harm? Physical harm, that is, tissue damage, is worse than emotional harm, which is considered to be separate from the body and less tangible. All of these assumptions-born of essentialism-are baked into the law at its deepest levels, driving verdicts of guilt and innocence and gauging punishments on a massive scale, even as neuroscience has been quietly debunking them as myths. Simply put, some people are punished undeservedly, and others escape punishment, based on an outdated theory of the mind that is rooted in belief rather than science. In this chapter, we'll explore some common myths about emotion in the legal system and ask whether a biologically richer theory of the mind, especially one that is grounded in realistic neuroscience, can improve society's pursuit of justice. As every budding adolescent discovers, freedom is great. You can decide to stay out past midnight with your friends. You can decide not to do your homework. You can choose to eat cake for dinner. But as we all learn, choices come with consequences. The law is founded on the simple idea that you can choose to treat others well or badly. Choice bestows responsibility. If you treat others badly and consequently they suffer some harm, then you must be punished, particularly if you intended that harm. This is how society shows its respect for you as an individual. Your value as a human being, some legal scholars say, is rooted in the fact that you choose your actions and are responsible for them. If something interferes with your ability to choose your actions freely, the law says that you might be less responsible for the harm you caused. Take the case of Gordon Patterson, who caught his wife, Roberta, “in a state of semiundress” with her boyfriend, John Northrup. Patterson shot Northrup twice in the head, killing him. Patterson confessed to the shooting but argued that he was less culpable due to his “extreme emotional disturbance” at the time of the crime. According to U.S. law, Patterson's sudden burst of rage caused him not to be fully in control of his actions, and he was therefore found guilty of second-degree murder-rather than first-degree murder, which requires premeditation and carries a harsher punishment. In other words, rational killing is considered worse than emotional killing, all other circumstances being equal. The U.S. legal system assumes that emotions are part of our supposed animal nature and cause us to perform foolish and even violent acts, unless we control them with our rational thoughts. Centuries ago, legal minds decided that people, when provoked, sometimes kill because they haven't “cooled off” yet, and anger erupts unbidden. Anger steams, boils, explodes, and leaves a wake of destruction in its path. Anger makes people unable to conform their actions to the law, and so partially mitigates a person's responsibility for his actions. The argument is known as a heat-of-passion defense. The heat-of-passion defense depends on some familiar assumptions from the classical view of emotion. The first assumption is that there is one universal type of anger, with a specific fingerprint, that justifies such a defense to a charge of murder. It supposedly includes a flushed face, clenched jaw, flared nostrils, and increased heart rate, blood pressure, and perspiration. As you've already learned, this alleged fingerprint is merely a Western cultural stereotype that's not supported by data. On average, people's heart rates go up when angry, but there's tremendous variation, and similar increases are also part of the stereotypes for happiness, sadness, and fear. And yet, most killings are not committed in happiness or sadness; and if they were, the law does not consider these emotional episodes to be a mitigating factor. What's more, most instances of anger do not lead to killing. I can state quite definitively that in twenty years of creating anger in my lab, we've never seen a test subject kill anybody. We see a far greater repertoire of action: swearing, threatening, pounding the table, leaving the room, crying, trying to resolve whatever conflict they're having, or even smiling while wishing ill upon their oppressor. So the idea of anger as a trigger for uncontrolled murder is at best questionable. When I explain to people in the legal profession that anger has no biological fingerprint, they often assume I am claiming emotions don't exist. That's not at all the case. Of course anger exists. You just can't point to a spot in a defendant's brain, face, or EKG, and say, “Look, anger is right here,” let alone draw legal conclusions. The legal system's second assumption behind the heat-of-passion defense is that “cognitive control” in the brain is synonymous with rational thought, deliberate actions, and free will. For you to be considered culpable, it is not enough that you performed a harmful action (known by the legal term actus reus). You also had to mean it. You caused harm of your own free will with a guilty mind (mens rea). Emotions, on the other hand, are seen as rapid, automatically triggered reactions spewing from your ancient, inner beast. The human mind is considered a battleground for reason and emotion, so when you fail to exercise sufficient cognitive discipline, emotions are said to burst forth to hijack your behavior. They interfere with your choice of action, and therefore make you less culpable. This narrative of emotion as the primitive part of human nature, to be controlled by the more advanced and uniquely human rational parts, is the “triune brain” myth (chapter 4) whose roots go all the way back to Plato. The distinction between emotion and cognition hinges on their alleged separation in the brain, with one regulating the other. Your emotional amygdala spies an open cash register, but then, as the story goes, you rationally consider your likelihood of jail time, which causes your prefrontal cortex to slam on the brakes and stop your arm from dipping into the drawer. But as you've learned by now, thinking and feeling are not distinct in the brain. Your desire for easy cash and your decision to pass it up are both constructed across your entire brain by interacting networks. Whenever you carry out an action-whether it feels automatic, like recognizing an object as a gun, or more deliberate, like aiming one-your brain is always a whirlwind of parallel predictions that compete with one another to determine your actions and your experience. At different times, you have different experiences of agency. Emotion sometimes can feel uncontrollable, like a burst of anger that arrives without warning, but you can also act in anger with intent, methodically plotting someone's demise. In addition, non-emotions like memories or ideas can pop into your head unbidden. And yet we never hear of defendants who commit murder “in a fit of thinking.” You can even work yourself up deliberately into a frothing anger. Accused mass murderer Dylann Roof, who shot nine people in a Bible study meeting in South Carolina in June 2015, appeared to cultivate his anger toward African Americans deliberately for many months before the day he walked into that church. Roof said that he almost didn't go through with his plan because everyone was so nice to him, and he appeared to work himself up to the heinous deed in the meeting, uttering repeated phrases like “I have to do it” and “You have to go.” So, overall, moments of emotion are not synonymous with moments that you're out of control. Anger is a population of diverse instances, not a single automatic reaction in the true sense of the phrase. The same holds for every other category of emotion, cognition, perception, and other type of mental event. It might seem like your brain has a quick, intuitive process and a slower, deliberative one, and that the former is more emotional and the latter more rational, but this idea is not defensible on neuroscience or behavioral grounds. Sometimes your control network plays a large role in the construction process, and other times its role is less, but it is always involved, and the latter times are not necessarily emotional. Why does the fiction of the two-system brain survive, beyond the usual reason of essentialism? Because most psychology experiments unwittingly perpetuate this fiction. In real life, your brain predicts nonstop, with each brain state dependent on those that came before. Laboratory experiments break this dependency. Test subjects view images or listen to sounds presented in random order, responding after each one, say, by pressing a button. Such experiments disrupt the brain's natural process of prediction. And the results come out looking like the subject's brain makes a rapid, automatic response, followed by a controlled choice about 150 milliseconds later, as if the two responses came from distinct systems in the brain. The illusion of a two-system brain is a byproduct of a century-old, flawed experimental design, and our laws maintain the illusion.* The legal system, with its essentialized view of the mind and brain, mixes up volition-whether your brain actually played a role in controlling your behavior-and awareness of volition-whether you experience having a choice. Neuroscience has quite a bit to say about this distinction. If you sit in a chair with your legs bent, toes not touching the floor, and tap your knee just below your kneecap, the bottom half of your leg gives a little kick. Hold your hand to a flame and your arm recoils. Present a puff of air to your cornea and you blink. Each of these examples is a reflex: sensation leading directly to motion. Reflexes in your peripheral nervous system have sensory neurons wired directly to motor neurons. We call the resulting actions “involuntary” because there is one, and only one, specific behavior for a specific sensory stimulation due to the direct wiring. Your brain, however, is not wired like a reflex. If it were, you'd be at the mercy of the world, like a sea anemone that reflexively stabs whatever fish happens to brush against its tentacles. The anemone's sensory neurons, which receive input from the world, are directly connected to its motor neurons for movement. It has no volition. A human brain's sensory and motor neurons, however, communicate through intermediaries, called association neurons, and they endow your nervous system with a remarkable ability: decision-making. When an association neuron receives a signal from a sensory neuron, it has not one possible action but two. It can stimulate or inhibit a motor neuron. Therefore, the same sensory input can yield different outcomes on different occasions. This is the biological basis of choice, that most prized of human possessions. Thanks to association neurons, if a fish brushes against your skin, you can react with indifference, laughter, violence, or anything in between. You might feel like a sea anemone at times, but you have much more control over your harpoon than you might think. Your brain's control network, which helps select your actions, is composed of association neurons. This network is always engaged, actively selecting your actions; you just don't always feel in control. In other words, your experience of being in control is just that-an experience. Here's where the law is out of sync with science, thanks to the classical view of human nature. The law defines deliberate choice-free will-as whether you feel in control of your thoughts and actions. It fails to distinguish between your ability to choose-the workings of your control network-and your subjective experience of choice. The two are not the same in the brain. Scientists are still trying to figure out how the brain creates the experience of having control. But one thing is certain: there is no scientific justification for labeling a “moment without awareness of control” as emotion. What does all this mean for the law? Remember that the legal system decides guilt or innocence based on intent-whether someone meant to commit harm. The law should continue to punish based on how intentional harm is, not on whether emotion is involved or whether a person experiences himself as an agent with volition. Emotions are not temporary deviations from rationality. They are not alien forces that invade you without your consent. They are not tsunamis that leave destruction in their wake. They are not even your reactions to the world. They are your constructions of the world. Instances of emotion are no more out of control than thoughts or perceptions or beliefs or memories. The fact is, you construct many perceptions and experiences and you perform many actions, some that you control a lot and some that you don't. The legal system has a standard called the reasonable person who represents the norms of society, that is, the social reality within your culture. Defendants are measured against this standard. Consider the legal argument at the heart of the heat-of-passion defense: would a reasonable person have committed the same killing if he'd been similarly provoked without a chance to cool off ? The standard of the reasonable person, and the social norms behind it, is not merely reflected in the law-it is created by the law. It is a way of saying, “Here is what we expect a human person to act like, and we will punish you if you don't conform.” It's a social contract, a guide to behavior for the average person in a population of diverse individuals. And like all averages, the reasonable person is a fiction that doesn't apply exactly to any single individual. It's a stereotype, and it encompasses stereotyped ideas about emotional “expression,” feeling, and perception that are part of the classical view of emotion and the theory of human nature that supports it. A legal standard based on emotion stereotypes is especially problematic for the equitable treatment of men and women. The prevailing belief in many cultures is that women are more emotional and empathic, whereas men are more stoic and analytical. Shelves full of popular books portray this stereotype as fact: The Female Brain; The Male Brain; His Brain, Her Brain; The Essential Difference; Brain Sex; Unleash the Power of the Female Brain; and on and on. This stereotype affects even powerful women who are widely respected. Madeline Albright, the first female U.S. secretary of state, wrote in her memoir that “many of my colleagues made me feel that I was overly emotional, and I worked hard to get over that. In time, I learned to keep my voice flat and unemotional when I talked about issues that I considered important.”16 Take a moment and reflect on your own emotions. Do you tend to feel things intensely or more moderately? When we ask these types of questions in my lab to male and female test subjects-to describe their feelings from memory-the women report feeling more emotion than the men do on average. That is, the women believe they are more emotional than men, and the men agree. The one exception is anger, as subjects believe that men are angrier. However, when the same people record their emotional experiences as they occur in everyday life, there are no sex differences. Some men and women are very emotional, and some are not. Likewise, the female brain is not hardwired for emotion or empathy, and the male brain is not hardwired for stoicism or rationality. Where do these gender stereotypes come from? In the United States at least, women routinely “express” more emotion when compared to men. For example, women move their facial muscles more when watching films than men do, but women don't report more intense experiences of emotion while watching. This finding, if nothing else, might explain why the stereotypes of the stoic man and the emotional woman leak into the courtroom and have a significant influence on judges and juries. Because of these stereotypes, heat-of-passion defenses-and legal proceedings in general-are often applied differently to male versus female defendants. Consider two murder cases that are pretty similar except for the sex of the defendant. In the first case, a man named Robert Elliott was convicted of killing his brother, allegedly because of “extreme emotional disturbance” that included “an overwhelming fear of his brother.” The jury found him guilty of murder but the decision was overturned by the Supreme Court of Connecticut, citing that Elliott's “intense feelings” about his brother overwhelmed his “self-control” and “reason.” In the second case, a woman named Judy Norman killed her husband after he had systematically beaten and abused her for years. The Supreme Court of North Carolina rejected the defense's claim that Norman was acting in self-defense out of “a reasonable fear of imminent death or great bodily harm,” and she remained convicted of voluntary manslaughter. These two cases match several stereotypes about emotion in men versus women. Anger is stereotypically normal for men because they are supposed to be aggressors. Women are supposed to be victims, and good victims shouldn't become angry; they're supposed to be afraid. Women are punished for expressing anger-they lose respect, pay, and perhaps even their jobs. Whenever I see a savvy male politician play the “angry bitch card” against a female opponent, I take it as an ironic sign that she must be really competent and powerful. (I have yet to meet a successful woman who hasn't paid her dues as a “bitch” before she was accepted as a leader.)20 In courtrooms, angry women like Ms. Norman lose their liberty. In fact, in domestic violence cases, men who kill get shorter and lighter sentences, and are charged with less serious crimes, than are women who kill their intimate partners. A murderous husband is just acting like a stereotypical husband, but wives who kill are not acting like typical wives, and therefore they are rarely exonerated. Emotion stereotyping is even worse when the female victim of domestic violence is African American. The archetypal victim in American culture is fearful, passive, and helpless, but in African American communities, women sometimes violate this stereotype by defending themselves vigorously against their alleged batterers. By fighting back, they reinforce a different stereotype of female emotion, the “angry black woman,” which is also pervasive in the U.S. legal system. These women are more likely to be charged with domestic violence themselves, even when their actions were in self-defense and were less severe than the original assault. (No “stand your ground” allowed here!) And if they injure or kill their alleged batterer, they usually fare worse than a European American woman in the same situation. For example, consider the case of Jean Banks, an African American woman who stabbed and killed her live-in partner, James “Brother” McDonald, after he had beaten her for years, sometimes so severely that she required medical attention. On this particular day, both had been drinking, and during an argument, McDonald pushed Banks to the ground and attempted to slice her with a glass cutter. Banks grabbed a knife to defend herself and stabbed him through the heart. She claimed self-defense but nonetheless was convicted of second-degree murder. (Compare this to light-skinned Judy Norman, who was convicted of voluntary manslaughter, a lesser charge.)23 Angry women do not fare well outside of domestic violence cases either. Judges infer all sorts of negative personality characteristics in angry female rape victims that they tend not to attribute to angry male crime victims. When a woman has been raped, for instance, judges (and juries and the police) expect to see her express grief on the witness stand, which tends to bring the rapist a heavier sentence. When a female victim expresses anger, judges evaluate her negatively. These judges are falling prey to another version of the “angry bitch” phenomenon. When people perceive emotion in a man, they usually attribute it to his situation, but when they perceive emotion in a woman, they connect it to her personality. She's a bitch, but he's just having a bad day. Outside the courtroom, we find laws where gender stereotypes prescribe the acceptable emotions we must feel and express. Abortion laws, as written, signal which emotions are appropriate for a woman to feel, namely, remorse and guilt, whereas relief and happiness go unmentioned. The debate over the legality of gay marriage was, in a way, whether the law should sanction the emotion of romantic love between two people of the same sex. Adoption laws governing gay men raise the question of whether a father's love is equal to that of a mother. Overall, there is no scientific justification for the law's view of men's and women's emotions. They are merely beliefs that come from an outdated view of human nature. The examples I've chosen represent only a small slice of the issue, both on the legal side and on the science side. I've barely scratched the surface of emotion stereotypes of ethnic groups, for example, who face similar struggles in and out of court. As long as the law codifies emotion stereotypes, people will continue to be the target of inconsistent rulings. When Stefania Albertani pled guilty to drugging and killing her own sister, not to mention setting the corpse on fire, her defense team took a bold step and blamed her brain. Brain imaging revealed that two regions of Albertani's cortex contained fewer neurons than a control group of ten other healthy women. The regions were the insula, which the defense claimed was associated with aggression, and the anterior cingulate gyrus, which allegedly was associated with lowering one's inhibitions. Two expert witnesses concluded that a “causal relationship” between her brain structure and her crime was possible. After this testimony, Albertani's jail sentence was reduced from life imprisonment to twenty years. Legal decisions like this one, which was a media sensation in Italy in 2011, are becoming more common as lawyers employ neuroscience findings in their defense strategy. But are these decisions justified? Can brain structure explain why someone committed a crime? Can a region of a certain size or connectivity actually cause murderous behavior, and in the process, make a defendant less responsible for a crime?28 Legal arguments like those made by Albertani's defense team grossly misrepresent neuroscience findings and the conclusions that can be drawn from them. It is just not possible to localize a complex, psychological category like “Aggression” to one set of neurons, because of degeneracy; “Aggression,” like any other concept, may be implemented differently in the brain each time it's constructed. Even simple actions like hitting or biting have not been localized to a single set of neurons in the human brain. The brain regions mentioned by Albertani's defense team are among the most highly connected hubs in the entire brain. They show increased activation for just about every mental event you can list, from language to pain to math skills. So, sure, they might play a role in aggression and impulsivity in some instances. But it's a stretch to claim any specific causal relationship between these regions and the extreme aggression of murder . . if Albertani's motive was even aggression in the first place. It's also a stretch to claim that variation in brain size translates into variation in behavior. No two brains are exactly alike. They generally have the same parts, roughly in the same place, connected together in pretty much the same way, but at a fine-grained level, in their microcircuitry, they have vast differences. Some may translate into behavioral differences, but many do not. Your insula might be larger or more highly connected than mine without any discernable effect on your behavior when compared to my behavior. Even if we examine many brains and find a statistically significant difference in insula size between people who are more or less aggressive, that doesn't mean that a larger insula causes aggression, let alone murder. (Plus, even if a larger insula did cause aggression, how big does it need to be to produce a killer?) In rare cases, a tumor can press against the brain and cause severe personality changes, but in general, it is not scientifically justified to try a brain region for murder. Perhaps the most surprising thing about Albertani's case is that the expert witnesses and the judge thought that the brain was an “extenuating explanation” for Albertani's murderous behavior. All behavior stems from the brain. No human actions, thoughts, or feelings exist apart from firing neurons. The wrong way to use neuroscience in court is to argue that a biological explanation automatically releases someone from responsibility. You are your brain. The law often looks for simple, single causes, so it's tempting to blame a brain aberration for criminal behavior. But behavior in real life is anything but simple. It's a culmination of multiple factors, including predictions from your brain, prediction error from your five senses plus interoceptive sensation, and a complex cascade involving billions of prediction loops. And that's just the story inside a single person. Your brain is also surrounded by other brains in other bodies. Whenever you speak or act, you influence the predictions of others around you, who in turn influence your predictions right back. A whole culture collectively plays a role in the concepts you build and the predictions you make, and therefore in your behavior. People can argue over how large a role culture plays, but the fact of its role is not debatable. Bottom line: Sometimes a biological problem can interfere with your brain's ability to choose your actions with intent. Maybe you grow a brain tumor, or some neurons begin to die in just the wrong places. But mere variability in the brain-in its structure, function, chemistry, or genetics-is not an extenuating circumstance for a crime. Variation is the norm. Dzhokhar Tsarnaev, the Boston Marathon bomber, was convicted in 2015 and sentenced to death. Tsarnaev received a trial by jury, a right guaranteed to all Americans by the U.S. Constitution. According to the BBC, who reported on the sentencing, “Only two of the jurors believed Tsarnaev has felt remorse. The other 10, like many in Massachusetts, think he has no regrets.” Jurors formed these opinions of Tsarnaev's remorse by observing him closely during the trial, where he reportedly sat “stone-faced” throughout most of the proceedings. Slate.com noted that Tsarnaev's defense attorney “did not-or could not-present evidence [that] Dzhokhar Tsarnaev has felt any of the remorse that the prosecution says he is devoid of.”33 Trial by jury is considered the gold standard for fairness in a criminal case. Jurors are instructed to make decisions based only on the evidence presented. In a predicting brain, however, this is an impossible task. The jurors perceive every defendant, plaintiff, witness, judge, attorney, courtroom, and iota of evidence through the lens of their own conceptual system, which makes the idea of the impartial juror an implausible fiction. In effect, a jury is a dozen subjective perceptions that are supposed to yield one fair and objective truth. The idea that jurors can somehow detect remorse in a defendant, from his facial configurations or bodily movements or words, is steeped in the classical view, which assumes that emotions are universally expressed and recognized. The legal system assumes that remorse, like anger and other emotions, has a single, universal essence with a detectable fingerprint. However, remorse is an emotion category composed of many diverse instances, each one made for a specific situation. A defendant's construction of remorse depends on his concept for “Remorse,” culled from his prior experiences within his culture, which exists as cascades of predictions that guide his expression and his experience. On the other side of the courtroom, a juror's perception of remorse is a mental inference-a guess based on cascades of predictions in her brain that make sense of the defendant's facial movements, body posture, and voice. For that juror's perceptions to be “accurate,” she and the defendant must categorize with similar concepts. This kind of synchrony, with one person feeling remorse and the other perceiving it, even without words ever being spoken, is more likely to occur when two people have similar backgrounds, age, sex, or ethnicity. In the Boston Marathon Bombing case, if Tsarnaev felt remorse for his deeds, what would it have looked like? Would he have openly cried? Begged his victims for forgiveness? Expounded on the error of his ways? Perhaps, if he were following American stereotypes for expressing remorse, or if this were a trial in a Hollywood movie. But Tsarnaev is a young man of Muslim faith from Chechnya. He lived in the United States and had close American friends, but Tsarnaev had also (by his defense team's account) spent a lot of time with his older, Chechen brother. Chechen culture expects men to be stoic in the face of adversity. If they lose a battle, they should bravely accept defeat, a mindset known as the “Chechen wolf.” So if Tsarnaev felt remorse, he might well have remained stony-faced. Tsarnaev did reportedly become tearful for a moment when his aunt took the stand to plead for his life. Chechnya has a culture of honor, where it is painful to shame your family. If Tsarnaev saw a loved one publicly shamed, say, an aunt begging on his behalf, a few tears would be consistent with Chechen cultural norms for honor. We-and jurors-can only guess when constructing a perception to explain Tsarnaev's impassive stance. Using our Western cultural concepts of remorse, we perceived him as coolly indifferent or full of bravado, rather than stoic. So it's possible that our guesswork, in this case, produced a cultural misunderstanding in the courtroom, ultimately leading to his death sentence. Or maybe he really is remorseless. As it turns out, Tsarnaev actually did convey remorse for his actions in a letter of apology he wrote in 2013, just a few months after the bombing, two years before he went to trial. Jurors never saw the letter, however. It was sealed as confidential under the U.S. Government's Special Administrative Measures, citing an “international security issue,” and excluded as evidence from the trial. On June 25, 2015, Tsarnaev finally spoke at his sentencing hearing. He confessed to the bombing and stated that he understood the impact of his crime. “I am sorry for the lives that I've taken,” he apologized quietly and calmly, “for the suffering that I've caused you, for the damage that I've done. Irreparable damage.” The range of responses from victims and the press covering the trial was predictably variable. Some were stunned. Some were upset. Some were outraged. Some accepted his apology. And many just could not decide whether it was sincere. We can never know whether Tsarnaev experienced remorse for his terrible actions, nor if his letter could have affected his sentence. But one thing is certain: At a death penalty proceeding, a defendant's remorse is a critical feature that jurors must rely on, according to the law, to make a decision between imprisonment and death. And those perceptions of remorse, like all perceptions of emotion, are not detected but constructed. At the other end of the spectrum, a show of remorse can mean absolutely nothing. Take the case of Dominic Cinelli, a violent criminal with a thirty- year history of armed robberies, assaults, and prison escapes. Cinelli was serving three consecutive life sentences when he appeared before the Massachusetts Parole Board in 2008. A parole board is made up of psychologists, corrections officers, and other knowledgeable professionals who decide whether an inmate will serve beyond his minimum sentence or be released. They witness a virtual parade of remorse, some genuinely experienced and some faked, and their profound responsibility to the public rests on their ability to tell the difference. In November 2008, Cinelli convinced the parole board that he was no longer a criminal with darkness in his soul. The board unanimously voted to free him. It didn't take long for Cinelli to embark on a new series of robberies and fatally shoot a police officer. Cinelli was later killed during a shootout with the police. The governor of Massachusetts, Deval Patrick, saw five of the seven members of the parole board resign. He seemed to think that they lacked the ability to detect authentic remorse. It's possible that Cinelli was putting on an act. It's also possible that Cinelli authentically felt remorse in the moment while he was testifying, but once he was out of prison, his old model of the world resurfaced, with his old predictions, creating his old self, and his remorse evaporated. Since there is no objective criterion for feelings of remorse, we will never know for sure. There is likewise no objective criterion for anger, sadness, fear, or any other emotion relevant to a trial. U.S. Supreme Court Justice Anthony Kennedy once said that juries must “know the heart and mind of the offender” in order for a defendant to have a fair trial. Emotions, however, have no consistent fingerprints in facial movements, body posture and gestures, or voice. Jurors and other perceivers make educated guesses about what those movements and sounds mean in emotional terms, but there is no objective accuracy. At best, we can measure whether jurors agree with one another in the emotions they perceive, but when the defendant and the jurors have different backgrounds, beliefs, or expectations, agreement is a poor substitute for accuracy. If a defendant's demeanor cannot reveal emotion, then the legal system is left to grapple with a difficult question: under what circumstances can a trial be completely fair? When jurors or judges see smugness in a defendant's smile, or when they hear a witness's quavering voice as fear, they are making a mental inference, employing their emotion concepts to guess that the action (smiling or quavering) was caused by a particular state of mind. Mental inference, you'll remember, is how your brain gives meaning to other people's actions through a cascade of predictions (chapter 6). Mental inference is so pervasive and automatic, at least in cultures of the West, that we're usually unaware of doing it. We believe that our senses provide an accurate and objective representation of the world, as if we had X- ray vision for deciphering another person's behavior to discover his intent (“I can see right through you”). In these moments, we experience our perceptions of other people as an obvious property of them-a phenomenon we've called affective realism-rather than a combination of their actions and the concepts in our own brain. When someone is on trial for a crime, and liberty and life are at stake, there can be a gaping chasm between appearance and reality. Deep down we know this, but at the same time we are supremely confident that we can discern truth from fiction more accurately than the other schmucks in the room. And herein lies the problem in court. Jurors and judges are charged with an almost impossible task: to be a mind reader, or if you'd rather, a lie detector. They must decide if a person intended to cause harm. According to the legal system, intent is a fact that is as plain as the nose on a defendant's face. But in a predicting brain, a judgment about someone else's intent is always a guess you construct based on the defendant's actions, not a fact you detect; and just as with emotions, there is no objective, perceiver-independent criterion of intent. Seventy years of psychological research confirms that judgments like these are mental inferences, that is, guesses. Even if DNA evidence connects a defendant to the scene of a crime, it does not determine whether he had criminal intent. Judges and jurors infer intent, usually in line with their own beliefs, stereotypes, and current body states. Here is just one example of how this works. Test subjects watched a video of protestors being dispersed by police. They were told the protestors were pro-life activists picketing an abortion clinic. Those who were liberal Democrats, who tend to be pro-choice, inferred that the activists had violent intentions, whereas socially conservative subjects inferred peaceful intentions. The researchers also showed the same video to a second set of subjects, describing the protestors this time as gay rights activists objecting to the military's Don't Ask, Don't Tell policy. This time, those who were liberal Democrats, who tend to support gay rights, inferred that the activists had peaceful intentions, whereas socially conservative subjects inferred violent intentions. Now imagine that this video were evidence at a trial. All jurors would watch the same scenes, with exactly the same behaviors onscreen, but through affective realism, they would come away with only perceptions, not facts, constructed in line with their own beliefs, entirely without their awareness. My point is that bias is not advertised by a glowing sign worn around jurors' necks; we are all guilty of it, because the brain is wired for us to see what we believe, and it usually happens outside of everyone's awareness. Affective realism decimates the ideal of the impartial juror. Want to increase the likelihood of a conviction in a murder trial? Show the jury some gruesome photographic evidence. Tip their body budgets out of balance and chances are they'll attribute their unpleasant affect to the defendant: “I feel bad, therefore you must have done something bad. You are a bad person.” Or permit family members of the deceased to describe how the crime has hurt them, a practice known as a victim impact statement, and the jury will tend to recommend more severe punishments. Crank up the emotional impact of a victim impact statement by recording it professionally on video and adding music and narration like a dramatic film, and you've got the makings of a jury-swaying masterpiece. Affective realism intertwines with the law outside the courtroom as well. Imagine that you are enjoying a quiet evening at home when suddenly you hear loud banging outside. You look out the window and see an African American man attempting to force open the door of a nearby house. Being a dutiful citizen, you call 911, and the police arrive and arrest the perpetrator. Congratulations, you have just brought about the arrest of Harvard professor Henry Louis Gates, Jr., as it happened on July 16, 2009. Gates was trying to force open the front door of his own home, which had become stuck while he was traveling. Affective realism strikes again. The real-life eyewitness in this incident had an affective feeling, presumably based on her concepts about crime and skin color, and made a mental inference that the man outside the window had intent to commit a crime. A similar bout of affective realism gave birth to Florida's controversial “Stand Your Ground” law. This law permits the use of deadly force in self- defense if you reasonably believe you're in imminent danger of death or great bodily harm. A real-life incident was the catalyst for the law, but not in the way that you might think. Here's how the story is usually told: In 2004, an elderly couple was asleep in their trailer home in Florida. An intruder tried to break in, so the husband, James Workman, grabbed a gun and shot him. Now here's the true, tragic backstory: Workman's trailer was in a hurricane- damaged area, and the man he shot was an employee of the Federal Emergency Management Agency (FEMA). The victim, Rodney Cox, was African American; Workman is white. Workman, mostly likely under the influence of affective realism, perceived that Cox meant him harm and opened fire on an innocent man. Nevertheless, the inaccurate first story became a primary justification for Florida's law. The very history of stand your ground laws is, ironically, potent evidence against their value. It's impossible to determine reasonable fear for one's life in a society where racist stereotypes abound and affective realism literally transforms how people see each other. The whole line of reasoning for stand your ground is gutted by affective realism. If stand your ground doesn't scare the crap out of you, think about the impact of affective realism on people who legally carry concealed weapons. Affective realism indisputably influences people's perceptions of threat; therefore it virtually assures that innocent people will be shot by accident. It's simple: you predict a threat, sensory information from the world says otherwise, but then your control network downplays the prediction error to maintain the prediction of threat. Bam, you've shot a harmless fellow citizen. Human brains are built for this sort of delusion, through the same process that produces daydreams and imagination. I will not wade any further into the national debate about firearms for now, but from a purely scientific perspective, consider this. The founding fathers of the United States had good reasons for protecting a “right of the people to keep and bear Arms” in the Second Amendment of the Constitution, but they were not neuroscientists. Nobody in 1789 knew that the human brain constructs every perception and is ruled by interoceptive predictions. Right now, over 60 percent of people in the United States believe that crime is on the rise (though it's historically low), and they also believe that owning a gun will make them safer. These beliefs are ripe to lead people, through affective realism, to genuinely see a deadly threat where there is none and to act accordingly. Now that we know definitively that our senses don't reveal objective reality, shouldn't this critical knowledge influence our laws?48 As a general rule, the legal system has had a lot of difficulty coming to grips with the mountains of scientific evidence that our senses don't provide a literal readout of the world. For hundreds of years, eyewitness reports used to be considered one of the most reliable forms of evidence. When a witness said, “I saw him do it” or “I heard her say it,” these statements were considered to be facts. The law also treated memories as if they entered the brain pristinely, were stored whole, and were later retrieved and played back like a movie. Just as jurors cannot pull back the curtain of their own beliefs for direct access to some unblemished version of reality, witnesses and defendants do not report a collection of facts but a description of their own perceptions. One can glance at Serena Williams's triumphant face at the beginning of chapter 3 and later, on the witness stand, swear on a Bible that Williams was screaming in terror. Any words spoken by eyewitnesses are based on recollections that are constructed in the moment, using past experiences that were themselves constructed. Psychologist Daniel L. Schacter, one of the world's experts on memory, tells the story of a brutal rape that took place in Australia in 1975. The victim told police that she'd seen her attacker's face clearly, identifying him as Donald Thomson, a scientist. Police picked up Thomson the next day based on this eyewitness evidence, but Thomson had an iron-clad alibi: he was being interviewed on television at the time of the rape. It turned out that the victim's TV was on when the intruder broke into her house, and it was tuned to Thomson's interview, which ironically was about Thomson's research on memory distortion. The poor woman had somehow, in her trauma, fused Thomson's face and identity onto her attacker. Most men falsely accused are not so lucky. Jurors place a lot of weight on eyewitness testimony, yet they accept mistaken identifications just as frequently as correct ones, as long as the witnesses sound confident. In one study of convictions that were later overturned by DNA evidence, 70 percent of the accused were convicted based on eyewitness testimony. Eyewitness reports are perhaps the least reliable evidence one can have. Memories are not like a photograph-they are simulations, created by the same core networks that construct experiences and perceptions of emotion. A memory is represented in your brain in bits and pieces as patterns of firing neurons, and “recall” is a cascade of predictions that reconstruct the event. Your memories are therefore highly vulnerable to reshaping by your current circumstances, like having your body all worked up in the witness stand, or if you're being badgered by a persistent defense attorney. The law has been slow to accept that memories are constructed, but the situation is gradually changing. The Supreme Courts of New Jersey, Oregon, and Massachusetts are leading the way in this regard. Their jurors now receive instructions that provide step-by-step details-based on years of psychological research-explaining all the ways in which memory can go wrong in eyewitness testimony. They read how memories are constructed and infused with beliefs that can result in distortions and illusions, how the instructions given by lawyers and police can introduce biases, how confidence is unrelated to accuracy, how stress can impair memory, and how eyewitness testimony was a factor in falsely convicting more than three quarters of the people who were exonerated by DNA evidence for crimes that they did not commit. Unfortunately, no such guidelines exist to explain to jurors what an emotional expression is, what a mental inference is, or how they are constructed. The figure of the dispassionate judge, who renders emotionless decisions in strict accordance with the law, is an archetype in many societies. The law expects judges to be neutral, as emotion would presumably get in the way of fair decisions. “Good judges pride themselves on the rationality of their rulings and the suppression of their personal proclivities,” wrote the late U.S. Supreme Court Justice Antonin Scalia, “including most especially their emotions.”53 In some ways, a purely rational approach to legal decision-making sounds compelling and even noble, but as we've seen so far, the brain's wiring doesn't divide passion from reason. We needn't work hard to poke holes in this argument; it comes with its own holes pre-drilled. Let's start with the idea that a judge can be dispassionate, which should be interpreted as “having no affect” (rather than “having no emotion”). This idea is a biological impossibility unless that person has suffered brain damage. As we discussed in chapter 4, no decision can ever be free of affect as long as loudmouthed body-budgeting circuitry is driving predictions throughout the brain. Affectless decision-making from the bench is a fairy tale. Robert Jackson, another former Supreme Court justice, described “dispassionate judges” as “mythical beings” like “Santa Claus or Uncle Sam or Easter bunnies.” Direct scientific evidence shows him to be pretty much on target. Remember how judges' impartiality was easily swayed in parole cases held right before lunchtime, when they attributed their unpleasant affect to the prisoner instead of to hunger (chapter 4)? In another series of experiments, over 1,800 state and federal judges from the United States and Canada were handed scenarios of civil and criminal cases and asked what their rulings would be. Some scenarios were identical except the defendants were portrayed as more likeable or unlikeable. The experimenters found that judges tended to rule in favor of more likeable or sympathetic people. Even the U.S. Supreme Court is not immune to leaking passion from the bench. A team of political scientists examined 8 million words spoken by the members of the Court during oral arguments, and their questioning, over thirty years. They found that when judges focus “more unpleasant language” toward an attorney, that side is more likely to lose. You can predict the loser by simply counting the justices' negative words during questioning. Not only that, but by examining the affective connotations in the judges' words during oral arguments, you can predict their votes. Common sense dictates that judges experience strong affect in the courtroom. How could they not? They hold people's futures in their hands. Their working hours are filled with heinous crimes and grievously harmed victims. I know how draining this can be, having been a therapist for victims of rape and childhood sexual abuse, and sometimes working with the perpetrators. Judges also encounter defendants who are more likable than the people they have preyed on, a situation that surely is challenging to grapple with, especially in a courtroom full of whispering spectators and bickering attorneys. And sometimes a judge must shoulder the affect of an entire country. Former U.S. Supreme Court Justice David Souter suffered so much while deciding Bush v. Gore that he wept because of its deliberations (along with half of the United States). All this mental effort taxes a judge's body budget. The judge's life is one of intense and continual emotional labor under the fiction of equanimity. Nevertheless, the law continues to hold dear the fiction of the dispassionate judge, even at the highest levels. When Supreme Court Justice Elena Kagan, as a nominee in 2010, was asked whether it was ever appropriate for feelings to help decide a case, she replied to the contrary, “It's the law all the way down.” Justice Sonia Sotomayor also ran into opposition during her confirmation hearings, as some senators feared that her emotions and empathy were in direct opposition to her abilities to judge fairly. Her take on all this, for the most part, was that judges do have feelings but should not make decisions based on them. Nonetheless, the evidence is clear that judges are not affectless in their rulings. The next question is: should they be? Is pure reason really the best way to render a wise decision? Imagine a person who is very calmly and coolly weighing the pros and cons about whether or not another person should die. There's not a trace of emotion in sight. Like Hannibal Lecter in The Silence of the Lambs, or Anton Chigurh in No Country for Old Men. I am being a bit facetious here, but this kind of dispassionate decision-making is essentially what the law instructs in the sentencing portion of criminal cases. Rather than pretend that affect is absent, it's better to use affect wisely. As U.S. Supreme Court Justice William Brennan once expressed, “Sensitivity to one's intuitive and passionate responses, and awareness of the range of human experience, is therefore not only an inevitable but a desirable part of the judicial process, an aspect more to be nurtured than feared.” The key is emotional granularity: having a wide and deep range of concepts (emotion, physical, or otherwise) to make sense of the onslaught of bodily sensations that are the hazards of the job. Consider, for example, a judge faced with a defendant like James Holmes, who murdered twelve moviegoers and injured seventy more during a midnight screening of a Batman movie in Aurora, Colorado, in 2012. Such a judge might reasonably construct an experience of anger, but that feeling alone could be problematic; anger could prompt the judge to punish the defendant too harshly for the sake of retribution, threatening the moral order that the trial is founded on. To balance his view, some legal scholars argue, the judge could try to cultivate empathy for the defendant, who perhaps is insane or a victim of some sort himself. Anger is a form of ignorance; in this case, ignorance of the defendant's perspective. Holmes clearly struggled with serious mental illness for years. He tried to kill himself for the first time when he was eleven years old, and has attempted suicide several times in jail. Empathy is extremely difficult to cultivate for someone who opens fire on innocents in a movie theater. Even remembering that the defendant is a human being, no matter how severe or gruesome the crime, might be a struggle at times, but this is when empathy might be most important. It may prevent a judge from going too far in punishing the offender during sentencing, and help to ensure the morality of penal decision-making and retributive justice. This is the type of emotional granularity that makes for wise use of emotion in the courtroom. When it comes right down to it, the most useful emotions for a judge to feel depend on the judge's goals during the trial. What, for example, is the goal of punishment? Is it retribution? Deterrence to avoid future harm? Rehabilitation? This depends on the law's theory of the human mind. Whatever the goal, punishment must be enacted so that the defendant's humanity is preserved, while the victim's humanity is honored, even if the defendant commits an unspeakable act. To do otherwise puts the legal system itself in jeopardy. Why is it that you can sue someone for breaking your leg but not for breaking your heart? The law considers emotional damage to be less serious than physical damage and less deserving of punishment. Think about how ironic this is. The law protects the integrity of your anatomical body but not the integrity of your mind, even though your body is just a container for the organ that makes you who you are-your brain. Emotional harm is not considered real unless accompanied by physical harm. Mind and body are separate. (Let's all raise a glass to René Descartes here.) If there is one thing you can take away from this book, it is that the boundaries between mental and physical are porous. chapter 10 explained a bit about the ways in which emotional harm from chronic stress, parental emotional abuse and neglect, and other psychological ills can ultimately cause physical illness and injury. And we've seen how stress and proinflammatory cytokines lead to numerous health problems, including brain atrophy, and increase the likelihood of cancer, heart disease, diabetes, stroke, depression, and a host of other illnesses. But that's not the whole story. Emotional harm can shorten your life. Inside your body, you have little packets of genetic material that sit on the ends of your chromosomes like protective caps. They're called telomeres. All living things have telomeres-humans, fruit flies, amoebas, even the plants in your garden. Every time one of your cells divides, its telomeres get a little shorter (although they can be repaired by an enzyme called telomerase). So generally their size slowly decreases, and at some point, when they are too short, you die. This is normal aging. But guess what else causes your telomeres to get smaller? Stress does. Children who experience early adversity have shorter telomeres. In other words, emotional harm can do more serious damage, last longer, and cause more future harm than breaking a bone. This means the legal system might be misguided when it comes to understanding and gauging the degree of lasting injury that can come from emotional harm. As another example, consider chronic pain. The law treats chronic pain by and large as “emotional” because there's no observable tissue damage. In these cases, the law usually concludes that the suffering is not real enough to merit compensation. People who suffer from chronic pain are often diagnosed as mentally ill, and even more so if they opt for an invasive operation to try and reduce their “illusory” suffering. Medical insurance companies deny treatment since chronic pain is considered psychological, not physical. The sufferer cannot work, yet no compensation is provided. But as we saw in the preceding chapter, chronic pain is likely a brain disease of prediction gone wrong. The suffering is real. The law is missing the point that prediction and simulation are the normal way that the brain works, and chronic pain is a difference of degree, not kind. Interestingly, the law does accept that other types of harm can be absent now but show up in the future. A prominent example is chemical harm such as Gulf War Syndrome, a chronic, multi-symptom illness allegedly caused by unknown factors during the Gulf War, whose effects did not appear until later. Gulf War Syndrome is controversial; there is no consensus on whether it's actually a distinct medical condition. Regardless, thousands of veterans have taken their claims of Gulf War Syndrome to court. There is no analogous legal avenue for stress or other harm seen as emotional. (Awards for pain and suffering are relatively rare.) Having made this observation, I must point out that the law is deeply inconsistent and even ironic in its view of emotional harm when you consider international norms for torture. The Geneva Conventions prohibit psychological harm to prisoners of war, and the U.S. Constitution likewise forbids “cruel and unusual punishment.” So it's illegal for a government to torture a prisoner psychologically, but it's perfectly legal to place a prisoner in solitary confinement for long periods, even though the stress of confinement may shorten the prisoner's telomeres and therefore his life. It's also perfectly legal for a high school bully to insult, torment, and humiliate your children even though this will shorten their telomeres and potentially their lifespan. When a group of middle-school girls deliberately excludes another girl, they are acting with intent and motivation to cause suffering, yet legal action is rare. In one highly publicized case, fifteen-year- old Phoebe Prince hanged herself in 2010 after months of verbal aggression and physical threats. Six teenagers were criminally prosecuted for harassment, stalking, assault, and assorted civil rights violations after they bullied her and then posted crude comments on her Facebook memorial page. This case prompted Massachusetts to pass anti-bullying laws. These laws are a start, but they punish only the most extreme cases. How do you regulate the playground in a legal context?63 Bullies intend to cause suffering, but is the intent to cause harm? We cannot know for sure, but in most cases I doubt it. Most kids are unaware that the mental anguish they inflict can translate into physical illness, atrophied brain tissue, reduced IQ, and shortened telomeres. Kids will be kids, we say. But bullying is a national epidemic. In one study, over 50 percent of children nationwide reported being verbally or socially bullied at school, or having participated in bullying another child at school, at least once in two months. Over 20 percent reported being the victim or perpetrator of physical bullying, and over 13 percent reported involvement with electronic bullying. Bullying is considered a serious enough childhood risk, with potential lifelong health consequences, that at press time, the U.S. Institute of Medicine and the National Research Council's Committee on Law and Justice are producing a comprehensive report on its biological and psychological ramifications. If you suffer mental anguish in the moment, whether from bullying or another cause, should your suffering count as harm, and should the perpetrators be punished? A recent legal case implies the answer is sometimes yes. A company in Atlanta demanded DNA samples from its employees because someone was contaminating its warehouse with feces. It's illegal to take genetic information from someone without his consent (it violates the Genetic Information Nondiscrimination Act), but the case was won largely on emotional grounds. The two plaintiffs were awarded about $250,000 each to compensate them for feeling humiliated and bullied, plus a remarkable $1. million in punitive damages for “emotional distress and mental anguish.” The large award was not for the plaintiffs' actual emotional suffering but their potential emotional suffering in the future. After all, their personal health information could be used against them at any time for the rest of their lives. This fear of the future was easy for jurors to simulate and therefore empathize with. In a chronic pain case, it's harder: how do you see the invisible? There are no injuries to look at, and nothing to help your brain create the simulation, so empathy suffers and consequently so does compensation. The legal system has difficulty dealing with mental anguish for purely practical reasons. How do you measure it objectively if emotions have no essences or fingerprints? Also, physical harm like a broken leg is usually more economically predictable than emotional harm, which is far more variable. And how do you distinguish everyday emotional pain from lasting harm?66 Perhaps the most important question here is: Whose suffering counts as harm? Who deserves our empathy and therefore the full protection of the law? If you negligently or intentionally break my arm, you owe me. But if you negligently or intentionally break my heart, you don't, even if we were close for a long time, regulating each other's body budgets, and the breakup will put me through a physical process that can be as excruciating as withdrawal from an addictive drug. You can't sue someone for heartbreak, no matter how much you might want to (or how much they deserve it). The law is about creating and enforcing social reality. Empathic claims about pain are fundamentally claims about whose rights matter . . and whose humanity matters. As you've seen, the law embodies the classical view of emotion and the view of human nature from which it derives. This essentialist story is a folktale that is not respected by the brain and its connection to the body. Therefore, based on today's scientific view of the brain, I'm going to go out on a limb with some recommendations for jurors, judges, and the legal system in general. I am not a legal scholar, and I realize that the concerns of science are not the same as those of the law. I realize also that it's one thing to speculate about basic dilemmas of humanity in the pages of a book but quite another to establish legal precedent on them. But it's important to try to build bridges between disciplines. Neuroscience and the legal system are seriously out of sync on fundamental issues of human nature. These discrepancies must be addressed if the legal system is to remain one of our most impressive achievements of social reality and continue protecting people's inalienable rights to life, liberty, and the pursuit of happiness. I'd begin by educating judges and jurors (and other legal actors like attorneys, police officers, and parole officers) about the basic science of emotion and the predictive brain. The New Jersey, Oregon, and Massachusetts Supreme Courts are taking steps in the right direction by formally instructing jurors that human memory is constructed and fallible. We need a similar approach for emotion. Toward that end, I propose a set of five teaching points. You might call it an affective science manifesto for the legal system. The first teaching point in the manifesto concerns so-called expressions of emotion. Emotions are not expressed, displayed, or otherwise revealed in the face, body, and voice in any objective way, and anyone who determines innocence, guilt, or punishment needs to know this. You cannot recognize or detect anger, sadness, remorse, or any other emotion in another person-you can only guess, and some guesses are more informed than others. A fair trial depends on synchrony between experiencers (defendants and witnesses) and perceivers (jurors and judges), and this can be difficult to achieve in many circumstances. For example, some defendants are better at using their nonverbal movements to communicate information about their emotions, such as remorse. Some jurors will be better at synchronizing their concepts with a defendant than others will. That means jurors might need to work harder to perceive emotions in challenging situations, like when they disagree with a defendant or witness on a political issue, or when the other person is of a different ethnicity. Jurors should try to put themselves in the other person's shoes to facilitate this synchrony and cultivate empathy. The second point is about reality. Your sight, hearing, and other senses are always colored by your feelings. Even the most objective-sounding evidence is colored by affective realism. Jurors and judges must be educated about the predictive brain and affective realism, how their feelings literally alter what they see and hear in court. Perhaps the protestor video study I mentioned, where political beliefs caused people to perceive violent intent or not, could serve as an educational example. Jurors must also understand how affective realism influences eyewitnesses. Even a simple statement like “I saw him holding the knife” is a perception infused with affective realism. Eyewitness testimony does not relay cold, hard facts. The third point is about self-control. Events that feel automatic are not necessarily completely outside your control and are not necessarily emotional. Your predicting brain provides the same range of control when you construct an emotion as when you construct a thought or a memory. The defendant in a murder trial is not a man-shaped sea anemone at the mercy of his environment, triggered by anger to pursue an inevitable, aggressive act. Most instances of anger, no matter how automatic they feel, don't lead to murder. Anger can also unfold very deliberately over a long time, so there is nothing inherently automatic about it. You have relatively more responsibility for your actions when you have relatively more control, regardless of whether the event is an emotion or a cognition. Fourth, beware the “my brain made me do it” defense. Jurors and judges should be skeptical of claims that certain brain regions directly cause bad behavior. That is junk science. Every brain is unique; variation is normal (think degeneracy) and not necessarily meaningful. Unlawful behavior has never been definitively localized to any brain region. I am not referring here to foreign growths like tumors or obvious signs of neurodegeneration, which in some cases, such as certain types of frontotemporal dementia, can make it harder for people to conform their actions to the law. Even so, many tumors and neurodegenerative damage cause no run-ins with the legal system at all. The final teaching point is to be mindful of essentialism. Jurors and judges need to know that every culture is full of social categories like sex, race, ethnicity, and religion. These must not be mistaken for physical, biological categories with deep dividing lines in nature. Also, emotion stereotypes don't belong in a courtroom. Women should not be punished for feeling anger rather than fear toward their aggressors, and men should not be punished for feeling helpless and vulnerable rather than brave and aggressive. The law's reasonable person standard is a fiction based on stereotypes, and it is inconsistently applied. Perhaps it's time to bury the reasonable person and conceive some other standard for comparison. Beyond the affective science manifesto, we also have the longstanding myth of the dispassionate judge, which is both propagated and questioned by members of the U.S. Supreme Court and other legal experts. Scholars may debate in legal journals about the value of emotion in judicial action, but the anatomy of the human brain makes it implausible for any human, including a judge, to escape the influence of interoception and affect when making decisions. Emotions are neither the enemy nor a luxury but a source of wisdom. Judges need not reveal their emotions (just as therapists learn not to), but they must be aware of them and explicitly use them to the best of their ability. To employ emotions wisely, I suggest that judges learn to experience emotion with high granularity. If they feel unpleasant, they'll be helped if they can categorize finely to experience (say) anger distinctly from irritation or hunger. Anger can be a reminder to cultivate empathy toward an unsympathetic defendant, a gullible plaintiff, a belligerent witness, or a particularly intrusive attorney. Without empathy, anger can foster the type of retributive punishment that risks undermining the very notion of justice at the foundation of the legal system. Judges can cultivate higher granularity using the exercises I recommended in chapter 9: collecting experiences, learning more emotion words, using conceptual combination to invent and explore new emotion concepts, and deconstructing and recategorizing their emotional experiences in the moment. It sounds like a lot of work, but like any skill, it becomes habitual with practice. Also, it would not hurt for judges who face defendants from other cultures to be briefed on the different cultural norms for emotional experience and communication. Judges might also be educated to reduce the influence of affective realism when selecting jurors (a process known as voir dire). Often, judges and attorneys weed out jurors by asking them direct, transparent questions such as “Can you be objective, fair, and impartial in this case?” or “Do you know the defendant?” They also try to assess superficial similarities between jurors and defendants. For example, if a financial advisor stands accused of embezzling millions of dollars of his clients' retirement investments, the judge might ask potential jurors whether they themselves have been victims of embezzlement, or whether a close relative works in the financial industry. But surface markers of similarities and differences are only the tip of the iceberg. It might be wise to examine a juror's affective niche to understand how the juror might predict during a trial, which could indicate biases that shape perception. For example, a judge could ask what magazines the jurors read, what movies they prefer to see, or whether they play first-person shooter games, using standard assessment techniques from psychology. Such information would allow a judge to consider the potential biases of jurors based on how they spend their time, rather than just asking jurors directly about their biases (since such self- reports are not necessarily valid). My suggestions so far address low-hanging fruit. Now we're ready for the really difficult stuff-scientific considerations that could change fundamental assumptions in the law. We already know that our senses do not reveal reality, and judges and jurors necessarily suffer from affective realism. These factors, along with the rest of our knowledge of mind and brain, lead to a fairly radical idea (I'm almost afraid to say it): perhaps it is time to reevaluate trial by jury as the basis for determining guilt and innocence. Yes, it's enshrined in the U.S. Constitution, but the writers of that landmark document had no inkling of how the human brain works, nor that one day we could detect a defendant's DNA under a victim's fingernails. Before DNA evidence, the law could not say whether a judgment of guilt was true or false. The legal system could only decide whether or not the judgment was rendered fairly, meaning that the rules and procedures of law were followed consistently. The law was therefore not about truth but consistency. Due process was about avoiding procedural errors in rendering a decision of guilt or innocence, not about the validity of the decision itself. Today's legal system works only if we assume that consistency produces a just outcome. DNA testing is changing all that. It's not perfect, but it's immeasurably more objective than the affect-laden perceptions of human jurors. When DNA evidence is unavailable or irrelevant, perhaps trials might dispense with a jury and instead feature the collective wisdom of multiple judges working together, randomly drawn from a larger pool of judges. As I've said already, I'm not a legal scholar, just a scientist, so perhaps wiser legal minds can construct a balanced judicial panel system in better ways. A panel of skilled judges who are trained to be self-aware and emotionally granular might avoid affective realism more effectively than a jury would. It's not a perfect solution by any means: in the United States at least, judges tend to be on the older side, predominantly European American, and may overrepresent a particular set of beliefs while maintaining the illusion that they are free of them. Judges are also more likely to hand out maximum sentences. But one thing is certain: every day in America, thousands of people appear before a jury of their peers and hope they will be judged fairly, when in reality they are judged by human brains that always perceive the world from a self-interested point of view. To believe otherwise is a fiction that is not supported by the architecture of the brain. And now we get to the toughest issue of all: what it means to control your behavior and therefore be responsible for your actions. The law (like much of psychology) usually considers responsibility in two parts: actions caused by you, where you have more responsibility, and actions caused by the situation, where you have less. This simple dichotomy of internal versus external does not mesh with the reality of the predictive brain. In a construction view of human nature, every human action involves three types of responsibility, not two. The first is traditional: your behavior in the moment. You pull the trigger. You grab the money and run. (The legal system names this behavior actus reus, the harmful action.) The second type of responsibility involves your specific predictions that brought about the unlawful act (known as mens rea, the guilty mind). Your behavior is not caused in a single moment; it is always driven by prediction. When you steal money from an open cash register, you are an agent in the moment, but the ultimate cause of your behavior also includes concepts like “Cash Register,” “Money,” “Ownership,” and “Stealing.” Each of these concepts is associated with a large and diverse population of instances in your brain, and based on them, you issued predictions that led to your action. Now, if other people with similar concepts in the same situation (i.e., the reasonable person) would also steal the cash, well, you might be less culpable for your actions. However, they may well have left the cash untouched, in which case your responsibility is greater. The third type of responsibility relates to the content within your conceptual system, separately from how your brain uses that system to predict when breaking the law. A brain does not compute a mind in a vacuum. Every human being is the sum of his or her concepts, which become the predictions that drive behavior. The concepts in your head are not purely a matter of personal choice. Your predictions come from the cultural influences you were pickled in. When a European American police officer shoots an unarmed African American civilian, and the officer honestly saw a gun in the civilian's hands due to affective realism, the event has roots in something outside the moment. Even if the officer were overtly racist, his actions were partly caused by his concepts, formed by a lifetime of experience, which includes American stereotypes about race. The victim's concepts and actions are likewise informed by a lifetime of experience, which includes American stereotypes of cops. All of your predictions are shaped not just by direct experience but also indirectly by television, movies, friends, and the symbols of your culture. While it's exciting to escape into a world of urban crime in a movie, or to retreat from the stress of the day by watching an hour or two of a police drama on TV, routine depictions of police conflicts have a cost. They fine- tune our predictions about the danger posed by people of certain ethnicities or socioeconomic status. Your mind is not only a function of your brain but also of the other brains in your culture. This third domain of responsibility cuts two ways. Sometimes it's trivialized as “society is to blame,” a phrase lampooned as bleeding-heart liberal sentiment. I am saying something more nuanced. If you commit a crime, you are indeed to blame, but your actions are rooted in your conceptual system, and those concepts don't just appear in a puff of magic. They are forged by the social reality you live in, which gets under your skin to turn genes on and off and wire your neurons. You learn from your environment like any other animal. Nevertheless, all animals shape their own environment. So as a human being, you have the ability to shape your environment to modify your conceptual system, which means that you are ultimately responsible for the concepts that you accept and reject. As we discussed in chapter 8, the predictive brain expands the horizon of self-control beyond the moment of action and therefore broadens your responsibility in a complicated way. Your culture might teach you that people of a certain skin color are more likely to be criminals, but you have the ability to mitigate the harm that such beliefs can cause, and hone your predictions in a different direction. You can befriend people of different skin tones and see for yourself that they're law-abiding citizens. You can choose not to watch TV shows that reinforce racist stereotypes. Or you can blindly follow the norms of your culture, accept the stereotyped concepts bestowed upon you, and increase the chances that you'll treat certain people badly. Dylann Roof, the man who shot African American members of a Bible study group, chose to surround himself with symbols of white supremacy. Sure, he grew up in a society struggling with racism, but so did most adults in the United States, and most of us don't go around shooting people. So at the level of neurons, you and your society jointly cause certain predictions to become more likely in your brain. However, you still bear responsibility to overcome harmful ideology. The difficult truth is that each of us, ultimately, is responsible for our own predictions. The law has precedent for this prediction-based view of responsibility. For example, if you drive drunk and hit someone with your car, you are responsible for the harm you caused, even though you could not control your limbs effectively in your inebriated state. You should have known better, because every adult in our society knows that drunkenness carries a risk of bad decision-making, so you are culpable for bad things that happen downstream. The law calls this a foreseeability argument. It doesn't matter whether you intended to cause harm or not: you are liable. And we now have enough scientific evidence to extend the foreseeability argument from large-scale common sense to the millisecond predictions of the brain. You know full well that some of your concepts, such as racial stereotypes, can lead you into trouble. If your brain predicts that an African American youth in front of you is holding a weapon, and you perceive a gun where none is present, you have some degree of culpability even in the face of affective realism, because it is your responsibility to change your concepts. If you educate yourself and inoculate yourself against such stereotypes, expanding your conceptual system with the goal to change your predictions, you still might mistakenly see a gun where none is present, and a tragedy still might occur. But your culpability is diminished somewhat, because you've acted responsibly to change what you can. Eventually, the legal system must come to grips with the tremendous influence of culture on people's concepts and predictions, which determine their experiences and actions. After all, the brain wires itself to the social reality it finds itself in. This ability is one of the most important evolutionary advantages we have as a species. So we bear some responsibility for the concepts we help wire into future generations of little human brains. But this is not an issue for criminal law. It is actually a policy issue relevant to the First Amendment, which guarantees the right to free speech. The First Amendment was founded on the notion that free speech produces a war of ideas, allowing truth to prevail. However, its authors did not know that culture wires the brain. Ideas get under your skin, simply by sticking around for long enough. Once an idea is hardwired, you might not be in a position to easily reject it. The science of emotion is a convenient flashlight for illuminating some of the law's long-held assumptions about human nature-assumptions that we now know are not respected by the architecture of the human brain. People don't have a rational side and an emotional side, with the former regulating the latter. Judges can't set aside affect to issue rulings by pure reason. Jurors can't detect emotion in defendants. The most objective-looking evidence is tainted by affective realism. Criminal behavior can't be isolated to a blob in the brain. Emotional harm is not mere discomfort but can shorten a life. In short, every perception and experience within the courtroom-or anywhere else-is a culturally infused, highly personalized belief, corrected by sensory inputs from the world, rather than the result of an unbiased process. We're at a turning point where the new science of mind and brain can begin to shape the law. By educating judges, jurors, attorneys, witnesses, police officers, and other participants in the legal process, we should be able to produce a legal system that is ultimately more fair. Perhaps we cannot move away from trial by jury anytime soon, but even simple steps, like educating jurors that emotions are constructed, can improve the current situation. For now at least, the legal system still considers you to be an emotional beast enrobed in rational thought. Throughout this book, we've systematically challenged this myth by evidence and observation, but there's one remaining assumption that we haven't questioned yet: are beasts even emotional? Are the brains of our close primate cousins, such as chimps, capable of constructing emotion? What about dogs: do they have concepts and social reality as we do? Just how unique in the animal kingdom are our emotional abilities? We'll explore these topics in the next chapter."
  },
  {
    "index": 17,
    "level": 1,
    "start_page": 245,
    "end_page": 269,
    "title": "Is a Growling Dog Angry?",
    "content": "Is a Growling Dog Angry.? I don't have a dog, but several friends' dogs are part of my extended family. One of my favorites is Rowdy, part Golden Retriever and part Bernese Mountain Dog, who is an energetic, playful mutt, always ready for action. True to his name, Rowdy is a barker and a jumper, and he's known to growl when other dogs or strangers come near. In other words, he's a dog. Sometimes Rowdy can barely contain himself, and once this nearly proved to be his undoing. Rowdy was out for a walk with his owner, my friend Angie, when a teenage boy approached to pet him. Rowdy did not know the boy and proceeded to bark and jump up on him. The boy was not visibly hurt, so it was a surprise when a few hours later, his mother (who had not been present) had Rowdy arrested and registered as a “potentially dangerous dog.” Poor Rowdy had to be muzzled on walks for several years afterward. And if Rowdy ever again jumps up on someone, he will be registered as vicious and maybe even put down. The boy was afraid of Rowdy and perceived him as angry and dangerous. When you encounter a dog who barks and growls, does he actually feel anger? Or is this merely territorial behavior, or an overly boisterous attempt to be friendly? In short, can dogs experience emotion? Common sense seems to say yes, of course, Rowdy feels emotion when he growls. Numerous popular books explore the issue, like The Emotional Lives of Animals by Marc Bekoff, Animal Wise by Virginia Morell, and How Dogs Love Us by Gregory Berns, to name just a few. Dozens of news stories inform us of scientific discoveries in animal emotion: dogs get jealous, rats experience regret, crayfish feel anxiety, and even flies fear the incoming fly swatter. And of course, if you live with pets, you've certainly seen them behave in ways that seem emotional: running around in fear, jumping up in joy, whining in sadness, purring with love. It seems so obvious that animals experience emotions just the way we do.* Carl Safina, author of Beyond Words: What Animals Think and Feel, puts it succinctly: “So, do other animals have human emotions? Yes, they do. Do humans have animal emotions? Yes, they're largely the same.”1 Figure 12-1: Rowdy Some scientists are not so sure. They suggest that emotions in animals are just illusions: that Rowdy has brain circuits that trigger behaviors for survival but not for emotion. From their perspective, Rowdy can approach or withdraw in dominance or submission, to defend his territory or to avoid a threat. In these instances, the argument goes, Rowdy might experience pleasure, pain, arousal, or other varieties of affect, but he does not have the mental machinery to experience more than that. This latter explanation is deeply unsatisfying because it denies our own experiences. Millions of pet owners would bet money that their dogs growl in anger, droop in sadness, and hide their heads in shame. It's hard to conceive that these perceptions are illusions built around some general affective responses. I myself have succumbed to the allure of animal emotions. For years, my daughter has maintained a herd of guinea pigs in her bedroom. One day, we acquired a small baby, Cupcake. Every night for the first week, all by herself in a strange pen, Cupcake sounded like she was crying. I'd carry her around in my sweater pocket, all warm and cozy, which made her chirp with happiness. Whenever I approached the cage, the other pigs would squeal and run away, but little Cupcake would sit still as if waiting for me to pick her up, and then immediately crawl into the crook of my neck for a nuzzle. In those moments, it was very hard to resist the belief that she loved me. For many months, Cupcake was my late-night companion. She would nestle in my lap, purring, as I worked at my desk. Everyone in our house suspected that Cupcake was actually a puppy trapped in a guinea pig's body. And yet, as a scientist, I knew that my perceptions did not necessarily reveal what little Cupcake was actually feeling. In this chapter, we'll systematically explore what animals are capable of feeling, based on their brain circuitry and on experimental research. We'll have to set aside our fond feelings for our pets, as well as the essentialist theory of human nature, to look carefully at the evidence. Scientists pretty much agree that many of the earth's animals, from insects to worms to humans, share the same basic nervous system plan. They even agree, more or less, that animal brains were built according to the same general blueprint. But as anyone who has renovated a house has learned, the devil is in the details when translating a blueprint into reality. When it comes to comparing brains of different species, even if they have the same networks of regions, microscopic differences in wiring are sometimes as important as these large- scale similarities. The theory of constructed emotion prompts us to ask whether animals have three necessary ingredients for making emotion. The first ingredient is interoception: do animals have the neural equipment to create interoceptive sensations and experience them as affect? The second is emotion concepts: can animals learn purely mental concepts like “Fear” and “Happiness,” and if so, can they predict with these concepts to categorize their sensations and make emotions like ours? Finally, there's social reality: can animals share emotion concepts with each other so they are passed down to the next generation? To see what animals are capable of feeling, we'll focus primarily on monkeys and great apes because they're our closest evolutionary cousins. In the process, we'll discover whether animals share the kinds of emotions that we feel . . and the answer has an unexpected twist. All animals regulate their body budget to stay alive, so they all must have an interoceptive network of some sort. My lab, together with neuroscientists Wim Vanduffel and Dante Mantini, set out to verify this network in macaque monkeys and were successful. (Macaques and humans shared their last common ancestor about 25 million years ago.) The macaque interoceptive network has some of the same parts as the human interoceptive network we discovered, as well as some differences. The macaque network is structured to function by prediction in the same way that the human network does. Macaques also likely experience affect. They can't tell us verbally how they feel, of course, but one of my former doctoral students, Eliza Bliss- Moreau, has evidence that they show the same bodily changes in the same situations that we humans do when we feel affect. Eliza studies macaques at the California National Primate Research Center at the University of California, Davis. Her monkeys watched three hundred videos of other monkeys playing, fighting, sleeping, and so on, while Eliza tracked their eye movements and cardiovascular responses. She found that the activity in the monkeys' autonomic nervous system mirrored what a human's would do when viewing these videos. In humans, this nervous system activity is related to the affect they feel, suggesting that macaques experience pleasant affect when watching positive behaviors like foraging and grooming, and unpleasant affect when watching negative behaviors like cowering. Based on these and other clues from biology, macaques pretty definitely process interoception and feel affect, and if that's the case, then great apes such as chimpanzees, bonobos, gorillas, and orangutans surely feel affect as well. As for mammals in general, it's harder to say for sure. They undoubtedly feel pleasure and pain, as well as alertness and fatigue. Many mammals have circuitry that looks similar to ours but has different functions, so we can't answer the question just by examining the wiring. No one, to my knowledge, has specifically studied the interoceptive circuitry of dogs, but it seems pretty clear from their behavior that they have an affective life. And how about birds, fish, or reptiles? We don't know for sure. I have to admit that these questions preoccupy me as a civilian (as my husband calls me in non-scientist moments). I can't shop for meat or eggs in a supermarket or attempt to rid my kitchen of bloody irritating fruit flies without asking myself . . what do these creatures feel? I think it's best to assume all animals can experience affect. I realize this discussion has the potential to transport us from the land of science to the land of ethics, coming perilously close to moral issues such as pain and suffering in laboratory animals, creatures who are factory-farmed for food, and whether fish feel pain when a hook enters their mouth. The natural chemicals that relieve suffering within our own nervous systems, opioids, are found in fish, nematodes, snails, shrimps, crabs, and some insects. Even tiny flies might feel pain; we know that they can learn to avoid odors that are paired with electric shock. The eighteenth-century philosopher Jeremy Bentham thought that an animal belongs in the human moral circle only if we can prove the animal can feel pleasure or pain. I disagree. An animal is worthy of inclusion in our moral circle if there is any possibility at all that it can feel pain. Does that keep me from killing a fly? No, but I'll make it quick. Macaques do have an important difference from humans where affect is concerned. Many, many objects and events in your world, from the tiniest insect to the largest mountain, cause fluctuations in your body budget and change your affective feelings. That is, you have a large affective niche. Macaques, however, don't care about as many things as you and I do. Their affective niche is much smaller than ours; the sight of a majestic mountain rising in the distance doesn't impact their body budget in the least. Simply put, more things matter to us. An affective niche is one area of life where size truly matters. In the lab, if we present a human toddler with a collection of toys, they are usually within her affective niche. My daughter, Sophia, would sort her toys by shape, by color, by size, for the sheer fun of it, over and over, statistically honing the various concepts involved. Not so with macaques. The toys alone are uninteresting and don't impact the macaque body budget or prompt the monkeys to form concepts. We must offer the macaque a reward of some kind, like a tasty drink or treat, to bring the toys into the macaque's affective niche so statistical learning can proceed. (Eliza tells me that favorite monkey treats include white grape juice, dried fruit, Honey Nut Cheerios, grapes, cucumbers, clementines, and popcorn.) Repeat the reward enough times and the macaque will learn similarities among the toys. A human infant also receives rewards from his human caregivers: not just tasty treats like breast milk or formula but also the day-to-day effects of tending to his body budget. His caregivers become part of his affective niche because they feed him, keep him warm, and so on. He is born with rudimentary concepts for his mother's scent and voice, learned in utero. In the first few weeks of life, he learns to integrate his mother's other perceptual regularities, such as the feel of her touch and eventually the sight of her face, because she is regulating his body budget. She and other caregivers also guide the infant's attention to things of interest in the world. He follows their gaze to an object (say, a lamp), then they look at him, then at the lamp again, and talk about what he is looking at. They say the word “lamp” to him with intent, alerting and orienting him with a “baby talk” tone of voice. Other primates do not share attention like this, and so they cannot use it to regulate each other's body budgets the way that humans do. A mother macaque may follow her infant's gaze, but she will not look back and forth from the object to the infant's face, as if inviting her baby to wonder what is in her mind. Baby primates do learn concepts without the explicit reward of their mother's presence, but not with the range and diversity that baby humans do. Why do humans and macaques have such differently sized affective niches? For starters, a macaque's interoceptive network is less developed than a human's, particularly the circuitry that helps control prediction error. This means a macaque is not as nimble in directing attention to stuff in the world based on past experience. More importantly, a human brain is almost five times as large as a macaque brain. We have much greater connectivity in our control network and in parts of our interoceptive network. The human brain employs this heavy-duty machinery to compress and summarize prediction error in the way we discussed in chapter 6. This allows us to integrate and process more sensory information from more sources more efficiently than a macaque can, to learn purely mental concepts. That's why you can have majestic mountains in your affective niche and a macaque cannot. An interoceptive network, along with the affective niche it helps create, is not sufficient for feeling and perceiving emotions. For that, a brain must also be equipped to build a conceptual system, to construct emotion concepts, and to make sensations meaningful as emotions in themselves and others. A hypothetical macaque with the capacity for emotions must be able to look at another macaque swinging in a tree and see not only the physical movement but an instance of “Joy.” Animals can definitely learn concepts. Monkeys, sheep, goats, cows, raccoons, hamsters, pandas, harbor seals, bottlenose dolphins, and plenty of other animals learn concepts by smell. You might not think of smell as conceptual knowledge, but each time you smell the same aroma, such as popcorn in a movie theater, you're categorizing. The mix of chemicals in the air differs each time, and yet you perceive buttered popcorn. Similarly, most mammals use olfactory concepts to recognize friends, foes, and offspring. Many other animals learn concepts by sight or sound as well. Sheep apparently recognize one another by face (!), and goats by vocal bleats. In the lab, animals can learn additional concepts if you reward them with food or drink, widening their affective niche. Baboons can learn to distinguish a “B” from a “3” regardless of font, and macaques can distinguish animal images from food images. Rhesus macaques can learn the concept “Rhesus macaque” as distinct from “Japanese macaque,” even though they are the same species and differ only by color. (Does this remind you of something that humans do?) Macaques can even learn concepts to distinguish painting styles by Claude Monet, Vincent van Gogh, and Salvador Dalí. The concepts that animals learn will not be the same as human concepts, however. Humans construct goal-based concepts, and a macaque brain simply lacks the necessary wiring to do so. It's the same lack of wiring that accounts for their smaller affective niche. What about apes-can they construct goal-based concepts? Chimpanzees, our genetically closest cousins, have larger brains than macaques do, with more of the wiring necessary for integrating sensory information. A human brain is still three times as large as a chimp brain, though, with more of this critical wiring. That doesn't rule out goal-based concepts for chimps. It's just likely that your brain is better equipped to create purely mental concepts, such as “Wealth,” whereas a chimpanzee brain is better equipped to create concepts for actions and concrete objects, like “Eating” and “Gathering” and “Banana.”14 Apes almost certainly have concepts for physical behaviors, such as swinging from branch to branch. The big question is, can one chimp watch another chimp swinging in a tree and perceive an instance of “Joy”? That would require the observing chimp to have a purely mental concept and infer the swinging chimp's intention, making a mental inference. Most scientists assume that mental inference is a core ability of the human mind. So a lot is at stake if apes can do it. We know that monkeys cannot; they can understand what a human is doing but not what he is thinking, desiring, or feeling. Where apes are concerned, it's conceivable they could make mental inferences and construct goal-based concepts, but the scientific jury is still out. Chimps might have the prerequisites because they can create some mental similarities amid perceptual differences. For instance, they know that leopards climb trees, snakes climb trees, and monkeys climb trees. It's conceivable that chimps could extend this concept to a new animal who can perform a similar action, such as a housecat, and predict that the cat will climb a tree. But a human concept “To Climb” is more than just an action; it's a goal. So the real test would be whether chimps would understand that a person running up a flight of stairs, ambling up a ladder, and crawling up a rock face all share the goal “To Climb.” That mental feat would show us that chimps really can go beyond physical similarities, grouping together instances of climbing that look very different but have a shared mental goal. And if chimps could comprehend that moving up a social hierarchy is also climbing, then their concepts would be identical to our own. Human infants can accomplish such feats, as we learned in chapter 5, if they have a word to represent the concept. The next question, then, is whether great apes have the capacity to learn words and use them for learning concepts in the way that human infants do. Scientists have been trying to teach language to apes since the 1960s, usually with a visual symbol system such as American Sign Language because their vocal machinery is not well-adapted for human speech. Apes can learn to use hundreds of words or other symbols to refer to particular features of the world if there is a reward along the way. They can even combine symbols to communicate complex requests for food, such as “cheese eat-wanting to” and “gum hurry-wanting to have some.” Scientists still debate whether these apes understand the meanings of the symbols or are just mimicking their trainers in order to request rewards. For our purposes, the most important questions are whether great apes can learn and use words or symbols under their own steam, without an explicit reward, and whether they can build purely mental concepts like “Wealth” or “Sadness.”17 So far, we have very little evidence that apes can learn and use symbols on their own. They appear to have only one such concept that they can map to a symbol without requiring an external reward: “Food.” But when apes do learn to use a word, do they take the next step? Do they use a word as an invitation to go beyond what they see, hear, touch, and taste to infer the mental? We don't know yet. Words certainly don't prompt apes to search the minds of other creatures for concepts the way a human infant does. But there are intriguing possibilities. For example, it appears that chimps can categorize dissimilar-looking objects according to their function-tools, containers, food -if you reward them, and if they already have firsthand experience with the function. Moreover, if you teach and reward them to associate a symbol with a category like “Tool,” they can match the symbol to unfamiliar tools. Do apes use words in this way only to request rewards? Skeptics point out that apes certainly don't use symbols or words to talk about the weather or their children; they can refer to something other than a reward, but only if a reward is waiting at the other end. (It would be interesting to observe what would happen to symbol-trained apes if their trainers stopped rewarding them. Would they continue to use the symbols?) The important point, I think, is that words don't seem to be intrinsically part of most apes' affective niche, as they are for typical human babies. To apes, words alone are not worth learning. One important exception to this story might be bonobos. They are very social creatures, far more egalitarian and cooperative than common chimps. They also have a larger social network and play longer before assuming adult roles. And some bonobos appear able to complete tasks without external rewards, whereas chimps seem to require them. Take the story of Kanzi, an infant bonobo who watched his stepmother and other adult bonobos earn food rewards for learning language-like symbols. By six months old, Kanzi appeared to be learning the symbols too, on his own, by watching other bonobos earn rewards. At a certain point, the scientists realized with careful testing that Kanzi appeared to understand some spoken English. So it is possible that a bonobo brain, immersed in a language-rich environment, can learn the meaning of concrete words. Chimps, in contrast to bonobos, have been characterized as charming, clever creatures with a dark side. They hunt and kill each other opportunistically to take over territory or get food. They also attack strangers for no reason, maintain a rigid dominance hierarchy, and beat females into sexual submission. Bonobos would rather work out their conflicts by having sex. That's a much better alternative than genocide. Nevertheless, chimps may have been given a bad rap in the lab when it comes to concept learning. Chimps in language experiments were removed from their mothers in infancy and raised in a human-like environment vastly different from their natural habitat. These infants would normally live with their mother for up to ten years and nurse with them for five, so this premature separation could have changed the wiring of each chimp's interoceptive network and strongly influenced the results of the experiments. (Imagine separating a human infant from his mother like this!)21 When tested under more natural circumstances, a chimp's affective niche appears to be broader than many experiments suggest. For this insight, we have to thank the primatologist Tetsuro Matsuzawa at Kyoto University's Primate Research Institute. Matsuzawa has accomplished a truly impressive task. He has three generations of chimps who live in an outdoor compound built to look like a forest. Each day, chimps come to the lab by choice to do experiments. Sometimes they are rewarded, of course, but to emphasize this is to miss the point. These animals have a long-term, trusting relationship with Matsuzawa and the other human experimenters at the institute. A mother chimp will hold her baby on her lap and allow a human to run an experiment with her infant. For example, one study tested human and chimp infants as they learned concepts for mammals, furniture, and vehicles (using lifelike miniatures). This learning proceeded with no rewards as each infant was tested while sitting on his or her mother's lap. The infant's proximity to the mother, in relation to the trusting bond with the human experimenter, may have been enough to bring this situation into the chimp infant's affective niche. Incredibly, the chimp and human infants formed concepts equally well under these conditions. Still, the human infants spontaneously manipulated the objects, like moving toy trucks around, making concept formation more likely, whereas the chimps did not. Matsuzawa's troupe would be ideal for learning the limits of a chimp's conceptual abilities. We could test infant chimps, whose conceptual systems are still malleable, in a natural environment on their mothers' laps, perhaps conducting concept-building experiments like those in chapter 5. Would chimp infants be able to use a nonsense word like “toma” to group together objects or images that share little perceptual similarity, as human infants can? At present, however, we have no firm evidence that chimps can form goal- based concepts. They cannot imagine something completely novel, like a flying leopard, even though they and macaques have a network that's analogous to the human default mode network (part of the interoceptive network). They cannot consider the same situation from different points of view. They can't imagine a future that is different from the present. They also do not realize that goal-based information resides inside the heads of other creatures. That's why chimps and other great apes most likely cannot create goal-based concepts. When rewarded, apes can learn a word, but they cannot spontaneously use the word to form a mental concept with a goal, like “Things That Taste Good with Termites.”23 Any concept can be goal-based-recall that “Fish” can be a pet or a dinner -but emotion concepts are only goal-based, so it seems very likely that chimps cannot learn emotion concepts like “Happiness” and “Anger.” Even if they can learn an emotion word like “angry,” it's not clear that they can understand it or use it in a goal-based way, like categorizing another creature's actions as anger. Sometimes apes appear to understand a purely mental concept when they do not. In one experiment, chimps earned tokens for completing tasks and could exchange them for food. They spontaneously learned to save up their tokens to exchange them for a desired treat. When you watch chimps engage in this transaction, it is tempting to infer that chimps understand the concept “Money.” But here, the token was just a tool for obtaining food, rather than a form of currency that's exchangeable for goods in general. The chimps did not understand, as many humans do, that money comes to have value for its own sake. If chimps cannot form goal-based concepts, then necessarily, chimps are not naturally equipped to teach concepts to one another; that is, they don't have social reality. Even if they could learn a concept like “Anger” from a human trainer, one generation doesn't create the context for the next generation to bootstrap concepts into their brains. Chimps and other primates do have shared practices, like cracking nuts with rocks, but chimp mothers don't spontaneously instruct their infants on the finer culinary points; the children learn by observation. For example, in a troop of macaques in Japan, one member began washing her food before eating it, and within ten years, three-quarters of the adults in her troop had picked up the practice. This sort of collective intentionality is very limited compared to what we humans do with words and the mental concepts that we invent. The human capacity for social reality appears unique in the animal kingdom. Only we can create and share purely mental concepts using words. Only we can use these concepts to more effectively regulate our own body budgets and each other's, while we cooperate and compete with one another. Only we have concepts for mental states, such as emotion concepts, for predicting and making sense of sensations. Social reality is a human superpower. Which brings us back to Matsuzawa and his chimps. It is remarkable how he nestled a chimp troupe, preserving its family relationships, into human culture in an intimate way. I wonder whether, over time, Matsuzawa's very human cultural context will influence the brain development of the infant chimps, as they are raised by mothers who are acculturated by a group of trusting, loving humans. One example that I find particularly striking, relayed by Virginia Morell in her book Animal Wise, describes two human experimenters who provide social support to a nursing mother chimp. The mother is reluctant to nurse her infant, but the experimenters gently encourage her to be brave. In Morell's words, “A researcher gently picks up the baby and places it in the mother's arms. The infant's hands latch on to her fur. The mother then attempts to nurse but cries when the baby takes her nipple; she seems about to drop her infant to the floor. But then the soft voice of the scientist is heard again. Yes, yes, he says soothingly, it may hurt at first, but soon it will not. And slowly the mother settles down, cradling her baby against her breast and letting the infant nurse.” Thousands of human mothers each day experience nursing for the first time, and I can tell you from experience that it hurts like hell. But someone else (a nurse, an older female relative, or a friend) offers supportive encouragement and shows you what to do, and eventually all is well. To the mother chimp, these helpful humans are not merely her caretakers: they are affectively salient to her, regulating her body budget. She and her infant and their relationship are being bathed in human culture. Will this social contact make a difference to the language and conceptual abilities of these chimps long-term? If their offspring eventually become able to form goal-based concepts, it's a whole new ballgame. Okay, so chimps and other primates don't appear to have emotion concepts or social reality. How about dogs like Rowdy? After all, we have bred dogs to be human companions, so they, like us, are truly social creatures. If any non- human animals were to be capable of emotion, dogs would seem to be prime candidates. Just a couple of decades ago, it took the Russian scientist Dimitri Belyaev only about forty generations to transform wild foxes into something that approximated domesticated dogs. Each time female foxes gave birth, Belyaev chose the fox pups who were most interested in and least aggressive toward humans and selectively bred them. The experimentally bred beasts looked like dogs; their skulls were shorter and they had wider muzzles, curly tails, and floppy ears, even though Belyaev did not select for these features. Their chemical makeup was closer to dogs than foxes. And they had a strong motivation to interact with humans. Modern dogs also have long been bred for certain desirable characteristics, like attaching to a human caregiver, and other characteristics surely have come along for the ride, perhaps even something like human emotion concepts. One of those inadvertently bred characteristics, I speculate, is a certain kind of dog nervous system. We can regulate a dog's body budget, and dogs can regulate ours in turn. (I wouldn't be surprised if dogs and their human owners even synchronize their heart rates, the way close humans do for each other.) We also probably selected for dogs with eyes that we perceive as expressive and facial muscles that move easily to serve as a canvas upon which we can paint complex mental states. We love dogs so much that we bred them to love us back, or at least to see them as loving us. We treat them as little almost- humans with four legs and a fur coat. But do dogs experience or perceive human emotion?29 Dogs, like other mammals, feel affect. No big surprise here. One way they appear to express affect is by wagging their tails. They apparently make larger tail-wagging movements to the right during pleasant events, such as seeing their owner, and to the left for unpleasant events, such as seeing an unfamiliar dog. The choice of side has been associated with brain activity: wagging to the right is said to mean relatively greater activity on the left side of the brain, and vice versa. Dogs also appear to look at each other's tails to perceive affect. They're more relaxed when they view movies of right-wagging tails and more stressed for left-wagging tails, as measured by heart rate and other factors. Dogs also appear to perceive affect in the faces and voices of humans. I haven't come across any relevant brain-imaging experiments on dogs, but if they have affect, it stands to reason that they have some sort of interoceptive network. Just how large their affective niche is no one knows, but given their social nature, I'll bet it is yoked to their owners in some way. Dogs can learn concepts too. Again, not surprising. They can distinguish dogs from other animals in photographs, for example, if trained to do so. It takes them a thousand or more trials to get the knack of it, compared to human infants who need only a few dozen trials. But dogs can learn to be accurate over 80 percent of the time, even if the dog in the photo is completely new or embedded in a complex scene. Not bad for a dog brain. Dogs also form olfactory concepts. They can distinguish the smell of an individual human, grouping together different smells from different parts of the body to treat as equivalent, and yet distinct from the smells of other humans. And of course, we know that dogs can be trained to track categories of objects by smell. Anyone who's been caught in an airport with food or drugs in their suitcase can tell you so. I will gingerly concede that dogs appear to infer intentions of some sort. Dogs are better than chimps at perceiving human gestures and following human gaze. When Sophia was younger and would play in the sand with her favorite beach dog, Harold, the two of them often looked to a human adult for permission to run farther away: Sophia to me and Harold to his owner. Dogs use our gaze to tell them what to attend to, and their skill is so great that they seem to read our mind in our eyes. Even more remarkably, dogs follow each other's gaze to get information about the world. When Rowdy wants to know what's going on, he spontaneously looks to his “sister,” Biscuit, a Golden Retriever, and follows her gaze. The two of them freeze as they reference each other, and then . . they both suddenly leap into action. It's like watching a silent movie. But being the skeptic that I am, I have my doubts that dogs are making goal-based mental inferences. They could be just really good at perceiving human actions, because, let's be honest, we've bred them to be sensitive to our every whim. Dogs do appear to understand that humans use symbols to communicate intent. For example, in one study, an experimenter put dog toys in different rooms and then used miniature replicas of the toys as symbols. Her test subjects (Border Collies) understood she was asking them, via the miniature, to retrieve the matching toy from the other room. This is rather more sophisticated than playing fetch. Studies also show that dogs use different growls and barks to communicate with each other, although they might just be communicating arousal (affect) in the acoustic signal. One study even shows that a dog named Sofia, like our chimp friends, could be trained to press symbols on a keyboard to communicate a few basic concepts: a walk, toy, water, play, food, and her crate. Clearly, dogs have something nontrivial going on upstairs, but even so, scientists have no indication yet that dogs have emotion concepts. In fact, there's pretty good evidence that they don't, though many dog behaviors look emotional. Dog owners, for example, infer guilt when they believe their dog is hiding something (for example, avoiding eye contact) or is being submissive (such as drooping the ears, lying down and showing the belly, or holding the tail low). But do dogs have a concept of guilt? A clever study investigated this question. In each trial, a dog owner offered his or her dog a desirable biscuit, then explicitly instructed the dog not to eat it and promptly left the room. Unbeknownst to the owner, however, an experimenter then entered the room and influenced the dog's behavior, either handing the treat to the dog (who ate it) or removing the treat from the room. Afterward, the experimenter either told the owner the truth or lied. Half the owners were told that their dog had obeyed and to greet their dog in a warm and friendly manner; the rest heard that the dog had eaten the biscuit and should be scolded. This created four different scenarios: obedient dog with a friendly owner, obedient dog being scolded, disobedient dog with a friendly owner, and disobedient dog being scolded. What happened? The scolded dogs performed more behaviors that people perceive as stereotypically guilty, regardless of whether or not the dogs had disobeyed. This is evidence that dogs were not experiencing guilt at performing a forbidden act; rather, their owners were perceiving guilt when they believed the dog had eaten the biscuit. Another study looked at jealousy in dogs, asking owners to interact with a toy dog while the real dog watched. The toy barked, whined, and wagged its tail. The study found that dogs in this situation would snap, whine, push at the owner and the toy, and insert themselves between the owner and the toy, more often than when the owner interacted with a different toy (a jack-o-lantern) or read a book. The authors interpreted these findings to mean that the dogs were jealous, particularly because many of the dogs tested sniffed the anus of the toy dog. Unfortunately, the experimenters did not test to see if the owners were behaving differently in the three conditions (toy dog, jack-o-lantern, and reading) in any way that could account for the dogs' behavior. They assumed that the owner's behavior was identical, and that the dog understood that jealously was called for in only one condition. So even though many pet owners are confident that their dogs experience jealousy, we have no scientific evidence to support this belief. Scientists are still exploring the limits of what dogs can do, emotionally speaking. Their affective niche is broader than ours in some respects, because their senses of smell and hearing are superior; but their affective niche is narrower in other respects, because they can't travel into the future to imagine a world other than the present one. My view, from evaluating the evidence, is that dogs don't have human emotion concepts like anger, guilt, and jealousy. It's conceivable that one individual dog could develop some emotion-like concept of its own, different from any human emotion concept, in relation to its owner. Without language, however, the dog's emotion concept would necessarily be narrower than a human's, and it couldn't teach the concept to other dogs. So the possibility of a common “Anger” (or similar concept) experienced by dogs is vanishingly remote. Even if dogs don't share human emotions, it's remarkable just how much dogs and other animals can accomplish through affect alone. Many animals can experience unpleasant affect when another animal nearby is suffering. The first animal's body budget is taxed by the second animal's discomfort, so the first animal tries to fix the situation.* Even a rat will help another rat who is in distress, for example. Human infants can comfort another infant who is in distress. You don't need emotion concepts for this ability, just a nervous system with interoception that produces affect. Amid the accumulating evidence that dogs have some truly remarkable skills, we still severely misunderstand dogs. We see them relative to ourselves, using the outmoded essentialist theory of human nature, instead of seeing them on their own terms. John Bradshaw, the author of Dog Sense, explains that we view dogs wrongly as having a dominance-seeking “inner wolf” that needs to be tamed by a civilizing force, their owners (an intriguing parallel to our own mythical inner beast that must be tamed by rationality). Dogs are extremely social creatures, continues Bradshaw, as are wolves in the wild when you don't toss them into zoos with a bunch of strangers. Put a few dogs together in a park and in a few moments they're playing together. What looks like dominance in dogs is what Bradshaw calls “anxiety,” and what we'd say is a body budget that's out of balance. Think about it: we take an affiliative, affectionate creature whose body budget we regulate, and we abandon it for most of every day. (Can you imagine doing that to a human child?) Of course their body budget will get out of whack and they'll feel high-arousal, unpleasant affect. We've bred them to be affectively dependent on us. So owners must take care with their dogs' body budget. Dogs might not feel fear, anger, and other human emotions, but they do experience pleasure, distress, attachment, and other affective feelings. But for dogs to be successful as a species, living cooperatively with their human companions, affect may be enough. Let's recap where we are. Do animals regulate their body budgets by interoception? I cannot speak for the entire animal kingdom here but for mammals-rats, monkeys, apes, dogs-I think we are on pretty safe ground answering yes. Do animals experience affect? Again, I think we can give a pretty confident yes, based on some biological and behavioral clues. Can animals learn concepts and can they categorize predictively with those concepts? Definitely. Can they learn action-based concepts? Unquestionably yes. Can they learn the meaning of words? Under some circumstances, some animals can learn words or other symbol systems, in the sense that the symbols become part of the statistical patterns that a brain can capture and store for later use. But can animals use words to go beyond the statistical regularities in the world, to create goal-based similarities that unite actions or objects that look, sound, or feel different? Can they use words as invitations to form mental concepts? Do they realize that part of the information they need about the world resides in the minds of other creatures around them? Can they categorize actions and make them meaningful as mental events? Probably not. At least not in the way that we humans do. Apes can construct categorizations that are more similar to our own than we might have imagined. But right now, there is no clear evidence that any non-human animals on the planet have the sorts of emotion concepts that humans do. We alone have all the ingredients necessary to create and transmit social reality, including emotion concepts. This holds true even for Man's Best Friend. So, let's return to Rowdy: was he angry when he growled and jumped up on the boy? Based on our discussion so far, Rowdy lacks emotion concepts, so you might guess that my answer is no. Well, not exactly. (Get ready for that twist I mentioned at the beginning of the chapter.) From the perspective of the theory of constructed emotion, the question “Is a growling dog angry?” is the wrong question to ask in the first place, or at least incomplete. It assumes that a dog is measurably angry or not angry in some objective sense. But as you've learned, emotion categories have no consistent, biological fingerprints. Emotions are always constructed from some perceiver's point of view. So the question “Was Rowdy angry?” is actually two separate scientific questions: “Was Rowdy angry from the boy's perspective?” “Was Rowdy angry from his own perspective?” These questions have substantially different answers. The first question asks, “Could the boy construct a perception of anger from Rowdy's actions?” Absolutely. When we observe a dog's behavior, we use our own emotion concepts to make predictions and construct perceptions. Rowdy was angry, from a human perspective, if the boy constructed a perception of anger. Was the boy correct in his assessment? Accuracy for categories of social reality, you may remember, is a matter of consensus. Let's say that you and I are walking past Rowdy's house and he growls loudly. You experience him as angry. I don't. Accuracy could be: Do we agree? Do our experiences of Rowdy agree with his owner Angie's experience, as she knows him best? Do our experiences of Rowdy match the social norms of the situation, because this is social reality after all? If we agree, then our constructions are in sync. Now let's consider the second question, regarding Rowdy's experience. Did he feel anger when he growled? Was he able to construct an experience of anger from his sensory predictions? The answer is almost certainly no. Dogs do not have the human emotion concepts necessary to construct an instance of anger. Lacking a Western concept of “Anger,” dogs cannot categorize their interoceptive and other sensory information to create an instance of emotion. Nor can they perceive emotion in other dogs or in humans. Dogs do perceive distress and pleasure and a handful of other states, a feat that requires only affect. Dogs may well have some emotion-like concepts. For example, a number of scientists now suspect that very social animals, such as dogs and elephants, have some concept of death and can experience some kind of grief. This grief need not have exactly the same features as human grief, but both could be rooted in something similar: the neurochemical basis of attachment, body budgeting, and affect. In humans, the loss of a parent, lover, or close friend can wreak havoc with your budget and cause much distress that operates similarly to drug withdrawal. When one creature loses another who helped to keep its body budget on track, the first creature will feel miserable from the budget imbalance. So Brian Ferry of the rock band Roxy Music was right- love is a drug. Rowdy's misadventure has a backstory that may have affected his behavior on that fateful day. Earlier that week, before his arrest, Rowdy lost his “sister” Sadie, a Golden Retriever who died of old age. Their owner Angie believes this is why Rowdy jumped up on the boy that day. She said Rowdy was grieving, which in canine terms means he lost a creature who helped to regulate his body budget, and he temporarily forgot his training. Rowdy knows he is not supposed to jump, but maybe he just wasn't himself that day -whatever self a dog can have. There are anecdotal reports of dogs who stop eating or become apathetic after the death of another dog in the family. Some people see these cases as evidence of grief in dogs, but they also could be understood more simply as an effect of body-budget imbalance, accompanied by unpleasant affect. After all, Angie was probably grieving Sadie's death, and Rowdy, being very sensitive to her behavior, could have detected some affective change in her, throwing off his own budget even more. Dividing our growling dog question into two questions, reflecting human and canine perceptions separately, is not a parlor trick. I'll admit, the distinctions I'm making here are subtle. Construction views of emotion are frequently misinterpreted as saying “dogs don't have emotions” (and sometimes even “people don't have emotions”). Such simplistic statements are meaningless because they assume emotions have essences so that they can exist, or not, independent of any perceiver. But emotions are perceptions, and every perception requires a perceiver. And therefore every question about an instance of emotion must be asked from a particular point of view. If apes, dogs, and other animals don't have the capacity to experience human emotions, why are there so many news stories about emotions being discovered in animals, even in insects? It all comes down to a subtle mistake that's repeated over and over in science, and which is very difficult to detect and overcome. Picture this: a rat is placed into a small box with an electrical grid on the floor. Scientists play a loud tone and then a moment later give the rat an electrical shock. The shock causes the rat to freeze and its heart rate and blood pressure to rise, as it stimulates a circuit that involves key neurons in the amygdala. The scientists repeat this process many times, pairing the tone and the shock, with the same results. Eventually, they play the tone without the shock, and the rat, having learned that the tone foreshadows the shock, again freezes and has increased heart rate and blood pressure. The rat's brain and body respond as if expecting the shock. Scientists who adhere to the classical view say that the rat has learned to be afraid of the tone, calling this phenomenon “fear learning.” (This is the same type of experiment performed on SM, the woman with no amygdala who allegedly couldn't learn fear, as described in chapter 1.) All over the world, for decades, scientists have been shocking rats, flies, and other animals to map how neurons in the amygdala allow them to learn to freeze. Having identified this freezing circuit, scientists then infer that the amygdala contains a fear circuit-the essence of fear-and the increased heart rate, blood pressure, and freezing is said to represent a consistent, biological fingerprint for fear. (I've never been sure why they decided it's fear. Couldn't the rat be learning surprise, or vigilance, or maybe just pain? If I were the rat, I'd be pretty pissed off about the shocks, so why isn't it “anger learning”?)41 Anyway, these scientists go on to say that their fear learning analysis extends from rats to humans, because the relevant fear circuitry in the amygdala has been passed to us through mammalian evolution à la the “triune brain.” These fear learning studies helped to establish the amygdala as the supposed brain location of fear. In psychology and neuroscience, so-called fear learning has become an industry. Scientists use it to explain anxiety disorders like post-traumatic stress disorder (PTSD). It's employed to aid with drug discovery in the pharmaceutical industry and to understand sleep disturbance. With over 100,000 hits on Google, “fear learning” is one of the most commonly used phrases in psychology and neuroscience. And yet, under the hood, fear learning is just a fancy name for another well-known phenomenon: classical conditioning or Pavlovian conditioning, named after the physiologist Ivan Pavlov, who discovered it with his famous experiments on salivating dogs.* The classic fear learning experiment demonstrates that a benign stimulus, such as a tone, can acquire the ability to trigger certain amygdala circuitry in anticipation of uncertain danger. Scientists have spent years mapping this circuitry in elegant detail. Now comes the subtle mistake I alluded to. Freezing is a behavior, whereas fear is a much more complex mental state. The scientists who believe they study fear learning are categorizing a freezing behavior as “Fear” and the underlying circuit for freezing as a fear circuit. Just as I categorized Cupcake the guinea pig as happy, when she herself couldn't construct an experience of happiness, these scientists unknowingly apply their own emotion concepts, construct perceptions of fear, and attribute fear to the freezing rat. I call this general scientific mistake the mental inference fallacy. Mental inference is normal; we all do it every day, automatically and effortlessly. When you see a friend smile, you might instantly infer that she is happy. When you see a man drinking a glass of water, you might infer that he's thirsty. Alternatively, you might infer that he's feeling dry-mouthed anxiety or pausing dramatically before making a point. When you're on a lunch date and you feel hot and flushed, you might infer that it's caused by romantic feelings or by a case of the flu. Children of course perceive emotions in their toys and their security blankets and have fascinating two-way conversations with them, but adults are also experts in this regard. In a famous experiment from the 1940s, Fritz Heider and Mary-Ann Simmel created a simple animation of geometric shapes to see if viewers would infer mental states. The video features two triangles and a circle moving around a large rectangle. The video contains no sound and no explanation for the movements. Even so, viewers readily assigned emotions and other mental states to the shapes. The large triangle, some said, was bullying the small, innocent triangle until the brave circle came to the rescue. Figure 12-2: Still image from a Heider-Simmel video available at heam.info/heider-simmel Scientists, as members of the human species, make mental inferences when interpreting the findings of their own experiments. In fact, every time scientists record a physical measurement and assign it a mental cause, they commit the mental inference fallacy. “That change in heartbeat was caused by excitement.” “That scowl is expressing anger.” “That activity in the anterior insula was caused by disgust.” “That test subject pressed the computer key slightly faster because of anxiety.” Emotions do not cause these actions in any objective, perceiver-independent sense. These actions, on their own, are surely evidence that something psychological has occurred, but the scientists are guessing what it is. That is what scientists do: we measure stuff, and then we transform the pattern of numbers into something meaningful by making an inference. But when scientific explanation is your goal, some inferences are better than others. The fear learning phenomenon is the most dramatic example of the mental inference fallacy in the science of emotion.* Its practitioners blur the important distinction among movement, behavior, and experience. Contracting a muscle is a movement. Freezing is a behavior because it involves multiple, coordinated muscle movements. The feeling of fear is an experience that may or may not occur together with behaviors like freezing. Circuitry that controls freezing is not circuitry for fear. This egregious scientific misunderstanding, along with the phrase “fear learning,” has sown confusion for decades and turned what's effectively an experiment on classical conditioning into an industry of fear. The whole notion of fear learning is fraught with other problems. Rats in threatening situations do not always freeze. When you put them into a small box with tones and shocks arriving together at unpredictable times, rats indeed freeze, but in a larger enclosure, rats run away, unless they're cornered, in which case they attack. If you restrain the rat during the tone (which shouldn't matter, because the rat is going to freeze anyway), its heart rate goes down instead of up. Additionally, not all of these varied behaviors require the amygdala. To date, scientists have identified at least three alleged fear pathways in the rat brain, each associated with a specific behavior, all of them products of the mental inference fallacy. Finally, a simple behavior like freezing is supported by multiple circuits within a distributed network that is not specific to freezing or fear. In a nutshell, you can't study fear by shocking rats unless at the outset you have defined “fear” circularly as “the freezing response of a shocked rat.” Humans, like rats, act in various ways when threatened. We might freeze, flee, or attack. We might also crack jokes, faint, or ignore what's going on. Such behaviors might be evoked by distinct circuitry in the brain that is shared among mammals, but they are not inherently emotional, and they're not evidence that emotions have biological essences. Nevertheless, some scientists continue to write that they've isolated highly complex mental states in animals. Baby rats, for example, when separated from their mother after birth, make a high-pitched noise that sounds like crying. Some scientists inferred that the brain circuitry responsible for the crying must be the circuitry for distress. But these baby rats aren't sad. They're cold. The sound is just a byproduct as the baby rats try to regulate their body temperature-part of their body budget-a task normally done by their absent mothers. It has nothing to do with emotion. The mental inference fallacy strikes again. From now on, any time that you read an article about animal emotion, watch for this pattern. If a scientist labels a behavior like freezing using a mental state word like “fear,” you should think, “Aha, the mental inference fallacy!” To be fair, it's extremely hard for scientists to avoid the trap of mental inference. Grant agencies prefer to fund research that is directly relevant to humans. Scientists must also recognize that they are performing a mental inference in the first place, which is a nontrivial feat of introspection. And then they must be brave enough to face the criticism and scorn of their colleagues for swimming against the tide. But it can be done. The neuroscientist Joseph E. LeDoux, who popularized the idea of fear learning in his acclaimed book The Emotional Brain, now argues against using the term “fear” altogether when referring to a rat. In taking this stand, he is a scientist of rare intellectual courage. He had published hundreds of papers on so-called fear learning, and a popular book on the brain basis of fear in the amygdala, yet he carefully considered the contrary evidence and revised his position. In his revised view, freezing helps keep an animal safe when facing threat; it is a survival behavior. His classic experiments reveal what he now calls a survival circuit that controls freezing behavior, not a mental state like fear. LeDoux's theoretical shift is just another example of the new scientific revolution of the mind and brain, steering the field toward a more scientifically defensible theory of emotion. Although LeDoux and other like-minded scientists have made the shift, you can still easily find the mental inference fallacy in YouTube videos and TED talks by other researchers who study emotion in animals. The speaker shows you a compelling movie or a picture of an animal engaging in some behavior. See how the rat is happy when you tickle it; see how sad the dog is when he whimpers; see how afraid the rat is when she freezes. But remember, emotions are not observed, they are constructed. When you watch the video, you have no awareness that you're using conceptual knowledge to make an inference, any more than you were aware of the processes that turned random blobs into a bee in chapter 2. So to you, it seems like the animal is emotional. In chapter 4, I explained that every so-called emotionally reactive brain region is issuing predictions to regulate the body budget. Add the mental inference fallacy, mix well, and you have a recipe for a grand mythology of how emotions work in the brain. It's one thing to observe that a rodent's anterior cingulate cortex increases its activity when a neighbor is in pain. It's quite another to say the rodent is feeling empathy. A simpler explanation is that the two animals are just influencing each other's body budgets, as so many creatures do. You're more likely to engage in mental inference when the animal in question is similar to yourself. It's easier to perceive joy in a scampering dog than in a scampering cockroach. It's easier to see love in a mother bunny sleeping with her young than in a mother caecilian, a worm-like amphibian, feeding her little babies on her own flesh. The Oscar-nominated science- fiction film District 9 provides a fantastic example of this phenomenon. Its alien creatures seem at first like disgusting, human-sized insects, but once we glimpse that they have families and loved ones, we feel empathy for them. Even Heider's and Simmel's shapes seem human-like, because their speed and trajectories are reminiscent of people chasing one another. We start to perceive their actions in terms of mental causes, and they enter our moral circle. Mental inference toward animals is not a bad thing in itself-it's completely normal. Every day, I drive by a billboard featuring an adorable baby orangutan. I beam every time I approach it, no matter what else I am brooding about, even though I know the orangutan is not really smiling toward me and does not share a mind like my own. Frankly, if everyone engaged in the mental inference fallacy with animals, and in the process we admitted those animals into our moral circle, maybe we'd have fewer poachers who slaughter elephants and rhinos for their ivory or hunt gorillas and bonobos as food. If people engaged in more mental inference when observing their fellow humans, perhaps we'd have less cruelty and fewer wars. When we have our scientist hats on, however, we must resist the lure of mental inference. We are accustomed to thinking about animals in terms of ourselves: how similar they are to us, what they teach us about ourselves, how they might be useful to us, how we are superior to them. It's okay for us to anthropomorphize animals if it's going to protect them. But when we see animals through the lens of our own identity, we can harm them in ways that we often don't think about. We treat anxiously attached dogs as “too dominant” and punish them when we should be offering them predictable care and affection. We rip baby chimps from their mothers when in the wild they would nurse until they are five years old, secure in the warmth and smell of their mother's fur. Our challenge is to understand animal minds for their own sake, not as inferior human minds. The latter idea comes from the classical view of human nature, which implies that chimps and other primates are less evolved, diminished versions of ourselves. They're not. They're adapted to the ecological niche that they live in. Chimps have to forage for food and modern humans largely do not, so a chimp brain is wired to identify and remember details, not to build mental similarities. In the end, if we learn about animals on their own terms, we will benefit because our relationship with them will be better. We humans will do less damage to them and to the world that we all inhabit. Animals are emotional creatures, at least as far as human perceivers are concerned. This is part of the social reality that we create. We grant emotions to our cars, our houseplants, and even little circles and triangles in a movie. We also grant emotions to animals. However, this does not mean that animals experience emotion. Animals with a small affective niche cannot form emotion concepts. A lion cannot hate a zebra when she hunts and kills it as prey. That is why we don't find the lion's actions immoral. Anytime you read a book or news story about animals experiencing human emotions (“News Flash: Cats Feel Schadenfreude toward Mice”), keep this mindset and you'll quickly see the mental inference fallacy materialize before your eyes. Some scientists still presume that all vertebrates share preserved, core emotion circuits to justify the claim that animals feel as humans do. One prominent neuroscientist, Jaak Panksepp, routinely invites his audiences to see evidence of such circuits in his photos of growling dogs and hissing cats, and in videos of baby birds “crying for their mothers.” It is doubtful, however, that these proposed emotion circuits exist in any animal brain. You do have survival circuits for behaviors like the famous “four F's” (fighting, fleeing, feeding, and mating); they're controlled by body-budgeting regions in your interoceptive network, and they cause bodily changes that you experience as affect, but they are not dedicated to emotion. For emotion, you also need emotion concepts for categorization. The search for emotional capacities in animal minds is ongoing. Bonobos and perhaps chimpanzees, our close cousins, might have the hot-wiring in their brain circuitry to form their own sort of emotion concepts. Elephants are another intriguing possibility; they are long-lived, social animals who form strong bonds in close-knit herds. Ditto for dolphins. Even dogs like Rowdy are good candidates, having been bred alongside humans for thousands of years. Something more may be going on in these animals, even if it is not human emotion. As for laboratory rats, Cupcake the guinea pig, and most other animals that we experience as having emotion, they cannot construct emotion because they don't have the necessary emotion concepts. Non-human animals feel affect, but the reality of their emotion is, for the moment, only within ourselves."
  },
  {
    "index": 18,
    "level": 1,
    "start_page": 270,
    "end_page": 283,
    "title": "From Brain to Mind: The New Frontier",
    "content": "From Brain to Mind: The New Frontier. The human brain is a master of deception. It creates experiences and directs actions with a magician's skill, never revealing how it does so, all the while giving us a false sense of confidence that its products-our day-to-day experiences-reveal its inner workings. Joy, sadness, surprise, fear, and other emotions seem so distinct and feel so built-in that we assume they have separate causes inside us. When you have a brain that essentializes, it's easy to come up with a wrong theory of the mind. We are, after all, a bunch of brains trying to figure out how brains work. For millennia, the deception has been largely a success. Oh, the essences of the mind received a makeover every century or two, but for the most part, the idea of mental organs has pretty much stuck around.* Casting away those essences remains a challenge today because the brain is wired to categorize, and categories breed essentialism. Every noun we utter is an opportunity to invent an essence without intending to do so. Little by little, the science of the mind is finally removing its training wheels. The skull is no longer the force field that it was, now that brain- imaging technology can peer harmlessly into a human head. New wearable measurement devices are moving psychology and neuroscience out of the lab and into the real world. As we amass petabytes of brain data with our twenty- first-century tech toys, however, the media, venture capitalists, most textbooks, and some scientists are still interpreting that data with a seventeenth-century theory of the mind (having upgraded to a fancy version of phrenology from Plato 1.0). Neuroscience has delivered a far better understanding of the brain and its function than our own experiences ever could, not just for emotion but for all mental events. If I have done my job correctly, you now realize that many seeming facts about emotions in textbooks and in the popular media are highly doubtful and must be reconsidered. In these pages, you've learned that emotions are part of the biological makeup of the human brain and body, but not because you have dedicated circuits for each one. Emotions are a result of evolution, but not as essences passed down from ancestral animals. You experience emotions without conscious effort, but that does not mean you're a passive recipient of these experiences. You perceive emotions without formal instruction, but that does not mean that emotions are innate or independent of learning. What's innate is that humans use concepts to build social reality, and social reality, in turn, wires the brain. Emotions are very real creations of social reality, made possible by human brains in concert with other human brains. In this final chapter, we will employ the theory of constructed emotion as a flashlight to focus on larger issues of the mind and brain. We'll take a hard look at the predicting brain and everything we've learned about it, such as degeneracy, core systems, and the wiring for concept development, to illuminate the kind of mind most likely to emerge from this kind of brain. We'll see which aspects of the mind are universal or inevitable, which are not, and what this means for your broader understanding of other people and yourself. For as long as people have been writing about humanity, there's been a pervasive assumption that the human mind is created by some all-powerful force. For the Ancient Greeks, that force was nature, embodied as gods. Christianity wrenched human nature away from Mother Nature and placed it in the hands of a single, omnipotent God. Darwin yanked it back and attributed it to a specific feature of nature called evolution. Suddenly you were no longer an immortal soul, and your mind was no longer a battleground of good and evil, righteousness and sin. You were instead a collection of specialized inner forces, sculpted by evolution, that struggle to control your actions. Your brain allegedly battles your body, rationality battles emotionality, cortex battles subcortex, and forces outside of you battle forces within you. With your animal brain wrapped in rational cortex, you are supposedly distinct from other animals in nature, not because you have a soul while they are soulless but because you are the pinnacle of evolution, endowed with insight and reason. You therefore came into the world preformed to respond to what it has to offer in a specific way, not in God's image but by your genes. Experiences like emotions are heralded as evidence that you are an animal through and through. But you are considered special in the animal kingdom because you can overcome your inner beast. As you have learned in this book, however, new discoveries about the brain have revolutionized our understanding of what it means to be human. Your mind is definitely a product of evolution, but it is not sculpted by genes alone. Sure, your brain is made of networked neurons, but that's just one factor in growing a human mind. Your brain also developed inside of a body, nestled among other human brains in bodies, who balanced your body budget and expanded your affective niche through actions and words. Your mind is not a battleground between opposing inner forces-passion and reason-that determine how responsible you are for your behavior. Rather, your mind is a computational moment within your constantly predicting brain. Your brain predicts with its concepts, and while scientists debate whether certain concepts are innate or learned, it's unquestionable that you learned a slew of them as your brain wired itself to its physical and social surroundings. Those concepts come from your culture and help negotiate the quintessential dilemma of living in groups-getting ahead versus getting along-a tug-of- war that has more than one solution. On balance, some cultures favor getting along, while others favor getting ahead. All these discoveries reveal a crucial insight: The human brain evolved, in the context of human cultures, to create more than one kind of mind. People in Western cultures, for example, experience thoughts and emotions as fundamentally different and sometimes in conflict. At the same time, Balinese and Ilongot cultures, and to a certain extent cultures guided by Buddhist philosophy, do not make hard distinctions between thinking and feeling. How do different kinds of minds emerge from one kind of brain with the same set of networks? How can one type of brain create your mind, full of emotion concepts and experiences, and my mind, which has different instances of the same concepts or maybe some different emotion concepts, and a Balinese mind that has no separate concepts or experiences for thoughts and feelings, each of which is adapted to its physical and social environment? On the surface, all normally developing human brains look pretty similar, particularly if you take off your glasses and squint. They all have two hemispheres. Every cortex has five lobes, with up to six layers. The neurons within every cortex are wired to compress information into efficient summaries, creating a conceptual system that shapes action and experience. Many of these features are present in other mammals, and some truly ancient aspects of your nervous system are even shared with insects. (One example is Hox genes, which organize a vertebrate's nervous system from head to tail.) Nevertheless, brains vary significantly from person to person: in the placement of every cortical groove and ridge, in the number of neurons within particular layers of the cortex or in subcortical regions, in the microwiring between neurons, and in the strength of connectivity within brain networks. When you take into account these fine details, no two brains from the same species are structured completely alike. Also, within a single brain such as your own, the wiring is not static. Just as the arbor of a tree grows in the spring and shrinks in the fall, interconnections between your axons and dendrites increase and decrease as you age. You even grow new neurons in certain brain regions. This kind of anatomical change, called plasticity, also occurs with experience. Your experiences become encoded in your brain's wiring and can eventually change the wiring, increasing the chances that you'll have the same experience again, or use a previous experience to create a new one. And from one moment to another, your billions of neurons continually reconfigure themselves from one pattern into another. Chemicals called neurotransmitters make this possible. They enable signals to pass between neurons, and they dial up or dial down neural connections in a split second, so information flows along different paths. Neurotransmitters empower a single brain with a single set of networks to construct diverse mental events, creating something greater than the sum of the parts. Then, of course, we have degeneracy: different sets of neurons produce the same outcomes. Plus, no matter how finely or coarsely you look at brain tissue-as networks, regions, or individual neurons-that tissue contributes to more than one category of mental event, such as anger, attention, or even vision or hearing. Microwiring. Neurotransmitters. Plasticity. Degeneracy. Multipurpose circuitry. Neuroscientists sum up this incredible well of variation by calling the brain a “complex system.” I don't mean complexity colloquially, as in “gosh, that brain sure is complicated,” but something more formal. Complexity is a metric to describe any structure that efficiently creates and transmits information. A system with high complexity can create many new patterns by combining bits and pieces of old patterns. You can find complex systems in neuroscience, physics, mathematics, economics, and other scholarly disciplines. The human brain is a high-complexity system because, within one physical structure, it can reconfigure its billions of neurons to construct a huge repertoire of experiences, perceptions, and behaviors. It achieves high complexity via an ultra-efficient arrangement for communication centered on the critical “hubs” mentioned in chapter 6. This organization permits the brain to integrate so much information from multiple sources so efficiently that it can support consciousness. In contrast, the model of the brain posited by the classical view-independent blobs with distinct functions -would be a low- complexity system because each blob would accomplish its single function by itself. A brain with high complexity and degeneracy brings distinct advantages. It can create and carry more information. It's more robust and reliable, with multiple paths to get to the same end. It's more resistant to injury and illness; you've seen living examples in the twins with amygdala damage (chapter 1) and Roger with his ravaged predictive brain circuitry (chapter 4). Such a brain therefore makes you more likely to survive and pass your genes to the next generation. Natural selection favors a complex brain. Complexity, not rationality, makes it possible for you to be an architect of your experience. Your genes allow you, and others, to remodel your brain and therefore your mind. Complexity implies that the wiring diagram of a brain is not a set of instructions for a single kind of mind with universal mental organs. But the human brain has few preset mental concepts, such as perhaps pleasantness and unpleasantness (valence), agitation and calmness (arousal), loudness and softness, brightness and darkness, and other properties of consciousness. Instead, variation is the norm. The human brain is structured to learn many different concepts and to invent many social realities, depending on the contingencies it is exposed to. This variability is not infinite or arbitrary; it is constrained by the brain's need for efficiency and speed, by the outside world, and by the human dilemma of getting along versus getting ahead. Your culture handed you one particular system of concepts, values, and practices to address that dilemma. We don't need one universal mind, with one set of universal concepts, to claim that we are all one species. All we need is an exceptionally complex human brain that wires itself to its social and physical surroundings, ultimately producing different kinds of minds. A human brain can create many kinds of minds, yet all human minds do have some common ingredients. For millennia, scholars believed that the inevitable bits of the mind were essences, but they are not. The ingredients are three aspects of the mind that we've encountered in this book: affective realism, concepts, and social reality. They (and perhaps others) are inevitable and therefore universal, barring illness, based on the anatomy and function of the brain. Affective realism, the phenomenon that you experience what you believe, is inevitable because of your wiring. The body-budgeting regions in your interoceptive network-your inner loudmouthed, mostly deaf scientist with a megaphone-are the most powerful predictors in your brain, and your primary sensory regions are eager listeners. Body-budget predictions laden with affect, not logic and reason, are the main drivers of your experience and behavior. We all think a food “is delicious” as if the flavor were embedded in the food, when flavor is a construction and the deliciousness is our own affect. When a soldier in a warzone perceives a gun in someone's hands when no gun is present, he might actually see that gun; it's not a mistake but a genuine perception. Judges who are hungry during parole hearings render more negative decisions. Nobody can completely escape affective realism. Your own perceptions are not like a photograph of the world. They are not even a painting of photographic quality, like a Vermeer. They are more like a Van Gogh or Monet. (Or on a very bad day, perhaps a Jackson Pollock.)11 But you can recognize affective realism by its effects. Anytime you have a gut feeling that you know something to be true, that's affective realism. When you hear some news or read a story that you immediately believe, that's affective realism too. Or if you are immediately dismissive of a message, or even dislike the messenger, that is also affective realism. We all like things that support our beliefs, and usually dislike things that violate those beliefs. Affective realism keeps you believing something even when the evidence puts it highly in doubt. It's not because of ignorance or malevolence-it is simply a matter of how the brain is wired and operates. Everything you believe, and everything you see, is colored by your brain's budget-balancing act. Affective realism, when left unchecked, leads people to be dead certain and inflexible. When two opposing groups believe deeply that they are right, they engage in political skirmishes, ideological battles, even wars. The two views of human nature you've seen in this book, from the classical view and construction, have been duking it out for several thousand years. In this ongoing battle, affective realism has led each side to stereotype the other's point of view. The classical view is caricatured as biological determinism, that culture is completely irrelevant and genes are absolute destiny, justifying the present social order of who is wealthy and who struggles. That caricature depicts an extreme version of favoring “getting ahead” over “getting along.” Construction, on the other hand, is criticized as absolute collectivism at the expense of the individual, or as the mistaken view that humans are one big superorganism like the Borg from Star Trek, and that the brain is “a uniform meatloaf” in which every neuron has exactly the same function. It's an exaggerated version of “getting along” trumping “getting ahead.” Each side in this battle ignores the subtleties and variations that necessarily arise in scientific communities. If you've read this far, you've seen that the evidence points to a more nuanced conclusion: the dividing line between biology and culture is porous. Culture arose from natural selection, and as culture gets under the skin and into the brain, it helps to shape the next generation of humans. Affective realism is an inevitability, and yet you are not helpless against it. The best defense against affective realism is curiosity. I tell my students to be particularly mindful when you love or hate something you read. These feelings probably mean that the ideas you've read are firmly in your affective niche, so keep an open mind about them. Your affect is not evidence that the science is good or bad. The biologist Stuart Firestein in his lovely book Ignorance encourages curiosity as a way to learn about the world. Try to become comfortable with uncertainty, he suggests, finding pleasure in mystery, and being mindful enough to cultivate doubt. These practices will help you take a calm look at evidence that violates your own deeply held beliefs and experience the pleasure of the hunt for knowledge. The second inevitability of the mind is that you have concepts, because the human brain is wired to construct a conceptual system. You build concepts for the smallest physical details, like fleeting bits of light and sound, and for incredibly complex ideas like “Impressionism” and “Things Not to Bring on Airplane Rides.” (The latter includes loaded guns, herds of elephants, and your boring Aunt Edna.) Your brain's concepts are a model of the world that keeps you alive, serves to meet your body's energy needs, and ultimately determines how well you propagate your genes. What is not inevitable, however, is that you have particular concepts. Sure, everyone may have some basic concepts as a function of their wiring, such as “Positive” versus “Negative,” but not every mind has distinct concepts for “Feeling” and “Thinking.” Any set of concepts that helps you regulate your body budget and stay alive, as far as your brain is concerned, will do just fine. The emotion concepts that you learned in childhood are just one salient example. Concepts are not just “in your head.” Suppose you and I are chatting over coffee, and when I make some witty remark, you smile and nod. If my brain predicted your smile and your nod, and the visual input to my brain confirms these movements, then my own prediction-say, to nod back at you- becomes my behavior. You in turn might have predicted my nod, along with a host of other possibilities, which causes a change in your sensory input, which interacts with your predictions. In other words, your neurons influence one another not only through direct connections but indirectly through the outside environment, in an interaction with me. We are performing a synchronized dance of prediction and action, regulating each other's body budgets. This same synchrony is the basis of social connection and empathy; it makes people trust and like each other, and it's crucial for parent-infant bonding. Your personal experience, therefore, is actively constructed by your actions. You tweak the world, and the world tweaks you back. You are, in a very real sense, an architect of your environment as well as your experience. Your movements, and other people's movements in turn, influence your own incoming sensory input. These incoming sensations, like any experience, can rewire your brain. So you're not only an architect of your experience, you're also an electrician. Concepts are vital to human survival, but we must also be careful with them because concepts open the door to essentialism. They encourage us to see things that aren't present. Firestein opens Ignorance with an old proverb, “It is very difficult to find a black cat in a dark room, especially when there is no cat.” This statement beautifully sums up the search for essences. History has many examples of scientists who searched fruitlessly for an essence because they used the wrong concept to guide their hypotheses. Firestein gives the example of luminiferous ether, a mysterious substance that was thought to fill the universe so that light would have a medium to move through. The ether was a black cat, writes Firestein, and physicists had been theorizing in a dark room, and then experimenting in it, looking for evidence of a cat that did not exist. The same applies to the classical view of emotion, whose mental organs are a human invention that mistakes the question for the answer. Concepts also encourage us not to see things that are present. One illusory stripe of a rainbow contains an infinite number of frequencies, but your concepts for “Red,” “Blue,” and other colors cause your brain to ignore the variability. Likewise, the frowny-faced stereotype of “Sadness” is a concept that downplays the great variation in that emotion category. The third inevitability of the mind that we've discussed is social reality. When you are born, you can't regulate your body budget by yourself- somebody else has to do it. In the process, your brain learns statistically, creates concepts, and wires itself to its environment, which is filled with other people who have structured their social world in particular ways. That social world becomes real to you as well. Social reality is the human superpower; we're the only animal that can communicate purely mental concepts among ourselves. No particular social reality is inevitable, just one that works for the group (and is constrained by physical reality). Social reality is in some ways a Faustian bargain. For some crucial human activities, such as building civilizations, social reality confers distinct advantages. Culture works most smoothly if we believe in our own mental creations, such as money and laws, without realizing that we're doing so. We don't suspect the involvement of our own hand (or neurons, as it were) in these constructions, so we just treat them as reality. And yet, this same superpower that makes us effective civilization-builders also impedes our own understanding of how we do it. We constantly mistake perceiver-dependent concepts-flowers, weeds, colors, money, race, facial expressions, and so on-for perceiver-independent reality. Many concepts that people consider to be purely physical are in fact beliefs about the physical, such as emotions, and many that appear to be biological are actually social. Even something that seems obviously biological, such as blindness, is not objective in biology. Some sightless people do not think of themselves as blind, because they get around in the world just fine. When you create social reality but fail to realize it, the result is a mess. Many psychologists, for example, do not realize that every psychological concept is social reality. We debate the differences between “will power” and “tenacity” and “grit” as if they were each distinct in nature, rather than constructions shared through collective intentionality. We separate “emotion,” “emotion regulation,” “self-regulation,” “memory,” “imagination,” “perception,” and scores of other mental categories, all of which can be explained as emerging from interoception and sensory input from the world, made meaningful by categorization, with assistance from the control network. These concepts are clearly social reality because not all cultures have them, whereas the brain is the brain is the brain. So, as a field, psychology keeps rediscovering the same phenomena and giving them new names and searching for them in new places in the brain. That's why we have a hundred concepts for “the self.” Even brain networks themselves go by multiple names. The default mode network, which is part of the interoceptive network, has more aliases than Sherlock Holmes. When we misconstrue the social as the physical, we misunderstand our world and ourselves. In this regard, social reality is a superpower only if we know that we have it. From these three inevitabilities of the mind, we see that construction teaches us to be skeptical. Your experiences are not a window into reality. Rather, your brain is wired to model your world, driven by what is relevant for your body budget, and then you experience that model as reality. Your moment-to- moment experience may feel like one discrete mental state followed by another, like beads on a string, but as you have learned in this book, your brain activity is continuous throughout intrinsic, core networks. Your experiences might seem to be triggered by the world outside the skull, but they're formed in a storm of prediction and correction. Ironically, each of us has a brain that creates a mind that misunderstands itself. Where construction advocates skepticism, essentialism is deeply committed to certainty. It says, “Your brain is as your mind appears to be.” You have thoughts, therefore you must have a blob in the brain for thoughts. You experience emotions, therefore you must have blobs in the brain for emotions. You see evidence of thoughts, emotions, and perceptions in other people around the world, so the corresponding brain blobs must be universal and everyone must have the same mental essences. Genes have allegedly produced a mind that is common to all humans. You also see emotions in this animal and that-Darwin even saw emotion in flies-and so these creatures by implication must have the same universal emotion blobs that you do. Neural activity passes from one blob to another like runners in a relay race pass a baton. Essentialism lays out not just a view of human nature but a worldview. It implies that your place in society is shaped by your genes. Therefore, if you are smarter, faster, or more powerful than others, you can justifiably succeed where others cannot. People get what they deserve and they deserve what they get. This view is a belief in a genetically just world, backed by a scientific- sounding ideology. What we experience as “certainty”-the feeling of knowing what is true about ourselves, each other, and the world around us-is an illusion that the brain manufactures to help us make it through each day. Giving up a bit of that certainty now and then is a good idea. For instance, we all think about ourselves and other people in terms of characteristics. He is “generous.” She is “loyal.” Your boss is “an asshole.” Our own sense of certainty tempts us to treat generosity, loyalty, and asshole-ness as if their essences actually live in those people, and as if they are detectable and measurable in objective terms. This not only determines our behavior toward them; we also feel justified in that behavior, even if the “generous” guy is just trying to suck up to you, the “loyal” woman is secretly self-serving, and your “asshole” boss has his mind on his sick kid at home. Certainty leads us to miss other explanations. I'm not saying that we are dumb or ill-equipped to grasp reality. I'm saying there is no single reality to grasp. Your brain can create more than one explanation for the sensory input around you-not an infinite number of realities, but definitely more than one. A healthy dose of skepticism yields a worldview that is different from the genetically just world of the classical view. Your place in society is not random but neither is it inevitable. Consider an African American child born into poverty. She is less likely to receive proper nutrition during her early years of brain development-circumstances that will, in particular, negatively impact the development of her prefrontal cortex (PFC). These neurons are particularly important for learning (i.e., processing prediction error) and control; not surprisingly, the size and performance of PFC regions is linked to many skills that are required for doing well in school. Poorer nutrition equals a thinner PFC, which is linked to poorer performance in school, and less education, like not completing high school, leads back to poverty. In this cyclic manner, society's stereotypes about race, which are social reality, can become the physical reality of brain wiring, thereby making it seem as if the cause of poverty were simply genes all along. Some research seems to show that such stereotypes are more accurate than we might think. Steven Pinker writes in The Blank Slate, for example, that “people who believe that African Americans are more likely to be on welfare than whites . . are not being irrational or bigoted. Those beliefs are correct” when compared to census figures. He and others argue that many scientists dismiss stereotypes as inaccurate because we are bullied into political correctness, are condescending toward ordinary people, or are biased by our own muddled assumptions about human nature. But as you've just seen, there is another possibility: the official welfare statistics are true because we, as a society, made them so. By virtue of our values and practices, we restrict options and narrow possibilities for some people while widening them for others, and then we say that stereotypes are accurate. They are accurate only in relation to a shared social reality that our collective concepts created in the first place. People aren't a bunch of billiard balls knocking one another around. We are a bunch of brains regulating each other's body budgets, building concepts and social reality together, and thereby helping to construct each other's minds and determine each other's outcomes. Some readers might dismiss this sort of constructionist worldview as a stereotypically bleeding-heart liberal ivory tower academic viewpoint from the Land Where Everything Is Relative. In fact, this view cuts across traditional political lines. The idea that you're molded by your culture is stereotypically liberal. At the same time, as we discussed in chapter 6, you are responsible in a broad sense for the concepts you have, which ultimately influence your behavior. Individual responsibility is a deeply conservative idea. You are also somewhat responsible to others, not only the less fortunate but also future generations, for how you influence their wiring. It matters how you treat other people. That is a fundamentally religious idea. The American Dream traditionally says, “If you work hard, anything is possible.” Construction agrees that you're indeed the agent of your own destiny, but you are bounded by your surroundings. Your wiring, determined in part by your culture, influences your later options. I don't know about you, but I find some comfort in a bit of uncertainty. It's refreshing to question the concepts that have been given to us, and to be curious about which are physical and which are social. There is a kind of freedom in realizing that we categorize to create meaning, and therefore it is possible to change meaning by recategorizing. Uncertainty means that things can be other than they appear. This realization brings hope in difficult times and can prompt gratitude in good times. Now it's time for me to drink my own Kool-Aid. Prediction, interoception, categorization, and the roles I've described for your various brain networks are not objective facts. They are concepts invented by scientists to describe the physical activity within a brain. I claim these concepts are the best way to understand certain computations being performed by neurons. However, there are many other ways to read the brain's wiring diagram (some of which wouldn't call it a wiring diagram at all). The theory of constructed emotion maps to the brain more closely than do so-called psychological essences or mental organs. In the future, I wouldn't be surprised to see more useful and functional concepts for the brain's structure emerge. As Firestein observes in Ignorance, no fact is “safe from the next generation of scientists with the next generation of tools.”20 The history of science, however, has been a slow but steady march in the direction of construction. Physics, chemistry, and biology began with intuitive, essentialist theories, rooted in naive realism and certainty. We progressed beyond these ideas because we noticed that the old observations held true only under certain conditions. So, we had to replace our concepts. A scientific revolution swaps out one social reality for another, just like a political revolution does with its new government and social order. Again and again in science, our new sets of concepts have led us away from essentialism toward variation, and from naive realism to construction. The theory of constructed emotion predicts and matches the latest scientific evidence about emotion, the mind, and the brain, and yet so much about the brain is still a mystery. We're finding that neurons aren't the only important cells in the brain; glial cells, long ignored, turn out to do a hell of a lot, possibly even communicating with each other without synapses. The enteric nervous system, which controls your stomach and intestines, is looking more and more important for understanding the mind, but it's extremely difficult to measure and therefore largely unexplored. We're even finding that microbes in your stomach have a huge effect on mental states, and nobody knows how or why. There's so much innovative research going on that in ten years, today's experts might feel like Plato in the presence of a brain-scanning machine. As our tools improve and our knowledge grows, I am confident that we'll discover the brain to be even more steeped in construction than we now know it to be. Perhaps our core ingredients like interoception and concepts will one day be seen as too essentialist, as we discover something even more finely constructed going on behind the scenes. Our scientific story is still evolving, but that's not surprising. Progress in science isn't always about finding the answers; it's about asking better questions. Today, those questions have forced a paradigm shift in the science of emotion, and more broadly in the science of mind and brain. In the coming years, I hope we'll all see fewer and fewer news stories about brain blobs for emotion in people or rats or fruit flies, and more about how brains and bodies construct emotion. In the meantime, whenever you see an essentialism-steeped news story about emotion, if you even feel a twinge of doubt, then you're playing a role in this scientific revolution. Like most important paradigm shifts in science, this one has the potential to transform our health, our laws, and who we are. To forge a new reality. If you've learned within these pages that you are an architect of your experience -and the experiences of those around you-then we're building that new reality together."
  },
  {
    "index": 20,
    "level": 1,
    "start_page": 292,
    "end_page": 296,
    "title": "Appendix A",
    "content": "Appendix A. Brain Basics Every Halloween, I create a life-sized model of the brain out of gelatin. I pour boiling water into peach-flavored gelatin, add condensed milk to make the mixture opaque, and dribble in some green food coloring to turn the brain a jiggly gray. The brain is a prop for an elaborate haunted house that my family and lab have designed and run since 2004 as a charity event. Visitors who make it through the haunted house always exclaim (once they can speak normally again) how realistic the brain looks, which is interesting because a real brain is nothing like a uniform blob of gelatin. It is a massive network composed of billions of brain cells wired together to pass information back and forth. To get the most out of this book, you'll need a few basic facts about the human brain. The most important type of brain cell for our discussion is the neuron. There are a wide variety of neurons, but in general, each one consists of a cell body, some branch-like structures on the top called dendrites, and one root-like structure on the bottom called an axon, which has axon terminals at its end, as in figure AA-1. The axon terminals of one neuron are close to the dendrites of other neurons-usually thousands-forming connections called synapses. A neuron “fires” by sending an electrical signal down its axon to its axon terminals, which release chemicals called neurotransmitters into the synapses, where they are picked up by receptors on the dendrites of other neurons. The neurotransmitters excite or inhibit each neuron on the other end of a synapse, changing its rate of firing. Through this process, one individual neuron influences thousands of others, and thousands of neurons can influence one, all simultaneously. This is the brain in action. Figure AA-1: Neurons come in different shapes but they each have a cell body, one long axon, and dendrites. At a more macro level, the human brain can be divided, more or less, into three major parts based on how the neurons are arranged.* The cortex is a sheet of neurons arranged in layers, anywhere from four to six (see figure AA-2), wired into circuits and networks. A cross section of this sheet reveals that neurons are organized into columns; neurons within the same column of cortex form synapses with each other, and with neurons in other columns. The cortex is folded around the subcortical regions that, in contrast to the layered cortex, are organized as clumps of neurons, as depicted in figure AA- 3. The ever-popular amygdala, for example, is a subcortical region. The third part of the brain, the cerebellum, is toward the bottom of the brain, at the back. The cerebellum is important for coordinating physical movements and making that information available to the rest of the brain. Scientists must point to different collections of neurons, that is, “brain areas,” so they have devised some terminology to help.* The cortex, which comes up repeatedly in this book, is divided into discrete areas called lobes, which are rather like continents in the brain (figure AA-4). Figure AA-2: Cross section of six-layered cortex Figure AA-3: Three major parts of the brain For navigating the entire brain, instead of using compass directions like east or northwest, scientists uses phrases like “dorsal anterior” (upper front) or “medial” (inner wall). Figure AA-5 shows the various road signs for finding your way around. Figure AA-4: Lobes of the cortex Figure AA-5: Road signs for the brain. Anterior = toward the front; posterior = toward the back; dorsal = toward the top; ventral = toward the bottom; medial = toward the midline or middle; and lateral = away from the midline toward the outside Your brain is part of your central nervous system, as distinct from the neurons that lace through your body, known as your peripheral nervous system. For historical reasons, not all of which make sense, they are usually studied as two separate systems. Your spinal cord (part of the central nervous system) carries information between your body and your brain. Figure AA-6: Components of the human nervous system Your autonomic nervous system is one avenue for your brain to regulate your body's internal environment. It carries your brain's commands to the body's internal organs, known as the viscera, and sends sensations from the viscera back up to the brain. This process controls heart rate, breathing rate, perspiration, digestion, hunger, the dilation of your pupils, sexual arousal, and a host of other bodily functions. It is responsible for “fight or flight” responses that tell your body to spend its energy resources, as well as “rest and digest” that replenish those resources. The autonomic nervous system also helps to control your metabolism, water balance, temperature, salt, heart and lung function, inflammation, and other resources across all systems of the body, like a budget. The somatic nervous system gives the brain access to muscles, joints, tendons, and ligaments."
  },
  {
    "index": 23,
    "level": 1,
    "start_page": 301,
    "end_page": 311,
    "title": "Appendix D",
    "content": "Appendix D. Evidence for the Concept Cascade I've described the brain in two ways that look like hierarchies. (They are metaphors to help understand brain activity; neurons are not wired in a strict hierarchy.) The first hierarchy in chapter 6 illustrates how the brain uses sensory input to form concepts, as a hierarchy of similarities and differences. This hierarchy is bottom-up and should be familiar to neuroscientists. Your primary sensory regions are at the bottom; their neurons fire to represent the different sensory details of bodily sensations, changing wavelengths of light, changes in air pressure, and so on, that make up a particular instance. The neurons at the top of the hierarchy represent the highest-level, efficient, multisensory summary of the instance. The second hierarchy in chapter 4 illustrates how concepts unpack as predictions, based on the structure of the cortex. This hierarchy is top-down and incorporates some of my own discoveries. Body-budgeting circuitry (more commonly called visceromotor limbic circuitry), the loudmouth of the brain, is at the top, and it issues but does not receive predictions. Primary sensory regions are at the bottom, as they receive predictions but don't issue them to other cortical regions. In this manner, body-budgeting regions drive predictions throughout the brain and down to the primary sensory regions, in progressively finer detail. The two hierarchies represent the same circuitry but operate in reverse. The former hierarchy is for learning concepts and the latter-which I call the concept cascade-is for applying those concepts to construct your perceptions and actions. In this manner, categorization is a whole-brain activity, with predictions flowing from simulated similarities to simulated differences, and prediction errors flowing in the other direction. The concept cascade involves some reasoned speculation but is consistent with evidence from neuroscience. At present, we have scientific evidence that all the external sensory systems (vision, hearing, etc.) operate by prediction. Along with my colleague neuroscientist W. Kyle Simmons, I discovered that the interoceptive network is also structured to function this way. Right now, scientists have specific details of the conceptual cascade within the visual system. The broader conceptual cascade that I've outlined in this book is based on three very solid pieces of evidence: (1) the anatomical evidence in chapter 4 about how predictions and prediction errors flow across the structure of cortex, (2) the anatomical evidence showing that the cortex is structured to compress sensory differences into multisensory summaries in chapter 6, and (3) scientific evidence on the functions of several brain networks, which we'll discuss now. A prediction originates as a multisensory summary, representing the goal of the concept, in a portion of the interoceptive network known as the default mode network. Notice I did not say that concepts are “stored” in the default mode network. I specifically use the word “originate.” Concepts do not live wholesale in the default mode network, or anywhere else, as if they were entities. This network simulates only part of the concept, namely, the efficient, multisensory summaries of the concept instances with none of their sensory details. When your brain constructs a concept of “Happiness” on the fly, for use in a specific situation, degeneracy is in play. Each instance is created with its own pattern of neurons. The more conceptually similar the instances are, the more the neural patterns will be close to one another in the default mode network, and some will even overlap, using some of the same neurons. Different representations need not be separate in the brain, just separable. The default mode network is an intrinsic network. In fact, it was the first intrinsic network to be discovered. Scientists noticed a set of brain regions that increased their activity when subjects were lying at rest. They named these regions the “default mode” because they are spontaneously active while the brain isn't being probed or stimulated by an experimental procedure. When I first learned about this network, I thought the choice of name was unfortunate, because numerous other intrinsic networks have since been discovered. But the name is ironic: Scientists originally believed the brain's “default” activity was aimless mind-wandering between tasks, when in fact this network is at the core of every prediction in the brain. Your brain's “default mode” by which it interprets and navigates the world, namely, prediction using concepts, makes the name fit this network nicely. Figure AD-1: The default mode network, which lies within the interoceptive network. Body-budgeting regions, which launch predictions, are in dark gray. They send commands to the subcortical nuclei that control the body's tissues and organs, metabolism, and immune function. Top is medial view, bottom is lateral. Neuroscientists have demonstrated pretty definitively that the default mode network represents key portions of concepts. This discovery required clever scientific experiments. You can't simply ask a test subject to simulate a concept and then look for increased activation in the default mode network. That single concept would barely perturb the brain's maelstrom of intrinsic activity, like spitting into an ocean wave. Fortunately, the cognitive neuroscientist Jeffrey R. Binder and his colleagues designed an ingenious brain-scanning experiment to work around this issue. They created two experimental tasks, one that used more conceptual knowledge than the other, and “subtracted” the results to yield the difference. In Binder's first experimental task, test subjects in a brain scanner listened to names of animals like “fox,” “elephant,” and “cow,” and were asked a question whose answer requires rich conceptual knowledge of purely mental similarities (e.g., “Is the animal found in the United States and used by people?”). In the second task, subjects were scanned while making a decision that requires more limited conceptual knowledge based on perceptual similarity (e.g., they were told to listen to syllables like “pa-da-su” and respond when they hear the consonants “b” and “d”). Both tasks should produce an increase in activation in sensory and motor networks, but only the former task should produce an increase in the default mode network. By “subtracting” one brain scan from the other, Binder and his colleagues removed the brain activity related to sensory and motor details and observed an increase in activity within the default mode network, as predicted. Binder's findings have been replicated by a meta-analysis of 120 similar brain-imaging experiments. The default mode network supports mental inference, that is, categorizing another person's thoughts and feelings with mental concepts. In one study, participants were presented with written descriptions of actions such as drinking coffee, brushing teeth, and eating ice cream. On some trials, participants were asked how people performed these actions: drinking coffee from a mug, brushing teeth with a toothbrush, eating ice cream with a spoon. Participants appeared to simulate these actions in motor regions of the brain. On other trials, participants were asked why people performed such actions: drinking coffee to stay awake, brushing teeth to avoid cavities, eating ice cream because it tastes good. These judgments require purely mental concepts, and they were more associated with activity in the default mode network. A growing number of cognitive neuroscientists, social psychologists, and neurologists speculate that the default mode network has a general function: it allows you to simulate how the world might be different from the way it is right now. This includes remembering the past and imagining the future from different points of view. This remarkable ability provides you with a leg up when negotiating the two big challenges of human life: getting along with others and getting ahead to benefit yourself. The social psychologist Daniel T. Gilbert, author of Stumbling on Happiness, who is famous for his humorous eloquence, calls the default mode network an “experience simulator,” akin to flight simulators for training pilots. By simulating a future world, you are better equipped to reach your future goals. The default mode network unites past, present, and future. Information from the past, constructed as concepts, forms predictions about the present, which make you better equipped to reach your future goals. I find it useful to think about the default mode network as playing a key role in categorization. The network initiates predictions to create simulations, thereby allowing the brain to work its magic of modeling the world. The “world” in this case includes the outside world, the minds of other people, and the body that holds the brain. Sometimes these simulations are corrected by the outside world, like when you construct emotions, and other times they aren't, like when you imagine or dream. Of course, the default mode network is not working alone. It contains only part of the pattern required for making a concept, namely, the mental, goal- based, multisensory knowledge that initiates a cascade. Anytime you imagine things, or your mind wanders, or your brain performs other intrinsic activity, you also simulate sights, sounds, changes in your body budget, and other sensations that are the domain of sensory and motor networks. Thus, it stands to reason that the default mode network should be interacting with these other networks to construct instances of concepts. (And they do, which you'll see shortly.)9 Newborns don't have a fully formed default mode network, hence their inability to predict and their diffuse “lantern” of attention; newborn brains spend a lot of time learning from prediction error. It very well may be that experience with the multisensory world, anchored in body budgeting, provides the needed inputs that help the default mode network to form. This occurs sometime during the first few years of life as the brain is bootstrapping concepts into its wiring. What begins as “outside” becomes “inside” as you become wired by your environment. My lab has been investigating the biology of concepts and categorization for some time, and we've uncovered considerable evidence about the roles of the default mode network, the rest of the interoceptive network, and the control network. When we peer into the brains of people who are experiencing emotion, or perceiving emotion in blinks, furrowed brows, muscle twitches, and the lilting voices of others, we see pretty clearly that key parts of these networks are hard at work. For starters, you might remember my lab's meta-analysis that examined every published neuroimaging study of emotion, which we saw in chapter 1. We divided the entire brain into tiny cubes called “voxels” (akin to “pixels” of the brain), and then identified voxels that consistently showed a significant increase in activity for any of the emotion categories we studied. We could not localize a single emotion category to any brain region. This same meta-analysis also provided evidence for the theory of constructed emotion. We identified groups of voxels that activated together with high probability, like a network would. These groups of voxels consistently fell within the interoceptive and control networks. When you consider that our meta-analysis, at the time it was conducted, covered over 150 diverse, independent studies by hundreds of scientists, in which subjects viewed faces, smelled scents, listened to music, watched movies, remembered past events, and performed many other emotion-evoking tasks, the emergence of these networks is particularly compelling. These findings are even more remarkable to me because the studies covered by the meta-analysis weren't designed to test the theory of constructed emotion. Most were inspired by classical view theories and designed to localize each emotion to a different region of the brain. And most of them studied only the most stereotyped examples of emotion categories and did not examine each emotion in all its real-life variations. Our meta-analysis project is ongoing, and we have collected almost four hundred brain-imaging studies to date. From this data, my colleagues and I used pattern classification analysis (chapter 1) to produce five summaries of emotion categories, shown in figure AD-2. In all five, the interoceptive network played a significant role. The control network was also present for all five, but less clearly for happiness and sadness. Remember that you're not looking at neural fingerprints here, just abstract summaries. No single instance of anger, disgust, fear, happiness, or sadness looks exactly like its associated summary. Each instance can use diverse combinations of neurons, as we know from the principle of degeneracy. For each study of (say) anger in the meta-analysis, the brain activity was closer to the anger summary than to the other summaries, so it was identified as anger. So we can diagnose an instance of anger, but we cannot specify which neurons will be active. In other words, we have applied Darwin's principle of population thinking to the construction of anger. The same result follows for the other four emotion categories we studied. Figure AD-2: Statistical summaries of the concepts (top to bottom) “Anger,” “Disgust,” “Fear,” “Happiness,” and “Sadness.” These are not neural fingerprints (see chapter 1). Left is lateral view, right is medial view. When we specifically design experiments to test the theory of constructed emotion, we find similar results. In one study, my collaborators Christine D. Wilson-Mendenhall and Lawrence W. Barsalou, and I asked subjects to immerse themselves in imagined scenarios while we performed brain scans. We saw evidence of the resulting simulations as increased activity in sensory and motor regions. We could also see evidence that their body budgets were perturbed, associated with changes in the interoceptive network. In a second phase after each immersion, test subjects were shown a word and asked to categorize their interoceptive sensations as instances of either “Anger” or “Fear.” As our subjects simulated these concepts, we saw even more increased activity in the interoceptive network. We also saw activations representing the low-level sensory and motor details, as well as increased activity in a key node in the control network. In a later study, we had subjects construct atypical, infrequent simulations, such as the pleasant fear of riding a rollercoaster and the unpleasant happiness of injuring yourself while winning a competition. We hypothesized that less typical simulations would require the interoceptive network to work harder to issue predictions, compared to simulating more typical instances like pleasant happiness and unpleasant fear, which are like mental habits. This is exactly what we observed. In a more recent set of experiments, our test subjects watched evocative movie scenes, and we saw the interoceptive network construct ongoing emotional experiences. Talma Hendler's lab at Tel Aviv University in Israel chose film clips that would create a variety of different experiences of sadness, fear, and anger. For example, some test subjects watched a scene from Sophie's Choice where the title character, played by Meryl Streep, must choose one of her children to be taken from her at Auschwitz. Other test subjects watched a clip from the film Stepmom, where Susan Sarandon's character reveals to her children that she is dying of cancer. In all cases, we observed that the default mode network and the remainder of the interoceptive network were firing more in synchrony in the moments when subjects reported more intense emotional experiences, and less so when subjects reported less intense experiences. Other studies make a similar case for emotion perception. In one study, subjects watched movies and explicitly categorized the characters' physical movements as emotional expressions. In other words, they made mental inferences about what the movements meant, a task that requires concepts. Their brains showed increased activity in the interoceptive network, in nodes of the control network, and in visual cortex where objects are represented. When discussing concepts, we must be mindful not to essentialize because it's super easy to imagine concepts as “stored” in your brain. For example, you could think concepts live in the default mode network alone (as if the summaries exist apart from their sensory and motor details). There is abundant evidence (and very little doubt), however, that any instance of any concept is represented by the entire brain. As you look at the hammer in figure AD-3, neurons in your motor cortex that control your hand movements have increased their firing. (And if you are like me, the neurons that simulate pain in your thumb are also firing madly.) This increase even occurs when you read the name of the object (“hammer”). Viewing the hammer also makes it easier for you to make a gripping motion with your hand. Figure AD-3: Tweaking your motor cortex Likewise, as you read these words: Apple, Tomato, Strawberry, Heart, Lobster neurons that process color sensations in early visual cortex also increase their firing rate, because all of the objects are typically red. So concepts have no mental core in the default mode network; they are represented throughout the entire brain. A second essentialist misconception is that your default mode network has a single set of neurons for each goal, like little essences, even if the rest of the concept, such as sensory and motor features, is distributed throughout the brain. This cannot be the case, however. If it were, then in brain scans we'd see this “essence” activate first, under all conditions, because it's at the top of their concept cascade, followed by the more variable sensory and motor differences depending on the situation, but we see nothing of the kind. Here again, essentialism yields to degeneracy. Each time you construct an instance of an emotion concept like “Happiness” with a particular goal, such as being with a close friend, the pattern of neural firing can be different. Even the highest-level, multisensory summary of “Happiness,” represented by sets of neurons in the default mode network, can be different each time. None of these instances need be physically alike, and yet they are all instances of “Happiness.” What is binding them together? Nothing. They are not “bound” together in any permanent way. But they are very likely initiated concurrently, as predictions. When you read the word “happy” or hear it spoken, or when you find yourself surrounded by your favorite people, your brain launches a variety of predictions, each with some prior probability of being likely in whatever the specific situation is. Words are powerful. This is reasoned speculation on my part because the brain operates on degeneracy, words are key to concept learning, and the default mode network and the language network share many brain regions. A third mistake of essentialism is thinking of concepts as “things.” When I was an undergraduate student, I took a course in astronomy where I learned the universe was expanding. At first, I was baffled: expanding into what? I was confused because I harbored an incorrect intuition that the universe was expanding into space. After some reflection, I realized that I conceived of “space” in rather literal, physical terms, as a big, dark, empty bucket. Instead, “space” is a theoretical idea-a concept-not a concrete, fixed entity; space is always computed in relation to something else. (“Space and time are in the eye of the beholder.”)21 Something similar happens when people think about concepts. A concept is not a “thing” that exists in the brain, any more than “space” is a physical thing that the universe expands into. “Concept” and “space” are ideas. It is a verbal convenience to talk about “a” concept. Really you have a conceptual system. When I write “you have a concept for awe,” this translates as “you have many instances that you have categorized, or that have been categorized for you, as awe, and each can be reconstituted as a pattern in your brain.” The “concept” refers to all the knowledge you construct about awe in your conceptual system in a given moment. Your brain is not a vessel that “contains” concepts. It enacts them as a computational moment over some period of time. When you “use a concept,” you are really constructing an instance of that concept on the spot. You don't have little packets of knowledge called “concepts” stored in your brain, any more than you have little packets called “memories” stored in your brain. Concepts have no existence separate from the process that creates them."
  }
]